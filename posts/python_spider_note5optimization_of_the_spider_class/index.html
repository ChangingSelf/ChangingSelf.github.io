<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>python爬虫学习笔记5爬虫类结构优化 - 憧憬少的个人博客</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="憧憬少的个人博客"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="憧憬少的个人博客"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="打算全部以 cookie 来登陆，而不依赖于 session（因为听组长说 session 没 cookie 快，而且我想学些新东西而不是翻来覆去地在舒适区鼓捣）。弄了几天终于弄出来个代码不那么混乱的爬虫类了，更新一下博文来总结一下。代码在我 github 的 spider 库里面。"><meta property="og:type" content="blog"><meta property="og:title" content="python爬虫学习笔记5爬虫类结构优化"><meta property="og:url" content="https://yxchangingself.xyz/posts/python_spider_note5optimization_of_the_spider_class/"><meta property="og:site_name" content="憧憬少的个人博客"><meta property="og:description" content="打算全部以 cookie 来登陆，而不依赖于 session（因为听组长说 session 没 cookie 快，而且我想学些新东西而不是翻来覆去地在舒适区鼓捣）。弄了几天终于弄出来个代码不那么混乱的爬虫类了，更新一下博文来总结一下。代码在我 github 的 spider 库里面。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://yxchangingself.xyz/img/og_image.png"><meta property="article:published_time" content="2019-04-21T04:44:01.000Z"><meta property="article:modified_time" content="2019-04-21T04:44:01.000Z"><meta property="article:author" content="憧憬少"><meta property="article:tag" content="spider"><meta property="article:tag" content="python"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yxchangingself.xyz/posts/python_spider_note5optimization_of_the_spider_class/"},"headline":"憧憬少的个人博客","image":["https://yxchangingself.xyz/img/og_image.png"],"datePublished":"2019-04-21T04:44:01.000Z","dateModified":"2019-04-21T04:44:01.000Z","author":{"@type":"Person","name":"憧憬少"},"description":"打算全部以 cookie 来登陆，而不依赖于 session（因为听组长说 session 没 cookie 快，而且我想学些新东西而不是翻来覆去地在舒适区鼓捣）。弄了几天终于弄出来个代码不那么混乱的爬虫类了，更新一下博文来总结一下。代码在我 github 的 spider 库里面。"}</script><link rel="canonical" href="https://yxchangingself.xyz/posts/python_spider_note5optimization_of_the_spider_class/"><link rel="alternate" href="/atom.xml" title="憧憬少的个人博客" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?74d1c5bd37e68cef3ecacf9c903ec5a5";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.0.2"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">ChangingSelf</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/friends">友链</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ChangingSelf/ChangingSelf.github.io"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-04-21T04:44:01.000Z" title="2019-04-21T04:44:01.000Z">2019-04-21</time>发表</span><span class="level-item"><time dateTime="2019-04-21T04:44:01.000Z" title="2019-04-21T04:44:01.000Z">2019-04-21</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span><span class="level-item">19 分钟读完 (大约2830个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">python爬虫学习笔记5爬虫类结构优化</h1><div class="content"><p>打算全部以 cookie 来登陆，而不依赖于 session（因为听组长说 session 没 cookie 快，而且我想学些新东西而不是翻来覆去地在舒适区鼓捣）。弄了几天终于弄出来个代码不那么混乱的爬虫类了，更新一下博文来总结一下。代码在我 github 的 spider 库里面。</p>
<a id="more"></a>

<h1 id="初步思路"><a href="#初步思路" class="headerlink" title="初步思路"></a>初步思路</h1><p>既然要封装成爬虫类，那么就以面向对象的思维来思考一下结构。</p>
<p>从通用的爬虫开始，先不考虑如何爬取特定的网站。</p>
<p>以下只是刚开始的思路，并不是最终思路。</p>
<p>爬虫的行为步骤并不复杂，分为以下几步：</p>
<ol>
<li>请求并获取网页（往往需要模拟登录）</li>
<li>解析网页提取内容（还需要先获取需要爬取的 url）</li>
<li>保存内容（保存到数据库）</li>
</ol>
<p>爬虫类方法（初步设计）：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>login</td>
<td>登录</td>
</tr>
<tr>
<td>parse</td>
<td>解析</td>
</tr>
<tr>
<td>save</td>
<td>保存</td>
</tr>
<tr>
<td>crawl</td>
<td>爬取（外部调用者只需调用这个方法即可）</td>
</tr>
</tbody></table>
<p>爬虫类属性（初步设计）：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>headers</td>
<td>请求的头部信息，用于伪装成浏览器</td>
</tr>
<tr>
<td>cookies</td>
<td>保存登录后得到的 cookies</td>
</tr>
<tr>
<td>db_data</td>
<td>数据库的信息，用于连接数据库</td>
</tr>
</tbody></table>
<h1 id="进一步设计"><a href="#进一步设计" class="headerlink" title="进一步设计"></a>进一步设计</h1><p>我想将这个爬虫类设计得更为通用，也就是只修改解析的部分就能爬取不同的网站。组长说我这是打算写一个爬虫框架，我可没那么厉害，只是觉得把逻辑写死不能通用的类根本不能叫做类罢了。</p>
<h2 id="参考代码"><a href="#参考代码" class="headerlink" title="参考代码"></a>参考代码</h2><p>我看了一下组长给出的参考代码，大致结构是这样的：</p>
<p>首先一个<code>Parse</code>解析类（为了关注结构，具体内容省略）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parse</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_index</span>(<span class="params">self,text</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        用于解析首页</span></span><br><span class="line"><span class="string">        :param text: 抓取到的文本</span></span><br><span class="line"><span class="string">        :return: cpatcha_url, 一个由元组构成的列表(元组由两个元素组成 (代号，学校名称))</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">       <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_captcha</span>(<span class="params">self, content, client</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        解析验证码</span></span><br><span class="line"><span class="string">        :return: &lt;int&gt; or &lt;str&gt; a code</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_info</span>(<span class="params">self, text</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        解析出基本信息</span></span><br><span class="line"><span class="string">        :param text:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_current_record</span>(<span class="params">self, text</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        解析消费记录</span></span><br><span class="line"><span class="string">        :param text:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self.parse_info(text)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_history_record</span>(<span class="params">self, text</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        解析历史消费记录</span></span><br><span class="line"><span class="string">        :param text:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self.parse_info(text)</span><br></pre></td></tr></table></figure>

<p>这个思路不错，<strong>将解析部分独立形成一个类</strong>，不过这样要如何与爬虫类进行逻辑上的关联呢？解析类的对象，是什么？是解析器吗？解析器与爬虫应该是什么关系呢？</p>
<p>我继续往下看：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Prepare</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login_data</span>(<span class="params">self,username, password, captcha, schoolcode, signtype</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        构造登陆使用的参数</span></span><br><span class="line"><span class="string">        :return:data</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">pass</span><span class="comment">#省略代码，下同</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">history_record_data</span>(<span class="params">self, beginTime, endTime</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        历史消费记录data</span></span><br><span class="line"><span class="string">        :param beginTime:</span></span><br><span class="line"><span class="string">        :param endTime:</span></span><br><span class="line"><span class="string">        :return: data</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这是一个<code>Prepare</code>类，准备类？准备登录用的数据。说起来似乎比解析类更难以让我接受。解析器还可以说是装在爬虫身上，但是，但是“准备”这件事情分明是一个动作啊喂！</p>
<p>好吧，“一类动作”倒能说得过去吧。我看看怎么和爬虫类联系起来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>(<span class="params">Parse, Prepare</span>):</span><span class="comment">#???</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>等会儿等会儿……</p>
<p>继承关系？</p>
<p>让我捋捋。</p>
<p>为了让爬虫能解析和能准备还真是不按套路出牌啊……</p>
<p>子类应该是父类的特化吧不是吗，就像猫类继承动物类，汽车类继承车类一样，猫是动物，汽车也是车。</p>
<p>算了不继续了，毕竟我不是为了故意和我组长作对。只是将其作为一个例子来说明我的思路。</p>
<h2 id="解析器类"><a href="#解析器类" class="headerlink" title="解析器类"></a>解析器类</h2><p>参考代码虽然不太能让我接受，但是它的结构仍然带给了我一定启发。就是解析函数不一定要作为爬虫的方法。</p>
<p>解析这个步骤如果真的只写在一个函数里面真的非常非常乱，因为解析不只一个函数。比如解析表单的隐藏域，解析页面的 url，解析页面内容等。</p>
<p>单独写一个解析类也可以。至于它和爬虫类的关系，我觉得<strong>组合关系</strong>更为合适（想象出了一只蜘蛛身上背着一个红外透视仪的样子），spider 的解析器可以更换，这样子我觉着更符合逻辑一些。</p>
<p>关于更换解析器的方式，我打算先写一个通用的解析器类作为基类，而后派生出子解析器类，子解析器根据不同的网站采取不同的解析行为。</p>
<p>然后新建<code>my_parser.py</code>文件，写了一个<code>MyParser</code>类。解析方式是 xpath 和 beautifulsoup。这里面的代码是我把已经用于爬取学校网站的特定代码通用化之后的示例代码，实际上并不会被调用，只是统一接口，用的时候会新写一个类继承它，并覆盖里面的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyParser</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login_data_parser</span>(<span class="params">self,login_url</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        This parser is for chd</span></span><br><span class="line"><span class="string">        :param url: the url you want to login</span></span><br><span class="line"><span class="string">        :return (a dict with login data,cookies)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        response=requests.get(login_url)</span><br><span class="line">        html=response.text</span><br><span class="line">        <span class="comment"># parse the html</span></span><br><span class="line">        soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        <span class="comment">#insert parser,following is an example</span></span><br><span class="line">        example_data=soup.find(<span class="string">&#x27;input&#x27;</span>,&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;example_data&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">        login_data=&#123;</span><br><span class="line">            <span class="string">&#x27;example_data&#x27;</span>:example_data</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> login_data,response.cookies</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uni_parser</span>(<span class="params">self,url,xpath,**kwargs</span>):</span></span><br><span class="line">        response=requests.post(url,**kwargs)</span><br><span class="line">        html=response.text</span><br><span class="line">        tree=etree.HTML(html)</span><br><span class="line">        result_list=tree.xpath(xpath)</span><br><span class="line">        <span class="keyword">return</span> result_list</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_urls</span>(<span class="params">self,catalogue_url,**kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        get all urls that needs to crawl.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment">#prepare</span></span><br><span class="line">        base_url=<span class="string">&#x27;http://example.cn/&#x27;</span></span><br><span class="line">        cata_base_url=catalogue_url.split(<span class="string">&#x27;?&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        para = &#123;</span><br><span class="line">            <span class="string">&#x27;pageIndex&#x27;</span>: <span class="number">1</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#get the number of pages</span></span><br><span class="line">        xpath=<span class="string">&#x27;//*[@id=&quot;page_num&quot;]/text()&#x27;</span></span><br><span class="line">        page_num=int(self.uni_parser(cata_base_url,xpath,params=para,**kwargs))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#repeat get single catalogue&#x27;s urls</span></span><br><span class="line">        xpath=<span class="string">&#x27;//a/@href&#x27;</span><span class="comment">#link tag&#x27;s xpath</span></span><br><span class="line">        url_list=[]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,page_num+<span class="number">1</span>):</span><br><span class="line">            para[<span class="string">&#x27;pageIndex&#x27;</span>] = i</span><br><span class="line">            <span class="comment">#get single catalogue&#x27;s urls</span></span><br><span class="line">            urls=self.uni_parser(cata_base_url,xpath,params=para,**kwargs)</span><br><span class="line">            <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">                url_list.append(base_url+str(url))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> url_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content</span>(<span class="params">self,url,**kwargs</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        get content from the parameter &quot;url&quot;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        html=requests.post(url,**kwargs).text</span><br><span class="line">        soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        content=soup.find(<span class="string">&#x27;div&#x27;</span>,id=<span class="string">&#x27;content&#x27;</span>)</span><br><span class="line">        content=str(content)</span><br><span class="line">        <span class="keyword">return</span> content</span><br></pre></td></tr></table></figure>

<p>我把构造登录信息的部分放在了解析器中。并在登录中调用。</p>
<p>登录之后得到的 cookies 就在参数中传递。</p>
<h2 id="数据库类"><a href="#数据库类" class="headerlink" title="数据库类"></a>数据库类</h2><p>由于只打算存到数据库，所以并没有写一个“存档宝石类“，或许之后会写。</p>
<p>目前我只写了一个保存函数，以及自己封装的一个数据库类。</p>
<p>这个数据库类是<code>my_database.py</code>中的<code>MyDatabase</code>（应该不会撞名吧），目前只封装了 insert 函数，传入的参数有三个：数据库名，表名，装有记录的字典。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDatabase</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,*args,**kwargs</span>):</span></span><br><span class="line">        self.conn=pymysql.connect(*args,**kwargs)</span><br><span class="line">        self.cursor=self.conn.cursor()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span>(<span class="params">self,db,table,record_dict</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param db:name of database that you want to use</span></span><br><span class="line"><span class="string">        :param table:name of table that you want to use</span></span><br><span class="line"><span class="string">        :param record_dict:key for column,value for value</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment">#1.use the database</span></span><br><span class="line">        sql=<span class="string">&#x27;use &#123;&#125;&#x27;</span>.format(db)</span><br><span class="line">        self.cursor.execute(sql)</span><br><span class="line">        self.conn.commit()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#2.connect the sql commend</span></span><br><span class="line">        sql=<span class="string">&#x27;insert into &#123;&#125;(&#x27;</span>.format(table)</span><br><span class="line"></span><br><span class="line">        record_list=list(record_dict.items())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> record_list:</span><br><span class="line">            sql += str(r[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">if</span> r != record_list[<span class="number">-1</span>]:</span><br><span class="line">                sql += <span class="string">&#x27;,&#x27;</span></span><br><span class="line"></span><br><span class="line">        sql+=<span class="string">&#x27;) values(&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> record_list:</span><br><span class="line">            sql += <span class="string">&#x27;&quot;&#x27;</span></span><br><span class="line">            sql += str(r[<span class="number">1</span>])</span><br><span class="line">            sql += <span class="string">&#x27;&quot;&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> r != record_list[<span class="number">-1</span>]:</span><br><span class="line">                sql += <span class="string">&#x27;,&#x27;</span></span><br><span class="line">        sql+=<span class="string">&#x27;)&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#3.commit</span></span><br><span class="line">        self.cursor.execute(sql)</span><br><span class="line">        self.conn.commit()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.cursor.close()</span><br><span class="line">        self.conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    db_data=&#123;</span><br><span class="line">        <span class="string">&#x27;host&#x27;</span>:<span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;user&#x27;</span>:<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;passwd&#x27;</span>:<span class="string">&#x27;password&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;port&#x27;</span>:<span class="number">3306</span>,</span><br><span class="line">        <span class="string">&#x27;charset&#x27;</span>:<span class="string">&#x27;utf8&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    test_record=&#123;</span><br><span class="line">        <span class="string">&#x27;idnew_table&#x27;</span>:<span class="string">&#x27;233&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    mydb=MyDatabase(**db_data)</span><br><span class="line">    mydb.insert(<span class="string">&#x27;news&#x27;</span>,<span class="string">&#x27;new_table&#x27;</span>,test_record)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>封装之后用起来比较方便。</p>
<h3 id="save-函数"><a href="#save-函数" class="headerlink" title="save 函数"></a>save 函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span>(<span class="params">content,**save_params</span>):</span></span><br><span class="line">    mydb=MyDatabase(**save_params)</span><br><span class="line">    record=&#123;</span><br><span class="line">        <span class="string">&#x27;content&#x27;</span>:pymysql.escape_string(content)</span><br><span class="line">    &#125;</span><br><span class="line">    mydb.insert(<span class="string">&#x27;dbase&#x27;</span>,<span class="string">&#x27;bulletin&#x27;</span>,record)</span><br></pre></td></tr></table></figure>

<p>pymysql.escape_string()函数是用于将内容转义的，因为爬取的是 html 代码（就不解析那么细了，直接把那一块 html 代码全部存下来，打开的时候格式还不会乱），有些内容可能使组合成的 sql 语句无法执行。</p>
<h2 id="爬虫类"><a href="#爬虫类" class="headerlink" title="爬虫类"></a>爬虫类</h2><p>给构造函数传入特定的解析器和保存函数，然后调用 crawl 方法就可以让 spider 背着特制的 parser 去爬取网站内容啦~</p>
<p>登录函数和上次不太一样，做了一些修改，不过主要功能仍然是获取登录之后的 cookies 的。</p>
<p>简单说一下修改：我们学校网站登录之后会从登陆页面开始，经过三四次跳转之后才到达首页，期间获取到的 cookies 都需要保留，这样才能利用这些 cookies 来进入新闻公告页面。于是禁止重定向，手动获取下一个 url，得到这一站的 cookies 之后再手动跳转，直到跳转到首页。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,parser,save,**save_params</span>):</span></span><br><span class="line">        self.parser=parser<span class="comment">#parser is a object of class</span></span><br><span class="line">        self.save=save<span class="comment">#save is a function</span></span><br><span class="line">        self.save_params=save_params</span><br><span class="line">        self.cookies=<span class="literal">None</span></span><br><span class="line">        self.headers=&#123;</span><br><span class="line">            <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login</span>(<span class="params">self,login_url,home_page_url</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        login</span></span><br><span class="line"><span class="string">        :param login_url: the url you want to login</span></span><br><span class="line"><span class="string">        :param login_data_parser: a callback function to get the login_data you need when you login,return (login_data,response.cookies)</span></span><br><span class="line"><span class="string">        :param target_url: Used to determine if you have logged in successfully</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: response of login</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        login_data=<span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#get the login data</span></span><br><span class="line">        login_data,cookies=self.parser.login_data_parser(login_url)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#login without redirecting</span></span><br><span class="line">        response=requests.post(login_url,headers=self.headers,data=login_data,cookies=cookies,allow_redirects=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        cookies_num=<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span>(home_page_url!=<span class="literal">None</span> <span class="keyword">and</span> response.url!=home_page_url):<span class="comment">#if spider is not reach the target page</span></span><br><span class="line">            print(<span class="string">&#x27;[spider]: I am at the &quot;&#123;&#125;&quot; now&#x27;</span>.format(response.url))</span><br><span class="line">            print(<span class="string">&#x27;[spider]: I have got a cookie!Its content is that \n&quot;&#123;&#125;&quot;&#x27;</span>.format(response.cookies))</span><br><span class="line">            <span class="comment">#merge the two cookies</span></span><br><span class="line">            cookies=dict(cookies,**response.cookies)</span><br><span class="line">            cookies=requests.utils.cookiejar_from_dict(cookies)</span><br><span class="line">            cookies_num+=<span class="number">1</span></span><br><span class="line">            print(<span class="string">&#x27;[spider]: Now I have &#123;&#125; cookies!&#x27;</span>.format(cookies_num))</span><br><span class="line">            next_station=response.headers[<span class="string">&#x27;Location&#x27;</span>]</span><br><span class="line">            print(<span class="string">&#x27;[spider]: Then I will go to the page whose url is &quot;&#123;&#125;&quot;&#x27;</span>.format(next_station))</span><br><span class="line">            response=requests.post(next_station,headers=self.headers,cookies=cookies,allow_redirects=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        cookies=dict(cookies,**response.cookies)</span><br><span class="line">        cookies=requests.utils.cookiejar_from_dict(cookies)</span><br><span class="line">        cookies_num+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(home_page_url!=<span class="literal">None</span> <span class="keyword">and</span> response.url==home_page_url):</span><br><span class="line">            print(<span class="string">&quot;login successfully&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.cookies=cookies</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span>(<span class="params">self,login_url,home_page_url,catalogue_url</span>):</span></span><br><span class="line">        self.login(login_url,home_page_url)</span><br><span class="line">        url_list=self.parser.get_urls(catalogue_url,cookies=self.cookies,headers=self.headers)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">            content=self.parser.get_content(url,cookies=self.cookies,headers=self.headers)</span><br><span class="line">            self.save(content,**self.save_params)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h1 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h1><p>为了更好地展示结构，大部分内容都 pass 省略掉。想看具体代码可以去我 github 的<a target="_blank" rel="noopener" href="https://github.com/HaneChiri/Spider">spider 库</a></p>
<p>这个文件内首先创建了一个特定解析类，继承自通用解析类，再写了一个保存函数，准备好参数，最后爬取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> my_spider <span class="keyword">import</span> MySpider</span><br><span class="line"><span class="keyword">from</span> my_parser <span class="keyword">import</span> MyParser</span><br><span class="line"><span class="keyword">from</span> my_database <span class="keyword">import</span> MyDatabase</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">chdParser</span>(<span class="params">MyParser</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login_data_parser</span>(<span class="params">self,login_url</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        This parser is for chd</span></span><br><span class="line"><span class="string">        :param url: the url you want to login</span></span><br><span class="line"><span class="string">        :return (a dict with login data,cookies)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> login_data,response.cookies</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_urls</span>(<span class="params">self,catalogue_url,**kwargs</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        get all urls that needs to crawl.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment">#prepare</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#get page number</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#repeat get single catalogue&#x27;s urls</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,page_num+<span class="number">1</span>):</span><br><span class="line">            para[<span class="string">&#x27;pageIndex&#x27;</span>] = i</span><br><span class="line">            <span class="comment">#get single catalogue&#x27;s urls</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> url_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span>(<span class="params">content,**save_params</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    login_url=<span class="string">&quot;pass&quot;</span><span class="comment">#省略</span></span><br><span class="line">    home_page_url=<span class="string">&quot;pass&quot;</span></span><br><span class="line">    catalogue_url=<span class="string">&quot;pass&quot;</span></span><br><span class="line"></span><br><span class="line">    parser=chdParser()</span><br><span class="line">    save_params=&#123;</span><br><span class="line">        <span class="string">&#x27;host&#x27;</span>:<span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;user&#x27;</span>:<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;passwd&#x27;</span>:<span class="string">&#x27;password&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;port&#x27;</span>:<span class="number">3306</span>,</span><br><span class="line">        <span class="string">&#x27;charset&#x27;</span>:<span class="string">&#x27;utf8&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    sp=MySpider(parser,save,**save_params)</span><br><span class="line">    sp.crawl(login_url,home_page_url,catalogue_url)</span><br></pre></td></tr></table></figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>python爬虫学习笔记5爬虫类结构优化</p><p><a href="https://yxchangingself.xyz/posts/python_spider_note5optimization_of_the_spider_class/">https://yxchangingself.xyz/posts/python_spider_note5optimization_of_the_spider_class/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>憧憬少</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-04-21</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-04-21</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/spider/">spider</a><a class="link-muted mr-2" rel="tag" href="/tags/python/">python</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/java_game_FightFieldFrame/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">java基于AWT的对战小游戏</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/python_spider_note4optimization_of_the_login_function/"><span class="level-item">python爬虫学习笔记4模拟登录函数的优化</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">ChangingSelf</a><p class="is-size-7"><span>&copy; 2021 憧憬少</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/">湘ICP备2021000400号-1</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/live2d-widget/autoload.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>