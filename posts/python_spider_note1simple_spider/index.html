<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>python爬虫学习笔记1简易爬虫 - 憧憬少的个人博客</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="憧憬少的个人博客"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="憧憬少的个人博客"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="学了 python 语法之后在 b 站搜索练手的小项目，发现了这个视频：Python 实用练手小项目（超简单） 视频里面讲解了一个爬取图片网站图片的小爬虫。后面用到了我还没学的数据库，不过前面的部分是已经学了的，于是我就打算写一个不用数据库的，爬取某个盗版小说内容的爬虫。 声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处"><meta property="og:type" content="blog"><meta property="og:title" content="python爬虫学习笔记1简易爬虫"><meta property="og:url" content="https://yxchangingself.xyz/posts/python_spider_note1simple_spider/"><meta property="og:site_name" content="憧憬少的个人博客"><meta property="og:description" content="学了 python 语法之后在 b 站搜索练手的小项目，发现了这个视频：Python 实用练手小项目（超简单） 视频里面讲解了一个爬取图片网站图片的小爬虫。后面用到了我还没学的数据库，不过前面的部分是已经学了的，于是我就打算写一个不用数据库的，爬取某个盗版小说内容的爬虫。 声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://yxchangingself.xyz/img/og_image.png"><meta property="article:published_time" content="2019-02-08T10:59:12.000Z"><meta property="article:modified_time" content="2019-02-08T10:59:12.000Z"><meta property="article:author" content="憧憬少"><meta property="article:tag" content="spider"><meta property="article:tag" content="python"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yxchangingself.xyz/posts/python_spider_note1simple_spider/"},"headline":"憧憬少的个人博客","image":["https://yxchangingself.xyz/img/og_image.png"],"datePublished":"2019-02-08T10:59:12.000Z","dateModified":"2019-02-08T10:59:12.000Z","author":{"@type":"Person","name":"憧憬少"},"description":"学了 python 语法之后在 b 站搜索练手的小项目，发现了这个视频：Python 实用练手小项目（超简单） 视频里面讲解了一个爬取图片网站图片的小爬虫。后面用到了我还没学的数据库，不过前面的部分是已经学了的，于是我就打算写一个不用数据库的，爬取某个盗版小说内容的爬虫。 声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处"}</script><link rel="canonical" href="https://yxchangingself.xyz/posts/python_spider_note1simple_spider/"><link rel="alternate" href="/atom.xml" title="憧憬少的个人博客" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?74d1c5bd37e68cef3ecacf9c903ec5a5";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.0.2"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">ChangingSelf</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ChangingSelf/ChangingSelf.github.io"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-02-08T10:59:12.000Z" title="2019-02-08T10:59:12.000Z">2019-02-08</time>发表</span><span class="level-item"><time dateTime="2019-02-08T10:59:12.000Z" title="2019-02-08T10:59:12.000Z">2019-02-08</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span><span class="level-item">17 分钟读完 (大约2589个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">python爬虫学习笔记1简易爬虫</h1><div class="content"><p>学了 python 语法之后在 b 站搜索练手的小项目，发现了这个视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av24431072">Python 实用练手小项目（超简单）</a></p>
<p>视频里面讲解了一个爬取图片网站图片的小爬虫。后面用到了我还没学的数据库，不过前面的部分是已经学了的，于是我就打算写一个不用数据库的，爬取某个盗版小说内容的爬虫。</p>
<p><strong>声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处。</strong></p>
<a id="more"></a>

<h1 id="项目描述"><a href="#项目描述" class="headerlink" title="项目描述"></a>项目描述</h1><p>爬虫，在我理解中就是模拟人的浏览行为来获取网站上的信息的脚本，爬虫能得到的信息，一般情况下人也有权限可以得到。</p>
<p>盗版小说网站，不需要登录就可以看到小说内容，内容是写死在 html 文件里面的，通过右键菜单的<code>查看源代码</code>就能够查看到小说内容，很适合拿来练手。</p>
<p><strong>再次声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处。</strong></p>
<h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>爬虫的思路是向服务器发出请求，并收到服务器回复的数据，接着从获取的数据中取得想要的信息，保存在数据库中。</p>
<p>由于是小说，就直接保存在文本文件当中。</p>
<p>所以分为以下几步：</p>
<ol>
<li>发出请求</li>
<li>接收数据</li>
<li>提取信息</li>
<li>保存数据</li>
</ol>
<h1 id="编程原理"><a href="#编程原理" class="headerlink" title="编程原理"></a>编程原理</h1><h2 id="发出请求和接收数据"><a href="#发出请求和接收数据" class="headerlink" title="发出请求和接收数据"></a>发出请求和接收数据</h2><p>发出请求需要一个库，名字叫做<code>requests</code>，它是基于 python 自带的<code>urllib</code>库写的第三方库，差不多就是升级版的意思吧。</p>
<p>要注意是<code>requests</code>，不是<code>request</code>，结尾有个 s，确实存在一个不带 s 的库，注意区分。</p>
<p>可以使用下面的命令进行安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>

<p>pip 是 Python 包管理工具，总之有了这个玩意，你不用管它从哪里下载，在哪里安装，总之就告诉它要安装啥，它就帮你安排得明明白白的。以后会遇到很多这样的东西，比如 npm 啥的。</p>
<p>命令在 cmd 里面输就行了，如果电脑上没有这东西就百度一下怎么下载，一般来说安装了 python 应该就有了。</p>
<p>如果使用的是 pyCharm 这种 IDE，那就可以直接在代码 import 这个库，等库的名字变红再在旁边找安装按钮，很方便的。</p>
<p>这个库里面有个 get 函数，是采用 get 的方式（除此之外还有 post 方式，学 html 表单的时候应该有学到）来向服务器发出访问请求，并将获得的数据作为返回值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#省略代码</span></span><br><span class="line">r = requests.get(url)<span class="comment">#url是你要访问的网址</span></span><br><span class="line">print(r)<span class="comment">#如果输出是&lt;Response [200]&gt;，那么就是访问成功了</span></span><br></pre></td></tr></table></figure>

<p>此时返回变量是请求对象，要从中获取数据，就需要使用它的两个属性<code>text</code>和<code>content</code></p>
<p><code>r.text</code>是数据的 html 形式，<code>r.content</code>是字节流的形式。<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/0e4ca633c6a6">二者的区别</a></p>
<p>前者返回文本格式（即二进制格式经过编码后），后者返回二进制格式。后者一般用于图片的保存。</p>
<p>我们需要获取的是文本内容，因此需要前者。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html=r.text</span><br></pre></td></tr></table></figure>

<h2 id="提取信息"><a href="#提取信息" class="headerlink" title="提取信息"></a>提取信息</h2><p>我们打开笔趣阁（一个盗版小说网站）的一个<a target="_blank" rel="noopener" href="https://www.biquger.com/biquge/4911/">小说页面</a>，随便选一章点进去，查看源代码，发现小说的内容是放在一个<code>&lt;div&gt;</code>里面的：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span> <span class="attr">id</span>=<span class="string">&quot;booktext&quot;</span>&gt;</span></span><br><span class="line">  小说内容</span><br><span class="line">  <span class="tag">&lt;<span class="name">center</span>&gt;</span>翻页信息<span class="tag">&lt;/<span class="name">center</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其他章节也是如此，所以就可以利用这个规律将其提取出来，用的就是正则表达式。</p>
<h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>使用正则表达式需要使用一个内置的库<code>re</code>，根据上面的规律可以写出下面的正则表达式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">reg = <span class="string">r&#x27;&lt;div class=&quot;content&quot; id=&quot;booktext&quot;&gt;(.*?)&lt;center&gt;&#x27;</span><span class="comment">#正则表达式</span></span><br><span class="line">reg = re.compile(reg)<span class="comment">#将字符串转换为正则表达式对象，加快匹配速度</span></span><br><span class="line">content= re.findall(reg, html)<span class="comment">#返回一个列表，列表项为匹配到的内容</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> content==[]:<span class="comment">#未匹配到小说内容</span></span><br><span class="line">    print(<span class="string">&quot;获取失败！&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    content=str(content[<span class="number">0</span>])<span class="comment">#将列表转换为字符串</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/nomorewzx/p/4203829.html">re.compile()函数</a></p>
<h3 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h3><p>但是我写到这里的时候遇到了一个问题，就是获取到的内容是乱码。一看到乱码就应该想到是编码出了问题。</p>
<p>右键菜单查看网页编码，是<code>GBK</code>编码，需要转换编码。现在的情况是，网页利用<code>GBK</code>的编码来“加密”了小说文本，而我们需要用同样的方式来“解码”。需要用到<code>decode</code>函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html=r.content.decode(<span class="string">&quot;GBK&quot;</span>, <span class="string">&quot;ignore&quot;</span>)<span class="comment">#转换编码</span></span><br></pre></td></tr></table></figure>

<p>将获得的二进制数据按照网页原本的编码<code>GBK</code>来解码，就能获取到正确的内容了。</p>
<h3 id="去除分隔字符"><a href="#去除分隔字符" class="headerlink" title="去除分隔字符"></a>去除分隔字符</h3><p>此时提取到的内容还有这很多 HTML 实体，比如<code>&amp;nbsp;</code>和<code>&lt;br /&gt;</code>，注意到它们的分布也有规律：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span> <span class="attr">id</span>=<span class="string">&quot;booktext&quot;</span>&gt;</span></span><br><span class="line">  <span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span>小说内容<span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span>小说内容<span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span>……省略……<span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span>大雪落下，悄然覆盖着这一切。<span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">center</span>&gt;</span><span class="tag">&lt;/<span class="name">center</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>除了开头和结尾之外，都是以<code>&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;</code>进行分隔的。</p>
<p>可以利用<code>split()</code>函数将其分割之后重新组合，</p>
<p>也可以使用字符串的替换函数<code>replace()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">content=content.replace(<span class="string">&quot;&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;</span>,<span class="string">&quot;\n\n    &quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h2><p>保存在文本文件中就 ok 了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(fileName,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fout:<span class="comment">#fileName为保存路径加文件名</span></span><br><span class="line">    fout.write(<span class="string">&#x27;\n\n=====================\n\n&#x27;</span> + fileName + <span class="string">&#x27;\n\n=====================\n\n&#x27;</span>)</span><br><span class="line">    fout.write(content)</span><br></pre></td></tr></table></figure>

<h1 id="获取单章节内容代码"><a href="#获取单章节内容代码" class="headerlink" title="获取单章节内容代码"></a>获取单章节内容代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNovelByURL</span>(<span class="params">url,fileName</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    :param url: 网页的url</span></span><br><span class="line"><span class="string">    :param fileName: 保存数据的文件的名字</span></span><br><span class="line"><span class="string">    :return: -1为失败，0为成功</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#筛选文件名内非法字符</span></span><br><span class="line">    <span class="comment">#调试的时候前面几百章都行突然一章不行，发现是因为章节名字里面有非法字符</span></span><br><span class="line">    reg=<span class="string">r&#x27;[\/:*?&quot;&lt;&gt;|]&#x27;</span></span><br><span class="line">    fileName=re.sub(reg,<span class="string">&quot;&quot;</span>,fileName)<span class="comment">#利用正则表达式去除非法字符</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取网页</span></span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    html = r.content</span><br><span class="line">    html = html.decode(<span class="string">&quot;GBK&quot;</span>, <span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">    <span class="comment"># 获取网页中小说内容</span></span><br><span class="line">    reg = <span class="string">&#x27;&lt;div class=&quot;content&quot; id=&quot;booktext&quot;&gt;\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(.*?)&lt;br /&gt;\n&lt;center&gt;&#x27;</span></span><br><span class="line">    reg = re.compile(reg)<span class="comment">#预编译</span></span><br><span class="line">    content = re.findall(reg, html)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存到文件</span></span><br><span class="line">    <span class="keyword">if</span> content==[]:</span><br><span class="line">        print(<span class="string">&quot;获取失败！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        content=str(content[<span class="number">0</span>])<span class="comment">#转换为字符串</span></span><br><span class="line">        content=content.replace(<span class="string">&quot;&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;</span>,<span class="string">&quot;\n\n    &quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(fileName,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fout:</span><br><span class="line">            fout.write(<span class="string">&#x27;\n\n=====================\n\n&#x27;</span> + fileName + <span class="string">&#x27;\n\n=====================\n\n&#x27;</span>)</span><br><span class="line">            fout.write(content)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">&quot;成功爬取（&#123;&#125;），存储在&#123;&#125;&quot;</span>.format(url,os.path.dirname(__file__)+<span class="string">&#x27;/&#x27;</span>+fileName))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h1 id="获取全部章节内容的思路"><a href="#获取全部章节内容的思路" class="headerlink" title="获取全部章节内容的思路"></a>获取全部章节内容的思路</h1><p>盗版小说网站章节的 url 有个规律，就是 url 的最后一串数字是连续的，照这个规律，知道第一章的 url，就可以获得后续章节的 url。于是我着手写这么个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNovelByIndexInc</span>(<span class="params">url, number=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    此函数用于通过已知的起始url来获取仅有尾部索引不同且连续的一系列网页内的小说，</span></span><br><span class="line"><span class="string">    不连续时会跳过获取失败的网址，不过有可能连续几千个网址都是无效网址，所以慎用此函数</span></span><br><span class="line"><span class="string">    或改用getNovelByContentPage函数</span></span><br><span class="line"><span class="string">    :param url:起始章节的url</span></span><br><span class="line"><span class="string">    :param number: 要获取的章节数</span></span><br><span class="line"><span class="string">    :return:无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>从我写的注释里面也可以看出，我失败了。</p>
<p>一开始的一百多章还是没什么问题的，只有偶尔几个网址是无效网址，但是后面爬取的时候等了十分钟还没爬取到下一章，一直输出“无效网址”，我查看了那断片的两个连续章节之后才发现，最后的一串数字差了几万。<del>不会是因为作者断更吧！</del></p>
<p>这种方式不可靠，还是换一种方式。</p>
<p>那么要如何可以改进呢？</p>
<p>我写了另一个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNovelByContentPage</span>(<span class="params">url,path=<span class="string">&#x27;novel&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    通过获取目录页面链接与标题，进一步调用获取已知链接页面的函数来保存页面内容</span></span><br><span class="line"><span class="string">    :param url: 书籍目录页面</span></span><br><span class="line"><span class="string">    :param path:保存路径，默认为同目录下的novel文件夹</span></span><br><span class="line"><span class="string">    :return:-1为失败，0为成功</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>网站的书籍页面会有一个目录，而目录下隐藏的就是我需要的全部章节的链接呀！</p>
<p>这个函数用到的内容上面也都讲到了，就直接放代码吧。</p>
<h1 id="获取全部章节内容的代码"><a href="#获取全部章节内容的代码" class="headerlink" title="获取全部章节内容的代码"></a>获取全部章节内容的代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNovelByContentPage</span>(<span class="params">url,path=<span class="string">&#x27;novel&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    通过获取目录页面链接与标题，进一步调用获取已知链接页面的函数来保存页面内容</span></span><br><span class="line"><span class="string">    :param url: 书籍目录页面</span></span><br><span class="line"><span class="string">    :param path:保存路径，默认为同目录下的novel文件夹</span></span><br><span class="line"><span class="string">    :return:-1为失败，0为成功</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取网页</span></span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    html = r.content<span class="comment">#获取网页二进制内容</span></span><br><span class="line">    html = html.decode(<span class="string">&quot;GBK&quot;</span>, <span class="string">&quot;ignore&quot;</span>)<span class="comment">#转换编码</span></span><br><span class="line">    <span class="comment"># 获取网页中小说内容</span></span><br><span class="line">    reg = <span class="string">&#x27;&lt;dd&gt;&lt;a href=&quot;(.*?)&quot; title=&quot;(.*?)&quot;&gt;.*?&lt;/a&gt;&lt;/dd&gt;&#x27;</span><span class="comment">#获取链接和标题</span></span><br><span class="line">    reg = re.compile(reg, re.S)</span><br><span class="line">    info= re.findall(reg, html)</span><br><span class="line">    <span class="comment">#由于是分组匹配，得到的列表中每个元素的[0]是链接，[1]是标题</span></span><br><span class="line">    <span class="comment">#保存到文件</span></span><br><span class="line">    <span class="keyword">if</span> info==[]:</span><br><span class="line">        print(<span class="string">&quot;获取章节目录失败&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):<span class="comment">#检查目录是否已经存在</span></span><br><span class="line">            os.makedirs(path)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> info:</span><br><span class="line">            realpath=path+<span class="string">&quot;\\&quot;</span>+i[<span class="number">1</span>]+<span class="string">&quot;.txt&quot;</span></span><br><span class="line">            <span class="keyword">if</span> os.path.exists(realpath):<span class="comment">#避免重复爬取</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                getNovelByURL(i[<span class="number">0</span>],realpath)<span class="comment">#调用获取单页面内容的函数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>python爬虫学习笔记1简易爬虫</p><p><a href="https://yxchangingself.xyz/posts/python_spider_note1simple_spider/">https://yxchangingself.xyz/posts/python_spider_note1simple_spider/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>憧憬少</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-02-08</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-02-08</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/spider/">spider</a><a class="link-muted mr-2" rel="tag" href="/tags/python/">python</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/notepadpp_file_association/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">notepad++添加文件关联</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/hexo_visit_count/"><span class="level-item">为博客增加访问统计</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "2f073166ee4f73cac6e348d6fe94374a",
            repo: "blog-comments",
            owner: "ChangingSelf",
            clientID: "2c2d9b5607027ef5684f",
            clientSecret: "b974e75a7b4f1d80dee5e2ada5abad43526a05fc",
            admin: ["ChangingSelf"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#项目描述"><span class="level-left"><span class="level-item">1</span><span class="level-item">项目描述</span></span></a></li><li><a class="level is-mobile" href="#思路"><span class="level-left"><span class="level-item">2</span><span class="level-item">思路</span></span></a></li><li><a class="level is-mobile" href="#编程原理"><span class="level-left"><span class="level-item">3</span><span class="level-item">编程原理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#发出请求和接收数据"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">发出请求和接收数据</span></span></a></li><li><a class="level is-mobile" href="#提取信息"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">提取信息</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#正则表达式"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">正则表达式</span></span></a></li><li><a class="level is-mobile" href="#编码转换"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">编码转换</span></span></a></li><li><a class="level is-mobile" href="#去除分隔字符"><span class="level-left"><span class="level-item">3.2.3</span><span class="level-item">去除分隔字符</span></span></a></li></ul></li><li><a class="level is-mobile" href="#保存数据"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">保存数据</span></span></a></li></ul></li><li><a class="level is-mobile" href="#获取单章节内容代码"><span class="level-left"><span class="level-item">4</span><span class="level-item">获取单章节内容代码</span></span></a></li><li><a class="level is-mobile" href="#获取全部章节内容的思路"><span class="level-left"><span class="level-item">5</span><span class="level-item">获取全部章节内容的思路</span></span></a></li><li><a class="level is-mobile" href="#获取全部章节内容的代码"><span class="level-left"><span class="level-item">6</span><span class="level-item">获取全部章节内容的代码</span></span></a></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">ChangingSelf</a><p class="is-size-7"><span>&copy; 2020 憧憬少</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/live2d-widget/autoload.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>