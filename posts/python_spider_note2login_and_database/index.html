<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>python爬虫学习笔记2模拟登录与数据库 - 编程技术笔记</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="编程技术笔记"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="编程技术笔记"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="为了加入学校里面一个技术小组，我接受了写一个爬取学校网站通知公告的任务。这个任务比以前写的爬虫更难的地方在于，需要模拟登录才能获得页面，以及将得到的数据存入数据库。 本文按照日期来记录我完成任务的过程，然后再整理一遍全部代码。读者可以通过侧栏目录跳转阅读。不介绍库的安装。 传送门：爬虫学习笔记 1"><meta property="og:type" content="blog"><meta property="og:title" content="python爬虫学习笔记2模拟登录与数据库"><meta property="og:url" content="https://yxchangingself.xyz/posts/python_spider_note2login_and_database/"><meta property="og:site_name" content="编程技术笔记"><meta property="og:description" content="为了加入学校里面一个技术小组，我接受了写一个爬取学校网站通知公告的任务。这个任务比以前写的爬虫更难的地方在于，需要模拟登录才能获得页面，以及将得到的数据存入数据库。 本文按照日期来记录我完成任务的过程，然后再整理一遍全部代码。读者可以通过侧栏目录跳转阅读。不介绍库的安装。 传送门：爬虫学习笔记 1"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/HaneChiri/PicBed/master/blog_images/spider_f12_form_data.png"><meta property="article:published_time" content="2019-03-09T05:30:43.000Z"><meta property="article:modified_time" content="2019-03-09T05:30:43.000Z"><meta property="article:author" content="憧憬少"><meta property="article:tag" content="python"><meta property="article:tag" content="爬虫"><meta property="article:tag" content="mysql"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://raw.githubusercontent.com/HaneChiri/PicBed/master/blog_images/spider_f12_form_data.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yxchangingself.xyz/posts/python_spider_note2login_and_database/"},"headline":"python爬虫学习笔记2模拟登录与数据库","image":["https://raw.githubusercontent.com/HaneChiri/PicBed/master/blog_images/spider_f12_form_data.png"],"datePublished":"2019-03-09T05:30:43.000Z","dateModified":"2019-03-09T05:30:43.000Z","author":{"@type":"Person","name":"憧憬少"},"publisher":{"@type":"Organization","name":"编程技术笔记","logo":{"@type":"ImageObject","url":{"text":"ChangingSelf"}}},"description":"为了加入学校里面一个技术小组，我接受了写一个爬取学校网站通知公告的任务。这个任务比以前写的爬虫更难的地方在于，需要模拟登录才能获得页面，以及将得到的数据存入数据库。 本文按照日期来记录我完成任务的过程，然后再整理一遍全部代码。读者可以通过侧栏目录跳转阅读。不介绍库的安装。 传送门：爬虫学习笔记 1"}</script><link rel="canonical" href="https://yxchangingself.xyz/posts/python_spider_note2login_and_database/"><link rel="alternate" href="/atom.xml" title="编程技术笔记" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?74d1c5bd37e68cef3ecacf9c903ec5a5";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body class="is-2-column"><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">ChangingSelf</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/catalogue">目录</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/friends">友链</a><a class="navbar-item" href="/about">关于</a><a class="navbar-item" href="/statistics">统计</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ChangingSelf/ChangingSelf.github.io"><i class="fab fa-github"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-03-09T05:30:43.000Z" title="2019/3/9 13:30:43">2019-03-09</time>发表</span><span class="level-item"><time dateTime="2019-03-09T05:30:43.000Z" title="2019/3/9 13:30:43">2019-03-09</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/">项目总结</a></span><span class="level-item">1 小时读完 (大约7563个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">python爬虫学习笔记2模拟登录与数据库</h1><div class="content"><p>为了加入学校里面一个技术小组，我接受了写一个爬取学校网站通知公告的任务。这个任务比以前写的爬虫更难的地方在于，需要模拟登录才能获得页面，以及将得到的数据存入数据库。</p>
<p>本文按照日期来记录我完成任务的过程，然后再整理一遍全部代码。读者可以通过侧栏目录跳转阅读。不介绍库的安装。</p>
<p>传送门：<a href="https://yxchangingself.xyz/posts/python_spider_note1simple_spider/#more">爬虫学习笔记 1</a></p>
<span id="more"></span>

<h1 id="转载声明"><a href="#转载声明" class="headerlink" title="转载声明"></a>转载声明</h1><p><strong>关于参考链接：</strong>本文用到的其他博客的链接都以（我自己对内容的概括或者文章原标题-来源网站-作者名）的格式给出，关于作者名，只有博客作者自己明确声明为“原创”，我才会加上作者名。引用的文章内容我会放在来源链接的下方。</p>
<p><strong>关于本文：</strong>我发一下链接都注明出处了，如果想转载，也请这样做。作者<strong>憧憬少</strong>，链接的话看浏览器地址栏。</p>
<h1 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h1><p>爬取信息门户新闻并且存入数据库。</p>
<p>首先分解任务：</p>
<ol>
<li>实现爬取综合新闻页面的公开新闻存入 markdown 文件中(190303 完成)</li>
<li>将数据存到数据库（190304 完成）</li>
<li>学习模拟登录（190305 到 190307 完成）</li>
<li>爬取信息门户新闻（190308 完成）</li>
<li>（进阶）将代码进行封装、优化（目前未封装）</li>
<li>（进阶）动态更新（目前未着手）</li>
</ol>
<h1 id="过程记录"><a href="#过程记录" class="headerlink" title="过程记录"></a>过程记录</h1><h2 id="190303-周日"><a href="#190303-周日" class="headerlink" title="190303 周日"></a>190303 周日</h2><h3 id="练习爬取公开页面"><a href="#练习爬取公开页面" class="headerlink" title="练习爬取公开页面"></a>练习爬取公开页面</h3><p>我的<a href="https://yxchangingself.xyz/posts/python_spider_note1simple_spider/#more">第一个爬虫</a>是在 2 月多的时候在家写的，那个只是个简单的爬虫，目标是公开的页面，不需要模拟登录，也不需要存储到数据库，直接存到 txt 文件中。</p>
<p>先爬取学校官网的综合新闻页面复习一下。</p>
<p>首先讲一下我的思路：</p>
<p>由于新闻和公告页面通常是有一个目录页面的，也就是包含子页面的链接，在目录的子页面内才是正文内容。</p>
<p>假设这一页目录有三个新闻，就像是下面：</p>
<ul>
<li>新闻目录<ul>
<li>新闻一</li>
<li>新闻二</li>
<li>新闻三</li>
<li>点击查看下一页</li>
</ul>
</li>
</ul>
<p>这样的结构。</p>
<p>如果要写一个爬虫函数来爬取所有新闻页面，那么就要从目录着手。目录中含有前往别的新闻页面的链接，所以可以在目录页获取本页所有新闻的链接，遍历所有链接并提取新闻内容。</p>
<p>至于翻页也可以这样做到，“下一页”按钮也是一个链接，可以通过这个链接获取到下一页的内容。翻页部分原理比较简单，我是先攻克其他难关，把它留到最后写的。</p>
<h4 id="提取单页面新闻"><a href="#提取单页面新闻" class="headerlink" title="提取单页面新闻"></a>提取单页面新闻</h4><p>首先是提取单个页面的新闻。向目标 url 发出访问请求：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getNews</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取页面的新闻与图片并存储为markdown文件</span></span><br><span class="line"><span class="string">    :param url: 要爬取的目标网页url</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#发送请求</span></span><br><span class="line">    r=requests.get(url)<span class="comment">#r为response对象</span></span><br><span class="line">    html=r.text<span class="comment">#r.text是请求的网页的内容</span></span><br><span class="line">    <span class="built_in">print</span>(html)</span><br></pre></td></tr></table></figure>

<h5 id="编码问题"><a href="#编码问题" class="headerlink" title="编码问题"></a>编码问题</h5><p>这里遇到了第一个问题，提取到的页面有乱码。</p>
<p>解决方法：先获取响应对象的二进制响应内容，然后将其编码为 utf8</p>
<p><strong>参考链接：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/t8116189520/article/details/78930009">python 中 response.text 与 response.content 的区别-CSDN</a></li>
</ul>
<blockquote>
<p>requests.content 返回的是二进制响应内容</p>
<p>而 requests.text 则是根据网页的响应来猜测编码</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/gavin-num1/p/5170247.html">UNICODE,GBK,UTF-8 区别（一个比较好的编码的教程，便于理解编码的概念）-博客园</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/w_linux/article/details/78370218">Python 解决抓取内容乱码问题（decode 和 encode 解码）-CSDN-浅然_</a></li>
</ul>
<blockquote>
<p>字符串在 Python 内部的表示是 unicode 编码，在做编码转换时，通常需要以 unicode 作为中间编码，即先将其他编码的字符串解码（decode）成 unicode，再从 unicode 编码（encode）成另一种编码。</p>
<p>decode 的作用是将其他编码的字符串转换成 unicode 编码，如 str1.decode(‘gb2312’)，表示将 gb2312 编码的字符串 str1 转换成 unicode 编码。</p>
<p>encode 的作用是将 unicode 编码转换成其他编码的字符串，如 str2.encode(‘utf-8’)，表示将 unicode 编码的字符串 str2 转换成 utf-8 编码。</p>
</blockquote>
<p>修改代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#发送请求</span></span><br><span class="line">r=requests.get(url)</span><br><span class="line">html=r.content<span class="comment">#获取二进制字节流</span></span><br><span class="line">html=html.decode(<span class="string">&#x27;utf-8&#x27;</span>)<span class="comment">#转换为utf8编码（该网页使用的是utf8编码）</span></span><br></pre></td></tr></table></figure>

<h5 id="解析网页（bs4）"><a href="#解析网页（bs4）" class="headerlink" title="解析网页（bs4）"></a>解析网页（bs4）</h5><p>一开始我和之前一样使用正则表达式来提取，但是不够熟悉，总是写不出匹配的上的正则表达式。还是使用另一个东西——BeautifulSoup 库</p>
<p>具体如何使用请查看其他教程，本文只说我自己用到的部分。</p>
<p><strong>参考链接：</strong></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42331423/article/details/80796683">Python 爬虫常用的几种数据提取方式-CSDN-凯里潇</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av18202461?p=11">零基础入门 python3 爬虫-bilibili</a>（里面的视频 p11）</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41686130/article/details/79856474">beautifulsoup（基本选择器，标准选择器，css 选择器）-CSDN-Halosec_Wei</a>（基本上是上面一个 b 站链接的文字版，不知道是不是同一个人）</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jb51.net/article/65287.htm">beautifulsoup 详细教程-脚本之家</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/kikaylee/article/details/56841789">beautifulsoup 基本用法总结-CSDN-kikay</a></p>
</li>
</ul>
<blockquote>
<p>BeautifulSoup 是 Python 的一个库，最主要的功能就是从网页爬取我们需要的数据。BeautifulSoup 将 html 解析为对象进行处理，全部页面转变为字典或者数组，相对于正则表达式的方式，可以大大简化处理过程。</p>
</blockquote>
<p>我目前的理解是，这个 BeautifulSoup 库需要用到其他 html 解析库，可以使用 python 自带的，也可以安装第三方库，其他的库就像功能扩展插件一样，没有的话它自己也能解析。我安装了名为 lxml 的解析库。</p>
<p>查看源代码，找到网页中有关新闻的代码，手动将其格式化之后如下（内容不重要，省略）：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">class</span>=<span class="string">&quot;arti-title&quot;</span>&gt;</span>标题省略<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;arti-metas&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;arti-update&quot;</span>&gt;</span>发布时间：2019-01-23<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;arti-update1&quot;</span>&gt;</span>作者：xx<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;arti-update2&quot;</span>&gt;</span>来源：xxx<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;entry&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">article</span> <span class="attr">class</span>=<span class="string">&quot;read&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;content&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;wp_articlecontent&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>新闻前言省略<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span><span class="tag">&lt;<span class="name">br</span> /&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>新闻内容省略<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">img</span></span></span><br><span class="line"><span class="tag">            <span class="attr">width</span>=<span class="string">&quot;556&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">height</span>=<span class="string">&quot;320&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">align</span>=<span class="string">&quot;bottom&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">src</span>=<span class="string">&quot;url省略&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">border</span>=<span class="string">&quot;0&quot;</span></span></span><br><span class="line"><span class="tag">          /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">&quot;text-align:right;&quot;</span>&gt;</span>（审稿：xx <span class="symbol">&amp;nbsp;</span>网络编辑：xx）<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">article</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>接着上面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解析html</span></span><br><span class="line">soup=BeautifulSoup(html,<span class="string">&quot;lxml&quot;</span>)<span class="comment">#返回已解析的对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取标题</span></span><br><span class="line">title=soup.find(<span class="string">&#x27;h1&#x27;</span>,class_=<span class="string">&#x27;arti-title&#x27;</span>).string</span><br><span class="line"><span class="comment">#获取时间</span></span><br><span class="line">update=soup.find(<span class="string">&#x27;span&#x27;</span>,class_=<span class="string">&#x27;arti-update&#x27;</span>).string</span><br><span class="line"><span class="comment">#获取正文标签</span></span><br><span class="line">content=soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;wp_articlecontent&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="提取图片"><a href="#提取图片" class="headerlink" title="提取图片"></a>提取图片</h5><p>我打算将新闻保存到 markdown 文件中，提取新闻中的图片的链接的地址，这样在 md 文件中就能显示出图片了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取图片链接</span></span><br><span class="line">base=<span class="string">&#x27;学校官网url，用于和img标签中的相对地址拼接成绝对地址&#x27;</span></span><br><span class="line">imgsTag=content.find_all(<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line">imgsUrl=[]</span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> imgsTag:</span><br><span class="line">    imgsUrl.append(base+img[<span class="string">&#x27;src&#x27;</span>])<span class="comment">#拼接成完整的url</span></span><br><span class="line">    img.extract()<span class="comment">#删除图片标签</span></span><br></pre></td></tr></table></figure>

<h5 id="删除多余标签"><a href="#删除多余标签" class="headerlink" title="删除多余标签"></a>删除多余标签</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除多余标签</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> content.find_all(<span class="string">&#x27;p&#x27;</span>,&#123;<span class="string">&#x27;style&#x27;</span>:<span class="string">&quot;text-align:center;&quot;</span>&#125;):</span><br><span class="line">    p.extract()</span><br><span class="line">p=content.find(<span class="string">&#x27;p&#x27;</span>, &#123;<span class="string">&#x27;style&#x27;</span>: <span class="string">&quot;text-align:right;&quot;</span>&#125;)</span><br><span class="line"><span class="keyword">if</span>(p!=<span class="literal">None</span>):</span><br><span class="line">    p.extract()</span><br></pre></td></tr></table></figure>

<h5 id="保存到文件"><a href="#保存到文件" class="headerlink" title="保存到文件"></a>保存到文件</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拼接成字符串</span></span><br><span class="line"><span class="comment">#后来知道这样的提取方式其实不能完全提取到所有内容</span></span><br><span class="line">fileContent=<span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> content.contents:<span class="comment">#遍历正文内容的所有子标签</span></span><br><span class="line">    <span class="keyword">if</span>(i.string!=<span class="literal">None</span>):<span class="comment">#如果子标签里面有内容</span></span><br><span class="line">        <span class="comment">#print(i.string)#调试</span></span><br><span class="line">        fileContent+=i.string<span class="comment">#基本只剩下p标签了</span></span><br><span class="line">        fileContent+=<span class="string">&#x27;\n\n&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存到md文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data.md&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fout:</span><br><span class="line">    fout.write(fileContent)</span><br></pre></td></tr></table></figure>

<h5 id="代码总览"><a href="#代码总览" class="headerlink" title="代码总览"></a>代码总览</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup<span class="comment">#第4个版本改名bs4而不是全名那么长了</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getNews</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取页面的新闻与图片并存储为markdown文件</span></span><br><span class="line"><span class="string">    :param url: 要爬取的目标网页url</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#发出请求</span></span><br><span class="line">    r=requests.get(url)</span><br><span class="line">    html=r.content</span><br><span class="line">    html=html.decode(<span class="string">&#x27;utf-8&#x27;</span>)<span class="comment">#转换编码</span></span><br><span class="line">    <span class="comment">#解析html</span></span><br><span class="line">    soup=BeautifulSoup(html,<span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    content=soup.article</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取标题</span></span><br><span class="line">    title=soup.find(<span class="string">&#x27;h1&#x27;</span>,class_=<span class="string">&#x27;arti-title&#x27;</span>).string</span><br><span class="line">    <span class="comment">#获取时间</span></span><br><span class="line">    update=soup.find(<span class="string">&#x27;span&#x27;</span>,class_=<span class="string">&#x27;arti-update&#x27;</span>).string</span><br><span class="line">    <span class="comment">#获取正文</span></span><br><span class="line">    content=soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;wp_articlecontent&#x27;</span>)</span><br><span class="line">    <span class="comment">#获取图片链接</span></span><br><span class="line">    base=<span class="string">&#x27;http://xxxxx.xxx&#x27;</span><span class="comment">#学校官网url，用于和img标签中的相对地址拼接成绝对地址</span></span><br><span class="line">    imgsTag=content.find_all(<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line">    imgsUrl=[]</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> imgsTag:</span><br><span class="line">        imgsUrl.append(base+img[<span class="string">&#x27;src&#x27;</span>])<span class="comment">#拼接成完整的url</span></span><br><span class="line">        img.extract()<span class="comment">#删除图片标签</span></span><br><span class="line">    <span class="comment">#删除多余标签</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> content.find_all(<span class="string">&#x27;p&#x27;</span>,&#123;<span class="string">&#x27;style&#x27;</span>:<span class="string">&quot;text-align:center;&quot;</span>&#125;):</span><br><span class="line">        p.extract()</span><br><span class="line">    p=content.find(<span class="string">&#x27;p&#x27;</span>, &#123;<span class="string">&#x27;style&#x27;</span>: <span class="string">&quot;text-align:right;&quot;</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span>(p!=<span class="literal">None</span>):</span><br><span class="line">        p.extract()</span><br><span class="line">    <span class="comment"># 拼接成字符串</span></span><br><span class="line">    fileContent=<span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> content.contents:</span><br><span class="line">        <span class="keyword">if</span>(i.string!=<span class="literal">None</span>):</span><br><span class="line">            <span class="comment">#print(i.string)#调试</span></span><br><span class="line">            fileContent+=i.string</span><br><span class="line">            fileContent+=<span class="string">&#x27;\n\n&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data.md&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fout:</span><br><span class="line">        fout.write(fileContent)</span><br></pre></td></tr></table></figure>

<h4 id="提取多页面新闻"><a href="#提取多页面新闻" class="headerlink" title="提取多页面新闻"></a>提取多页面新闻</h4><p>原理在上面说了，提取完单页基本上就完成了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getNewsContents</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    爬取目录页面链接到的页面</span></span><br><span class="line"><span class="string">    :param url: 新闻目录页面的url</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#获取网页内容</span></span><br><span class="line">    r=requests.get(url)<span class="comment">#以get方式访问</span></span><br><span class="line">    html=r.content</span><br><span class="line">    html=html.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment">#获取每篇新闻的链接</span></span><br><span class="line">    base=<span class="string">&#x27;http://xxxxx.xxx&#x27;</span><span class="comment">#学校官网url，用于和相对地址拼接成绝对地址</span></span><br><span class="line">    soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> page_url <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;a&#x27;</span>,class_=<span class="string">&#x27;column-news-item&#x27;</span>):</span><br><span class="line">        page_url=base+<span class="string">&#x27;/&#x27;</span>+page_url[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(page_url)</span><br><span class="line">        getNews(page_url)<span class="comment">#调用提取单页函数</span></span><br></pre></td></tr></table></figure>

<h3 id="day1-进度"><a href="#day1-进度" class="headerlink" title="day1 进度"></a>day1 进度</h3><ol>
<li>实现爬取长安大学综合新闻页面的公开新闻存入 markdown 文件中</li>
<li>复习了 requests 库的使用</li>
<li>学习了 BeautifulSoup4 库的基本使用</li>
</ol>
<h2 id="190304-周一"><a href="#190304-周一" class="headerlink" title="190304 周一"></a>190304 周一</h2><p>这一天主要是将前一天爬取的数据存入数据库。</p>
<h3 id="将数据存入数据库"><a href="#将数据存入数据库" class="headerlink" title="将数据存入数据库"></a>将数据存入数据库</h3><h4 id="安装-MySQL-数据库"><a href="#安装-MySQL-数据库" class="headerlink" title="安装 MySQL 数据库"></a>安装 MySQL 数据库</h4><p>参考链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av18202461/?p=4">零基础入门 python3 爬虫-bilibili</a>（里面的视频 p4）</li>
</ul>
<h4 id="使用-MySQL-Workbench"><a href="#使用-MySQL-Workbench" class="headerlink" title="使用 MySQL Workbench"></a>使用 MySQL Workbench</h4><p>MySQL Workbench 是一个可视化工具，安装 MySQL 的时候自带（我安装的是最新版的），在安装目录找到它的 exe 然后加个快捷方式在桌面，可以方便地查看数据和执行 SQL 查询指令，具体使用方法可以问度娘。我现在也不是很会。</p>
<p>我创建的数据库名为 news，里面创建了一个数据表 chdnews。</p>
<h4 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h4><p>和大多数数据库一样，MySQL 是 C&#x2F;S 模式的，也就是客户端（client）&#x2F;服务端（server）模式的。数据库有可能在远程服务器上。想要使用数据库，就需要连接到数据库。</p>
<p>python 中要使用数据库需要一个 pymysql 库。</p>
<p>下面是连接的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="comment">#连接数据库</span></span><br><span class="line">db = pymysql.connect(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, port=<span class="number">3306</span>, user=<span class="string">&#x27;root&#x27;</span>, passwd=<span class="string">&#x27;root&#x27;</span>, db=<span class="string">&#x27;news&#x27;</span>, charset=<span class="string">&#x27;utf8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这个连接函数看参数名就可以看出含义了。</p>
<ul>
<li>host：主机 ip，127.0.0.1 是回传地址，指本机。也就是连接本电脑的 MySQL 的意思</li>
<li>port：端口号，用来和 ip 一起指定需要使用数据库的软件。在安装的时候会让你设置，默认 3306</li>
<li>user&amp;passwd：用户名和密码，在安装的时候已经设置好了</li>
<li>db：你要连接的数据库的名字。一台电脑上可以有很多数据库，数据库里面可以有很多数据表。</li>
<li>charset：字符编码</li>
</ul>
<h4 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h4><p>接着可以准备一个游标，游标大概是一个用于存储结果集开头地址的指针吧，我是这么理解的。在我学了更多数据库知识后可能会更新这一部分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建游标</span></span><br><span class="line">cursor = db.cursor()</span><br></pre></td></tr></table></figure>

<p>接着执行 SQL 的插入语句：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#插入</span></span><br><span class="line">cursor.execute(<span class="string">&quot;insert into chdnews(`title`,`article`) values(&#x27;&#123;0&#125;&#x27;,&#x27;&#123;1&#125;&#x27;)&quot;</span>.<span class="built_in">format</span>(title,fileContent))<span class="comment">#此处变量为上文代码中的变量</span></span><br></pre></td></tr></table></figure>

<p>这里的 SQL 语句是这样的：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> 数据表名(字段名<span class="number">1</span>，字段名<span class="number">2</span>) <span class="keyword">values</span>(值<span class="number">1</span>，值<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>后面的<code>format</code>函数是 python 的格式化函数，将变量的值加入到字符串中对应位置。</p>
<p>最后提交：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#提交更改</span></span><br><span class="line">db.commit()</span><br></pre></td></tr></table></figure>

<p>接着打开 workbench，就会发现已经存入数据库了。（你得把代码放在上面提取单页新闻的函数那里，放在保存到文件的那部分代码那儿）</p>
<h3 id="day2-进度"><a href="#day2-进度" class="headerlink" title="day2 进度"></a>day2 进度</h3><ol>
<li>下载并安装 MySQL 以及 MySQL Workbench</li>
<li>使用 pymysql 库进行数据库的连接，实现了把第一天得到的数据存入数据库</li>
</ol>
<h2 id="190305-周二"><a href="#190305-周二" class="headerlink" title="190305 周二"></a>190305 周二</h2><h3 id="初步了解模拟登录"><a href="#初步了解模拟登录" class="headerlink" title="初步了解模拟登录"></a>初步了解模拟登录</h3><p>最后的任务需要爬取登录后才能查看的页面，于是我去搜索了很多博客，只放一部分对我有帮助的链接。</p>
<p>参考链接：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/woainifanfan/p/5754580.html">模拟登录 CSDN-博客园</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wodeboke-y/p/9873609.html">模拟登录 github-博客园</a></p>
</li>
</ul>
<p>首先查看一下需要的登录数据：</p>
<ol>
<li>打开登录网页，用 F12 打开开发者工具，选择 network（网络）选项卡</li>
<li>登录你的账号，此时控制台会显示一大堆请求与响应，找到以 post 方式发送的请求，一般排在第一个</li>
<li>那里会显示几个栏目，找到<code>Form Data</code>（表单数据），这个里面是你填写登录表单之后使用 POST 方式发送给服务端的内容。这里面除了自己填写的账号密码之外还有一些东西，比如下图的<code>lt</code>,<code>dllt</code>,<code>execution</code>,<code>_eventId</code>,<code>rmShown</code>这些都是在表单的隐藏域中，查看登录页面的源代码是可以看的到的。这些隐藏起来的东西是为了检验你是否是从浏览器进来的，只要获取到这些东西，再加上头部信息，就能伪装成浏览器了</li>
<li>至于头部信息，在下图也可以看到我折叠起来的几个栏目，有一个是<code>Request Headers</code>，这是我们在点击登录按钮时发送的 POST 请求信息的信息头。将里面的<code>User-Agent</code>给复制到你代码里面存在一个字典里面等会用</li>
<li>把头部信息和表单数据都看一下，准备一下</li>
</ol>
<p><img src="https://raw.githubusercontent.com/HaneChiri/PicBed/master/blog_images/spider_f12_form_data.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#登录前的准备</span></span><br><span class="line">login_url = <span class="string">&#x27;http://xxxx.xxx&#x27;</span><span class="comment">#登录页面的url</span></span><br><span class="line"><span class="comment">#头部信息</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#x27;</span></span><br><span class="line">    <span class="comment">#加上后面这些会后悔的，别加。</span></span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>:<span class="string">&#x27;xx.xx.xx.xx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>:<span class="string">&#x27;http://xxx.xxx?xxx=http://xxx.xx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Origin&#x27;</span>:<span class="string">&#x27;http://xxx.xxx.xx&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#登录用的数据</span></span><br><span class="line">login_data=&#123;</span><br><span class="line">        <span class="string">&#x27;username&#x27;</span>: <span class="string">&#x27;你的账号&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;你的密码&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;btn&#x27;</span>:<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;lt&#x27;</span>: LT-<span class="number">790162</span>-J9kW2aEFsK3ihu4AzXcovdsJy6cYBM1552123884047-D1Nx-cas，</span><br><span class="line">    <span class="comment">#实际上lt并不能这样写上去，下文会解释。这里记录我自己的错误</span></span><br><span class="line">        <span class="string">&#x27;dllt&#x27;</span>: <span class="string">&#x27;userNamePasswordLogin&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;execution&#x27;</span>: <span class="string">&#x27;e1s1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;_eventId&#x27;</span>: <span class="string">&#x27;submit&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;rmShown&#x27;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>数据准备好之后就开始登录，使用的是 requests 的另一个方法——post。</p>
<p>向服务器发出请求（request）的方式有 get 和 post，查看 html 源代码的时候在表单标签处可以看到表单提交的方法。如：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">id</span>=<span class="string">&quot;casLoginForm&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>像这样写 html 代码会让浏览器在你按下登录按钮的时候以 post 的方式提交表单，也就是以 post 的方式向服务器发起 request，将 form data 发送过去。</p>
<p>post 方法的好处是在发送过程中会隐藏你的表单数据，不会被直接看到；</p>
<p>而前面使用过的 get 方法，会把你的表单数据加在 url 后面，网址后边以问号开头，以&amp;连接的就是发送过去的参数。</p>
<p>涉及登录用 post 比较好，以免轻易泄露密码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以post方式发出登录请求</span></span><br><span class="line">r=requests.post(login_url,headers=headers,data=login_data)</span><br></pre></td></tr></table></figure>

<p>按理来说应该可以了呀，为什么不行？仍然得到登录页面。在这一天我折腾了很久，没有得到答案。</p>
<p>不过在找资料时却学到了其他的一些知识，关于 cookie 和 session。</p>
<h3 id="cookie-和-session"><a href="#cookie-和-session" class="headerlink" title="cookie 和 session"></a>cookie 和 session</h3><p>我目前的理解（如果不对欢迎留言）：</p>
<p>http 是无状态协议，两次访问都是独立的，不会保存状态信息。也就是你来过一次，下次再来的时候网站还是当你第一次来。那么怎么知道你来过，从而给你还原之前的数据呢？就有人想出 cookie 和 session 两种方式。</p>
<p><strong>cookie</strong>（直译：小甜饼）是服务端（网站服务器）收到客户端（你电脑）的 request（请求）的时候和 response（响应）一起发给客户端的数据。客户端把它存在文件里面，并在下一次访问这个网站时将 cookie 随着 request 一起发送过去，这样服务端就会知道你就是之前来过的那个人了。cookie 存储在客户端。</p>
<ol>
<li>客户端发送 request</li>
<li>服务端发送 response 附带一个 cookie（一串数据）</li>
<li>客户端第二次访问时把 cookie 复制一份一起发过去</li>
<li>服务端看到你的 cookie 就知道你是谁了</li>
</ol>
<p><strong>session</strong>（会话）是在服务端内存中保存的一个数据结构，一旦有客户端来访问，那么就给这个客户端创建一个新的 session 在服务端的内存，并将它的 session ID 随着 response 发回给客户端。客户端第二次访问时，会将被分配的 SID 随着 request 一起发过来，服务端在这边验证 SID 之后就会知道你来过。session 存储在服务端。</p>
<ol>
<li>客户端发送 request</li>
<li>服务端发送 response 并在自己这边创建一个 session（一堆数据）并发送一个 session ID 给客户端</li>
<li>客户端第二次访问时把 session ID 一起发过去</li>
<li>服务端看到你的 session ID 就知道你是谁了</li>
</ol>
<p>不过这俩是用来保持登录的，我还没登录成功想这个干啥？请看下一天。</p>
<h3 id="day3-进度"><a href="#day3-进度" class="headerlink" title="day3 进度"></a>day3 进度</h3><ol>
<li>初步了解 cookie 和 session 的概念</li>
<li>了解如何使用 chrome 浏览器的控制台查看 post 表单信息</li>
<li>尝试使用 requests 的 post 方法模拟登录，失败，返回登录页面</li>
</ol>
<h2 id="190306-周三"><a href="#190306-周三" class="headerlink" title="190306 周三"></a>190306 周三</h2><h3 id="表单校验码（非验证码）"><a href="#表单校验码（非验证码）" class="headerlink" title="表单校验码（非验证码）"></a>表单校验码（非验证码）</h3><p>怎么弄都不成功，都跳回登录页面。我只好去询问组长这是为什么。</p>
<p>原来我没发现表单校验码会变的！</p>
<p>一直没注意啊啊啊啊啊啊！</p>
<p>我没有认真比对过两次打开的乱码不一样，看结尾一样就以为一样了。其中的<code>lt</code>这个域每次打开网页都是不一样的，随机出的！</p>
<p>既然知道了问题，就好解决了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取登录校验码</span></span><br><span class="line">html=requests.post(login_url,headers=headers).text</span><br><span class="line">soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">lt=soup.find(<span class="string">&#x27;input&#x27;</span>,&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;lt&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">dllt=soup.find(<span class="string">&#x27;input&#x27;</span>,&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;dllt&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">execution = soup.find(<span class="string">&#x27;input&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;execution&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">_eventId = soup.find(<span class="string">&#x27;input&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;_eventId&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">rmShown = soup.find(<span class="string">&#x27;input&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;rmShown&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">login_data=&#123;</span><br><span class="line">    <span class="string">&#x27;username&#x27;</span>: <span class="built_in">input</span>(<span class="string">&quot;请输入学号：&quot;</span>),</span><br><span class="line">    <span class="string">&#x27;password&#x27;</span>: <span class="built_in">input</span>(<span class="string">&quot;请输入密码：&quot;</span>),</span><br><span class="line">    <span class="string">&#x27;btn&#x27;</span>:<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;lt&#x27;</span>: lt,</span><br><span class="line">    <span class="string">&#x27;dllt&#x27;</span>: dllt,</span><br><span class="line">    <span class="string">&#x27;execution&#x27;</span>: execution,</span><br><span class="line">    <span class="string">&#x27;_eventId&#x27;</span>: _eventId,</span><br><span class="line">    <span class="string">&#x27;rmShown&#x27;</span>: rmShown</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为了保险，我把其他的表单域也给解析赋值给变量了。</p>
<p>不过仍然无法登陆成功，而是进入了一个诡异的页面:</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Welcome to nginx!<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">      <span class="selector-tag">body</span> &#123;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">width</span>: <span class="number">35em</span>;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">margin</span>: <span class="number">0</span> auto;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">font-family</span>: Tahoma, Verdana, Arial, sans-serif;</span></span><br><span class="line"><span class="language-css">      &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Welcome to nginx!<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">      If you see this page, the nginx web server is successfully installed and</span><br><span class="line">      working. Further configuration is required.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">      For online documentation and support please refer to</span><br><span class="line">      <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;</span>nginx.org<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line">      Commercial support is available at</span><br><span class="line">      <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;</span>nginx.com<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span><span class="tag">&lt;<span class="name">em</span>&gt;</span>Thank you for using nginx.<span class="tag">&lt;/<span class="name">em</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>确实有进展，但是这是啥？nginx？查了一下是一个高性能的 HTTP 和反向代理服务器，但是和我现在登录有什么关系呢？（黑人问号.jpg）</p>
<h3 id="利用-session-保持校验码"><a href="#利用-session-保持校验码" class="headerlink" title="利用 session 保持校验码"></a>利用 session 保持校验码</h3><p>即使登录成功，还有一个问题无法解决，那就是我获取校验码的 request 和登录用的 request 是两次不同的访问请求呀，这样校验码又会变化。</p>
<p>我想起了前一天看到的 session，这玩意不就能让服务端记住我？（cookie 试了一下，保存下来的是空的文件不知道怎么回事）</p>
<p>于是新建一个会话：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#新建会话</span></span><br><span class="line">session=requests.session()</span><br></pre></td></tr></table></figure>

<p>在获取校验码的时候改成使用 session 变量来发起请求：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取登录校验码</span></span><br><span class="line">html=session.post(login_url,headers=headers).text</span><br></pre></td></tr></table></figure>

<p><strong>这里的 session 是在客户端创建的，并不是服务端那个，我想它可能存储的是服务端发送过来的 session ID 吧。</strong></p>
<p>同理在正式发送请求时这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#登录</span></span><br><span class="line">r=session.post(login_url,headers=headers,data=login_data)</span><br></pre></td></tr></table></figure>

<p>这样就能让服务端知道我是刚刚获取校验码的那个小伙汁：D</p>
<p>在这一天我没有办法验证是否有效，不过在之后我验证了这个方法的成功性。</p>
<h3 id="day4-进度"><a href="#day4-进度" class="headerlink" title="day4 进度"></a>day4 进度</h3><ol>
<li>知道了原来有个每次会变化的校验码“lt”，找到了跳转回登录页面的原因。使用 Beautifulsoup 来获取每次的校验码，不过仍然没有解决无法登录的问题</li>
<li>使用 session 对象来保证获取校验码和登录时是同一个会话，未验证</li>
</ol>
<h2 id="190307-周四"><a href="#190307-周四" class="headerlink" title="190307 周四"></a>190307 周四</h2><h3 id="多余的头部信息"><a href="#多余的头部信息" class="headerlink" title="多余的头部信息"></a>多余的头部信息</h3><p>我终于发现了问题所在！！！！！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="comment">#&#x27;Host&#x27;:&#x27;xxx.xxx.xxx.xxx&#x27;,</span></span><br><span class="line">    <span class="comment">#&#x27;Referer&#x27;:&#x27;http://xxx.xxx.xxx.xxx...&#x27;,#不详细打码了</span></span><br><span class="line">    <span class="comment">#&#x27;Origin&#x27;:&#x27;http://xxx.xxx.xxxx&#x27;</span></span><br><span class="line">    <span class="comment">#去掉多余的头信息才成功登录！！！！！卡了很久没想到是因为这个</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>头部信息写多了，我只保留了<code>User-Agent</code>之后成功登录了，你们能体会到我当时有多开心吗！</p>
<p>我将成为<del>新世界的卡密</del>小组里面最快完成的人！</p>
<p>解决了这个问题，剩下的就特别简单了。</p>
<p>当时我有一个下午的时间，于是我将进度迅速推进。</p>
<h3 id="爬取通知公告"><a href="#爬取通知公告" class="headerlink" title="爬取通知公告"></a>爬取通知公告</h3><p>设登录页面为 pageA，登录之后的页面跳转到 pageB，而 pageB 有一个按钮跳转到 pageC，这个 pageC 就是 day1 的时候的目录页面，里面有着 pageC1、pageC2、pageC3……等页面的链接，而这个 pageC 最后面还有个按钮用于跳转到目录的下一页，也就是 pageC?pageIndex&#x3D;2，还有 137 页公告栏目录。</p>
<p>没有什么新的东西，和 day1 说的爬取方式差不多，只是页面正文的格式和 day1 的新闻不太一样。核心结构如下，我省略了很多：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bulletin-content&quot;</span> <span class="attr">id</span>=<span class="string">&quot;bulletin-contentpe65&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">&quot;;background: white&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">name</span>=<span class="string">&quot;_GoBack&quot;</span>&gt;</span> <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-size: 20px;font-family: 仿宋&quot;</span>&gt;</span> 校属各单位： <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>大概就是一个<code>&lt;p&gt;</code>标签里面放一个或多个<code>&lt;span&gt;</code>标签，而这里面可能还会嵌套几个<code>&lt;span&gt;</code>标签，里面才有内容，而两个内部的<code>&lt;span&gt;</code>之间还可能有内容。</p>
<p>这要怎么解析？</p>
<p>在尝试了很多方案之后，我终于百度到一个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tag.get_text()<span class="comment">#提取名为tag的bs4标签的内部的所有文字</span></span><br></pre></td></tr></table></figure>

<p>参考链接：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ScapeD/article/details/81913923">BeautifulSoup 获取标签中包含的文字-CSDN-niewzh</a>（正是这个博客解决了我的问题）</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/f156207495/article/details/78074240/">BeautifulSoup 中的.text 方法和 get_text()方法的区别-CSDN</a></p>
</li>
</ul>
<p>解决方案：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取正文内容</span></span><br><span class="line">html=session.post(url,headers=headers).text</span><br><span class="line">soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">article=soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;bulletin-content&#x27;</span>)</span><br><span class="line">news_content=<span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> article.find_all(<span class="string">&#x27;p&#x27;</span>):</span><br><span class="line">    <span class="keyword">if</span> p.span!=<span class="literal">None</span>:<span class="comment">#如果p含有一层span</span></span><br><span class="line">        text=<span class="built_in">str</span>(p.get_text()).strip()<span class="comment">#获取内容并去除多余空格</span></span><br><span class="line">        news_content+=text+<span class="string">&#x27;\n&#x27;</span></span><br></pre></td></tr></table></figure>

<p>接着我就把爬下来的东西存到数据库里面去了。弄完之后得去赶作业了，这一天的时间用完了。</p>
<h3 id="day5-进度"><a href="#day5-进度" class="headerlink" title="day5 进度"></a>day5 进度</h3><p>1.找到无法登录且跳转到未知页面的原因是头部信息加了多余的值，解决之后成功登录到信息门户，实现模拟登陆 2.利用之前爬取单个页面到文件的方法，用 beautifulsoup 解析并保存内容到文件 3.存入 MySQL 数据库中 4.还差爬取多页目录的功能，预计明天完成。整理代码后可提交</p>
<h2 id="190308-周五"><a href="#190308-周五" class="headerlink" title="190308 周五"></a>190308 周五</h2><h3 id="更多的目录页"><a href="#更多的目录页" class="headerlink" title="更多的目录页"></a>更多的目录页</h3><p>开了一个新文件准备整理一下代码，并完成最后一个功能——爬取完目录页第一页之后爬取后面更多的页。</p>
<p>查看源代码的时候，找“第二页”这个按钮对应的链接，发现了规律：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;pagination-info clearFix&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">title</span>=<span class="string">&quot;共2740条记录 分137页显示&quot;</span>&gt;</span> 2740/137 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=1<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">title</span>=<span class="string">&quot;点击跳转到第1页&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span><span class="symbol">&amp;lt;</span><span class="symbol">&amp;lt;</span>&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">title</span>=<span class="string">&quot;当前页&quot;</span>&gt;</span>1<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=2<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">title</span>=<span class="string">&quot;点击跳转到第2页&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span>2&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=3<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">title</span>=<span class="string">&quot;点击跳转到第3页&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span>3&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=4<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">title</span>=<span class="string">&quot;点击跳转到第4页&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span>4&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=5<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">title</span>=<span class="string">&quot;点击跳转到第5页&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span>5&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=6<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span><span class="symbol">&amp;gt;</span>&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">    <span class="attr">href</span>=<span class="string">&quot;detach.portal?pageIndex=137<span class="symbol">&amp;amp;</span>pageSize=<span class="symbol">&amp;amp;</span>.pmn=view<span class="symbol">&amp;amp;</span>.ia=false<span class="symbol">&amp;amp;</span>action=bulletinsMoreView<span class="symbol">&amp;amp;</span>search=true<span class="symbol">&amp;amp;</span>groupid=all<span class="symbol">&amp;amp;</span>.pen=pe65&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">title</span>=<span class="string">&quot;点击跳转到最后页&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span><span class="symbol">&amp;gt;</span><span class="symbol">&amp;gt;</span>&lt;/a</span><br><span class="line">  &gt;</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>可以看出，指向其他目录页的相对链接，只是参数略有不同，参数中只有<code>pageIndex</code>发生了变化。至于给 url 加参数，我记得前几天看到过。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#作为参数的字典</span></span><br><span class="line">para=&#123;</span><br><span class="line">    <span class="string">&#x27;pageIndex&#x27;</span>:<span class="number">1</span>,<span class="comment">#这里需要修改，先爬第一页</span></span><br><span class="line">    <span class="string">&#x27;pageSize&#x27;</span>:<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;.pmn&#x27;</span>:<span class="string">&#x27;view&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;.ia&#x27;</span>:<span class="string">&#x27;false&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;action&#x27;</span>:<span class="string">&#x27;bulletinsMoreView&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;search&#x27;</span>:<span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;groupid&#x27;</span>:<span class="string">&#x27;all&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;.pen&#x27;</span>:<span class="string">&#x27;pe65&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">catalogue_url=<span class="string">&#x27;http://xxx.xx.xx.cn/detach.portal&#x27;</span><span class="comment">#未加参数的新闻目录页url</span></span><br><span class="line">    session = login()  <span class="comment"># 获取已登录的session,这个自定义函数会在下面列出</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,page_count+<span class="number">1</span>):<span class="comment">#page_count是要获取的页数</span></span><br><span class="line">        para[<span class="string">&#x27;pageIndex&#x27;</span>]=i<span class="comment">#设置新闻当前页的索引</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从目录页获取新闻页面链接</span></span><br><span class="line">        html = session.post(catalogue_url,params=para).text</span><br></pre></td></tr></table></figure>

<h3 id="整理代码"><a href="#整理代码" class="headerlink" title="整理代码"></a>整理代码</h3><p>要用到的库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br></pre></td></tr></table></figure>

<h4 id="get-bulletin"><a href="#get-bulletin" class="headerlink" title="get_bulletin"></a>get_bulletin</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_bulletin</span>(<span class="params">page_count</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    目录有多页，从第一页开始获取，往后获取page_count页的目录，并读取目录指向的所有公告</span></span><br><span class="line"><span class="string">    :param page_count: 要爬取的目录页面的数量</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    para=&#123;</span><br><span class="line">        <span class="string">&#x27;pageIndex&#x27;</span>:<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;pageSize&#x27;</span>:<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;.pmn&#x27;</span>:<span class="string">&#x27;view&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;.ia&#x27;</span>:<span class="string">&#x27;false&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;action&#x27;</span>:<span class="string">&#x27;bulletinsMoreView&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;search&#x27;</span>:<span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;groupid&#x27;</span>:<span class="string">&#x27;all&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;.pen&#x27;</span>:<span class="string">&#x27;pe65&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    catalogue_url=<span class="string">&#x27;http://xxx.xxx.xxx.cn/detach.portal&#x27;</span><span class="comment">#未加参数的公告目录页url</span></span><br><span class="line">    session = login()  <span class="comment"># 获取已登录的session</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,page_count+<span class="number">1</span>):</span><br><span class="line">        para[<span class="string">&#x27;pageIndex&#x27;</span>]=i<span class="comment">#设置公告当前页的索引</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从目录页获取公告页面链接</span></span><br><span class="line">        html = session.post(catalogue_url,params=para).text</span><br><span class="line">        soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        rss_title = soup.find_all(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;rss-title&#x27;</span>)</span><br><span class="line">        <span class="comment">#将得到的链接与标题组装成字典</span></span><br><span class="line">        bulletin_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> rss_title:</span><br><span class="line">            bulletin_title = <span class="built_in">str</span>(url.span.string).strip()</span><br><span class="line">            bulletin_url = <span class="string">&#x27;http://xxx.xx.xx.cn/&#x27;</span> + url[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">            bulletin_dict.setdefault(bulletin_title, bulletin_url)<span class="comment">#添加一条公告记录</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#保存公告到数据库</span></span><br><span class="line">        <span class="keyword">for</span> bulletin_title, bulletin_url <span class="keyword">in</span> bulletin_dict.items():</span><br><span class="line">            <span class="comment">#saveInTXT(bulletin_url, session, bulletin_title)#这个是保存到txt文件的函数，用于测试</span></span><br><span class="line">            saveInDB(news_url, session, news_title)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="login"><a href="#login" class="headerlink" title="login"></a>login</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">login</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    登录并返回已经登录的会话</span></span><br><span class="line"><span class="string">    :return: 已经登录的会话（session）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#设置</span></span><br><span class="line">    login_url = <span class="string">&#x27;http://xxx.xx.xx.cn/authserver/login?service=http%3A%2F%2F%2F&#x27;</span></span><br><span class="line">    headers=&#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#新建会话</span></span><br><span class="line">    session=requests.session()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取登录校验码</span></span><br><span class="line">    html=session.post(login_url,headers=headers).text</span><br><span class="line">    soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    lt=soup.find(<span class="string">&#x27;input&#x27;</span>,&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;lt&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    dllt=soup.find(<span class="string">&#x27;input&#x27;</span>,&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;dllt&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    execution = soup.find(<span class="string">&#x27;input&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;execution&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    _eventId = soup.find(<span class="string">&#x27;input&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;_eventId&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    rmShown = soup.find(<span class="string">&#x27;input&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;rmShown&#x27;</span>&#125;)[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    login_data=&#123;</span><br><span class="line">        <span class="string">&#x27;username&#x27;</span>: <span class="built_in">input</span>(<span class="string">&quot;请输入学号：&quot;</span>),</span><br><span class="line">        <span class="string">&#x27;password&#x27;</span>: <span class="built_in">input</span>(<span class="string">&quot;请输入密码：&quot;</span>),</span><br><span class="line">        <span class="string">&#x27;btn&#x27;</span>:<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;lt&#x27;</span>: lt,</span><br><span class="line">        <span class="string">&#x27;dllt&#x27;</span>: dllt,</span><br><span class="line">        <span class="string">&#x27;execution&#x27;</span>: execution,</span><br><span class="line">        <span class="string">&#x27;_eventId&#x27;</span>: _eventId,</span><br><span class="line">        <span class="string">&#x27;rmShown&#x27;</span>: rmShown</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#登录</span></span><br><span class="line">    response=session.post(login_url,headers=headers,data=login_data)</span><br><span class="line">    <span class="keyword">if</span> response.url==<span class="string">&#x27;http://xxx.xx.xx.cn/&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;登录成功！&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> session</span><br></pre></td></tr></table></figure>

<h4 id="saveInTXT"><a href="#saveInTXT" class="headerlink" title="saveInTXT"></a>saveInTXT</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">saveInTXT</span>(<span class="params">url, session, title</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    获取单个公告页面的公告并保存到txt</span></span><br><span class="line"><span class="string">    :param url: 要获取的页面的url</span></span><br><span class="line"><span class="string">    :param session:已经登录的会话</span></span><br><span class="line"><span class="string">    :param title:公告标题</span></span><br><span class="line"><span class="string">    :return:无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#将标题转换为可以作为文件名字的形式</span></span><br><span class="line">    reg = <span class="string">r&#x27;[\/:*?&quot;&lt;&gt;|]&#x27;</span></span><br><span class="line">    title = re.sub(reg, <span class="string">&quot;&quot;</span>, title)</span><br><span class="line"></span><br><span class="line">    path=<span class="string">&#x27;bullet\\&#x27;</span> + title+<span class="string">&#x27;.txt&#x27;</span><span class="comment">#保存在py文件目录下的bulletin文件夹内，以txt格式保存</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    #测试代码，从文件读取手动获取的公告html页面，单机测试</span></span><br><span class="line"><span class="string">    with open(&#x27;new.txt&#x27;,&#x27;r&#x27;,encoding=&#x27;utf8&#x27;) as fin:</span></span><br><span class="line"><span class="string">        html=fin.read()</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    html=session.post(url,headers=headers).text</span><br><span class="line">    soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="comment">#print(soup.prettify())</span></span><br><span class="line">    bulletin_content=soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;bulletin-content&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    bulletin_content= <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> bulletin_content.find_all(<span class="string">&#x27;p&#x27;</span>):</span><br><span class="line">        <span class="keyword">if</span> p.span!=<span class="literal">None</span>:<span class="comment">#如果p含有一层span</span></span><br><span class="line">            text=<span class="built_in">str</span>(p.get_text()).strip()</span><br><span class="line">            bulletin_content+= text + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> fout:</span><br><span class="line">        fout.write(bulletin_content)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;“&#123;&#125;”成功保存到&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(title,path))</span><br></pre></td></tr></table></figure>

<h4 id="saveInDB"><a href="#saveInDB" class="headerlink" title="saveInDB"></a>saveInDB</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">saveInDB</span>(<span class="params">url, session, title</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    获取单个公告页面的公告并保存到txt</span></span><br><span class="line"><span class="string">    :param url: 要获取的页面的url</span></span><br><span class="line"><span class="string">    :param session:已经登录的会话</span></span><br><span class="line"><span class="string">    :param title:公告标题</span></span><br><span class="line"><span class="string">    :return:无</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    html=session.post(url,headers=headers).text</span><br><span class="line">    soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    bulletin_content=soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;bulletin-content&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    bulletin_content= <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> bulletin_content.find_all(<span class="string">&#x27;p&#x27;</span>):</span><br><span class="line">        <span class="keyword">if</span> p.span!=<span class="literal">None</span>:<span class="comment">#如果p含有一层span</span></span><br><span class="line">            text=<span class="built_in">str</span>(p.get_text()).strip()</span><br><span class="line">            bulletin_content+= text + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存到数据库</span></span><br><span class="line">    db = pymysql.connect(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, port=<span class="number">3306</span>, user=<span class="string">&#x27;root&#x27;</span>, passwd=<span class="string">&#x27;root&#x27;</span>, db=<span class="string">&#x27;news&#x27;</span>, charset=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">    cursor = db.cursor()</span><br><span class="line">    cursor.execute(<span class="string">&quot;insert into chdnews(`title`,`content`) values(&#x27;&#123;0&#125;&#x27;,&#x27;&#123;1&#125;&#x27;)&quot;</span>.<span class="built_in">format</span>(title, bulletin_content))</span><br><span class="line">    db.commit()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;已经成功保存公告到数据库：“&#123;&#125;”&#x27;</span>.<span class="built_in">format</span>(title))</span><br></pre></td></tr></table></figure>

<h4 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用</span></span><br><span class="line">get_bulletin(<span class="number">10</span>)<span class="comment">#爬取10页公告</span></span><br></pre></td></tr></table></figure>

<p>暂时没有将其通用化，直接将网址写死在函数里面了。</p>
<h3 id="day6-进度"><a href="#day6-进度" class="headerlink" title="day6 进度"></a>day6 进度</h3><ol>
<li>通过调整服务门户的 url 中的参数来获取通知公告的每一个目录页的 url，从而爬取所有公告</li>
<li>将学习中写的测试代码重新构造整理，添加函数注释，提交任务</li>
</ol>
<h2 id="190309-周六"><a href="#190309-周六" class="headerlink" title="190309 周六"></a>190309 周六</h2><h3 id="day7-进度"><a href="#day7-进度" class="headerlink" title="day7 进度"></a>day7 进度</h3><p>写了本篇博客进行总结</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>python爬虫学习笔记2模拟登录与数据库</p><p><a href="https://yxchangingself.xyz/posts/python_spider_note2login_and_database/">https://yxchangingself.xyz/posts/python_spider_note2login_and_database/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>憧憬少</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-03-09</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-03-09</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/python/">python</a><a class="link-muted mr-2" rel="tag" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a><a class="link-muted mr-2" rel="tag" href="/tags/mysql/">mysql</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/python_spider_note3class_spider/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">python爬虫学习笔记3封装爬虫类</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/hexo_blog_switch_theme_1/"><span class="level-item">换了一个主题</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#转载声明"><span class="level-left"><span class="level-item">1</span><span class="level-item">转载声明</span></span></a></li><li><a class="level is-mobile" href="#任务介绍"><span class="level-left"><span class="level-item">2</span><span class="level-item">任务介绍</span></span></a></li><li><a class="level is-mobile" href="#过程记录"><span class="level-left"><span class="level-item">3</span><span class="level-item">过程记录</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#190303-周日"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">190303 周日</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#练习爬取公开页面"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">练习爬取公开页面</span></span></a></li><li><a class="level is-mobile" href="#day1-进度"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">day1 进度</span></span></a></li></ul></li><li><a class="level is-mobile" href="#190304-周一"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">190304 周一</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#将数据存入数据库"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">将数据存入数据库</span></span></a></li><li><a class="level is-mobile" href="#day2-进度"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">day2 进度</span></span></a></li></ul></li><li><a class="level is-mobile" href="#190305-周二"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">190305 周二</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#初步了解模拟登录"><span class="level-left"><span class="level-item">3.3.1</span><span class="level-item">初步了解模拟登录</span></span></a></li><li><a class="level is-mobile" href="#cookie-和-session"><span class="level-left"><span class="level-item">3.3.2</span><span class="level-item">cookie 和 session</span></span></a></li><li><a class="level is-mobile" href="#day3-进度"><span class="level-left"><span class="level-item">3.3.3</span><span class="level-item">day3 进度</span></span></a></li></ul></li><li><a class="level is-mobile" href="#190306-周三"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">190306 周三</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#表单校验码（非验证码）"><span class="level-left"><span class="level-item">3.4.1</span><span class="level-item">表单校验码（非验证码）</span></span></a></li><li><a class="level is-mobile" href="#利用-session-保持校验码"><span class="level-left"><span class="level-item">3.4.2</span><span class="level-item">利用 session 保持校验码</span></span></a></li><li><a class="level is-mobile" href="#day4-进度"><span class="level-left"><span class="level-item">3.4.3</span><span class="level-item">day4 进度</span></span></a></li></ul></li><li><a class="level is-mobile" href="#190307-周四"><span class="level-left"><span class="level-item">3.5</span><span class="level-item">190307 周四</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#多余的头部信息"><span class="level-left"><span class="level-item">3.5.1</span><span class="level-item">多余的头部信息</span></span></a></li><li><a class="level is-mobile" href="#爬取通知公告"><span class="level-left"><span class="level-item">3.5.2</span><span class="level-item">爬取通知公告</span></span></a></li><li><a class="level is-mobile" href="#day5-进度"><span class="level-left"><span class="level-item">3.5.3</span><span class="level-item">day5 进度</span></span></a></li></ul></li><li><a class="level is-mobile" href="#190308-周五"><span class="level-left"><span class="level-item">3.6</span><span class="level-item">190308 周五</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#更多的目录页"><span class="level-left"><span class="level-item">3.6.1</span><span class="level-item">更多的目录页</span></span></a></li><li><a class="level is-mobile" href="#整理代码"><span class="level-left"><span class="level-item">3.6.2</span><span class="level-item">整理代码</span></span></a></li><li><a class="level is-mobile" href="#day6-进度"><span class="level-left"><span class="level-item">3.6.3</span><span class="level-item">day6 进度</span></span></a></li></ul></li><li><a class="level is-mobile" href="#190309-周六"><span class="level-left"><span class="level-item">3.7</span><span class="level-item">190309 周六</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#day7-进度"><span class="level-left"><span class="level-item">3.7.1</span><span class="level-item">day7 进度</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">ChangingSelf</a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><p class="is-size-7"><span>&copy; 2024 憧憬少</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p><p class="is-size-7"><a href="https://beian.miit.gov.cn/" target="_blank">湘ICP备2021000400号-1</a> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44200002444480" target="_blank">粤公网安备 44200002444480号</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><script src="/live2d-widget/autoload.js"></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script type="text/javascript" src="/js/universe.js"></script><script src="https://cdn.jsdelivr.net/npm/echarts@5.5.1/dist/echarts.min.js"></script>
        <!-- ECharts 图表容器 -->
        
        <script>
            if(document.getElementById('heatmapChart')) {
                const heatmapChart = echarts.init(document.getElementById('heatmapChart'), 'light');
                const containerWidth = document.getElementById('heatmapChart').offsetWidth;
                const cellSize = Math.max(Math.floor(containerWidth / 60));
                heatmapChart.setOption({
                    tooltip: {
                        position: 'top',
                        formatter: params => `${params.value[0]}: ${params.value[1]} Articles`
                    },
                    visualMap: {
                        min: 0,
                        max: Math.max(...[["2019-02-06",1],["2019-02-07",1],["2019-02-08",1],["2019-02-18",1],["2019-02-27",1],["2019-02-28",1],["2019-03-09",1],["2019-03-15",1],["2019-03-19",1],["2019-03-30",1],["2019-04-07",1],["2019-04-11",1],["2019-04-12",1],["2019-04-21",1],["2019-06-13",1],["2019-06-25",1],["2019-06-26",2],["2019-06-27",1],["2019-06-28",1],["2019-06-30",1],["2019-07-01",2],["2019-07-09",1],["2019-07-18",1],["2019-07-20",1],["2019-08-06",1],["2019-08-07",1],["2019-08-10",1],["2019-08-11",1],["2019-08-18",1],["2019-08-20",1],["2019-09-06",1],["2019-09-10",1],["2019-09-14",1],["2019-12-30",1],["2019-12-31",1],["2020-01-02",1],["2020-01-15",1],["2020-01-27",1],["2020-01-28",1],["2020-02-04",1],["2020-02-18",1],["2020-03-03",1],["2020-03-08",1],["2020-03-14",1],["2020-03-22",1],["2020-03-29",1],["2020-04-05",1],["2020-04-16",1],["2020-04-17",1],["2020-04-23",1],["2020-08-10",2],["2020-09-27",1],["2020-10-11",2],["2020-11-22",1],["2021-01-07",1],["2021-01-12",1],["2021-01-21",1],["2021-03-06",1],["2021-06-27",1],["2021-07-09",1],["2022-02-08",1],["2022-06-01",1]].map(item => item[1])),
                        calculable: false,
                        orient: 'horizontal', // 横向布局
                        right: '5%',
                        bottom: '5%',
                        inRange: { color: ['#FFEFD5', '#FFA07A', '#FF4500'] }
                    },
                    calendar: {
                        top: '20%',
                        left: 'center',
                        range: new Date().getFullYear(),
                        cellSize: cellSize, // 方格大小
                        splitLine: { lineStyle: { color: '#E0E0E0', width: 1 } },
                        itemStyle: { borderWidth: 1, borderColor: '#E0E0E0' },
                        dayLabel: { firstDay: 1, fontSize: 12, color: '#333', show: false },
                        monthLabel: { fontSize: 12, color: '#555' }
                    },
                    series: [{
                        type: 'heatmap',
                        coordinateSystem: 'calendar',
                        data: [["2019-02-06",1],["2019-02-07",1],["2019-02-08",1],["2019-02-18",1],["2019-02-27",1],["2019-02-28",1],["2019-03-09",1],["2019-03-15",1],["2019-03-19",1],["2019-03-30",1],["2019-04-07",1],["2019-04-11",1],["2019-04-12",1],["2019-04-21",1],["2019-06-13",1],["2019-06-25",1],["2019-06-26",2],["2019-06-27",1],["2019-06-28",1],["2019-06-30",1],["2019-07-01",2],["2019-07-09",1],["2019-07-18",1],["2019-07-20",1],["2019-08-06",1],["2019-08-07",1],["2019-08-10",1],["2019-08-11",1],["2019-08-18",1],["2019-08-20",1],["2019-09-06",1],["2019-09-10",1],["2019-09-14",1],["2019-12-30",1],["2019-12-31",1],["2020-01-02",1],["2020-01-15",1],["2020-01-27",1],["2020-01-28",1],["2020-02-04",1],["2020-02-18",1],["2020-03-03",1],["2020-03-08",1],["2020-03-14",1],["2020-03-22",1],["2020-03-29",1],["2020-04-05",1],["2020-04-16",1],["2020-04-17",1],["2020-04-23",1],["2020-08-10",2],["2020-09-27",1],["2020-10-11",2],["2020-11-22",1],["2021-01-07",1],["2021-01-12",1],["2021-01-21",1],["2021-03-06",1],["2021-06-27",1],["2021-07-09",1],["2022-02-08",1],["2022-06-01",1]]
                    }]
                });
                // hexo热力图点击跳转到月份页面
                heatmapChart.on('click', function(params) {
                       if (params.componentType === 'series') {
                        const dateStr = params.value[0];
                        const dateParts = dateStr.split('-');
                        const year = parseInt(dateParts[0], 10);
                        const month = parseInt(dateParts[1], 10);
                        const formattedMonth = `${year}/${String(month).padStart(2, '0')}`;
                        window.location.href = '/archives/' + formattedMonth; // 一般归档页面路径为/archives/YYYY-MM
                    }
                });
            }
        </script>
    
        
        <script>
            if(document.getElementById('monthlyChart')) {
                const monthlyChart = echarts.init(document.getElementById('monthlyChart'), 'light');
                monthlyChart.setOption({
                    xAxis: {
                        type: 'category',
                        data: ["2019-02","2019-03","2019-04","2019-06","2019-07","2019-08","2019-09","2019-12","2020-01","2020-02","2020-03","2020-04","2020-08","2020-09","2020-10","2020-11","2021-01","2021-03","2021-06","2021-07","2022-02","2022-06"],
                        axisLabel: { fontSize: 12 }
                    },
                    yAxis: {
                        type: 'value',
                        splitLine: { lineStyle: { type: 'dashed', color: '#ccc' } }
                    },
                    series: [{
                        name: 'Articles',
                        type: 'line',
                        data: [6,4,4,7,5,6,3,2,4,2,5,4,2,1,2,1,3,1,1,1,1,1],
                        smooth: true,
                        lineStyle: { color: '#5470C6', width: 2 },
                        itemStyle: { color: '#5470C6' },
                        areaStyle: { color: 'rgba(84, 112, 198, 0.4)' },
                        symbolSize: 10, //圆点大一点，方便点击
                        animationDuration: 1000
                    }]
                });
                // 跳转到月份页面
                 monthlyChart.on('click', function(params) {
                    if (params.componentType === 'series') {
                        const year = params.name.split('-')[0];
                        const month = params.name.split('-')[1];
                        window.location.href = '/archives/' + year + '/' + month; 
                    }
                });
            }
        </script>
    
        
        <script>
            if(document.getElementById('tagsChart')){    
                const tagsChart = echarts.init(document.getElementById('tagsChart'), 'light');
                tagsChart.setOption({
                    tooltip: { trigger: 'item', formatter: '{b}: {c} ({d}%)' },
                    series: [{
                        type: 'pie',
                        radius: '60%',
                        data: [{"name":"python","value":20},{"name":"爬虫","value":14},{"name":"hexo","value":11},{"name":"cpp","value":6},{"name":"java","value":6},{"name":"scrapy","value":4},{"name":"算法学习","value":3},{"name":"tkinter","value":3}],
                        label: {
                            position: 'outside',
                            formatter: '{b} {c} ({d}%)',
                            fontSize: 12
                        },
                        color: ['#5470C6', '#91CC75', '#FAC858', '#EE6666', '#73C0DE', '#3BA272', '#FC8452', '#9A60B4'],
                        animationDuration: 1000
                    }],
                    legend: {
                        bottom: '0',
                        left: 'center',
                        data: [{"name":"python","value":20},{"name":"爬虫","value":14},{"name":"hexo","value":11},{"name":"cpp","value":6},{"name":"java","value":6},{"name":"scrapy","value":4},{"name":"算法学习","value":3},{"name":"tkinter","value":3}].map(tag => tag.name),
                        textStyle: { fontSize: 12 }
                    }
                });
                tagsChart.on('click', function(params) {
                    if (params.componentType === 'series') {
                        const tag = params.name;
                        window.location.href = '/tags/' + tag;
                    }
                });
            }
        </script>
    
        
        <script>
            if(document.getElementById('categoriesChart')){
                const categoriesChart = echarts.init(document.getElementById('categoriesChart'), 'light');
                categoriesChart.setOption({
                    xAxis: {
                        type: 'value',
                        splitLine: { lineStyle: { type: 'dashed', color: '#ccc' } }
                    },
                    yAxis: {
                        type: 'category',
                        data: [{"name":"项目总结","value":26},{"name":"解决方案","value":13},{"name":"日志随笔","value":11},{"name":"博客站务","value":10},{"name":"学习笔记","value":6}].map(category => category.name).reverse(),
                        axisLabel: { fontSize: 12 }
                    },
                    series: [{
                        name: 'Category Count',
                        type: 'bar',
                        data: [{"name":"项目总结","value":26},{"name":"解决方案","value":13},{"name":"日志随笔","value":11},{"name":"博客站务","value":10},{"name":"学习笔记","value":6}].map(category => category.value).reverse(),
                        label: {
                            show: true,
                            position: 'right',
                            fontSize: 12
                        },
                        itemStyle: {
                            color: new echarts.graphic.LinearGradient(0, 0, 1, 0, [
                                { offset: 0, color: '#91CC75' },
                                { offset: 1, color: '#73C0DE' }
                            ])
                        },
                        animationDuration: 1000
                    }]
                });
                categoriesChart.on('click', function(params) {
                    if (params.componentType === 'series') {
                        const category = params.name;
                        window.location.href = '/categories/' + category;
                    }
                });
            }
        </script>
    
    </body></html>