{"pages":[{"title":"关于","text":"我是谁 一个伪-二次元技术宅，一个b站up主。喜欢看动漫，看漫画，也画过画（画的很烂）；喜欢看小说，也写过小说（当然啦，写得很烂）；喜欢学一些新东西，但是基本上都是半吊子。涉猎广泛，很多东西都会一点，但是也都只会一点。 虽然周围的人叫我大佬，不过我知道我并没有达到那个境界。就好像以前有个称号叫学酥，外表看起来就像学霸一样蛮厉害的，但是里面都是渣。 不过我在改变，我在尝试去继续以前未能完成的事情，拾取以前的记忆碎片，接纳过去幼稚的自我。 我是憧憬少，I am ChangingSelf。 姓名 杨啸 昵称 憧憬少（ChangingSelf） 性别 男 专业 软件工程 QQ 913620659 Email ChangingSelf@163.com、yangxiao559@126.com、913620659@qq.com Github ChangingSelf（现在使用）、HaneChiri（以前的一些项目保存之处） Gitee ChangingSelf Bilibili 憧憬少 个人博客 yxchangingself.xyz 个人公众号 憧憬少的成长日记（更新一些周总结、月总结、年总结、读书笔记等） QQ交流群 563943146 文章分类文章分类调整于2021年1月21日，有关文章分类的详情见：第四次博客文章分类调整 分类 内容 项目总结 课设、练习等或大或小的项目的总结，一般会写设计思路，遇到的问题等 学习笔记 目的是回顾知识的笔记 解决方案 对某个特定问题的解决办法。 博客站务 与该博客站点的搭建、部署、修改、索引相关的文章 日志随笔 杂记、随笔（定期总结之类的一般发我公众号不发这里） 文章分类按顺序判定： 是否与博客站点相关？是，则归类“博客站务”； 是否有明确目标与截止时间？是，则归类“项目总结”； 是否是某个特定问题的解决方案？是，则归类“解决方案”； 是否需要回顾或者以后可能用的到？是，则归类“学习笔记”； 以上全否，放入“日志随笔” 本站历史 2018年8月底，我产生了建立个人博客的想法，并尝试租服务器搭建 WordPress 博客。搭建之后并不是很满意，并没有开始写。 2019年2月6日，在github上搭建了hexo博客，使用主题shana（夏娜）。详见：Hexo部署博客的过程记录 2019年2月7日，为博客添加访问统计。 2019年2月28日，将主题换成NexT。详见：换了一个主题 2019年6月26日，第一次调整博客分类。 2019年6月28日，开始使用图床工具PicGo，为文章配图方便了很多，所以文章中图片开始变多。 2019年12月30日，我确定了自己的昵称的正式的英文名——ChangingSelf，注册了一个新的域名yxChangingSelf.xyz，重新注册了一个新的github账号，将hexo博客迁移到这边。原博客保留之前的自定义域名（不续费了，所以不放出来了）。 2019年12月31日，第二次文章分类调整 2020年4月5日，将主题换成Matery。详见：第二次切换主题 2020年10月11日，将主题换成Icarus，并且第三次调整文章分类，详见：第三次切换主题 2021年1月7日，获得ICP备案号，将博客部署到腾讯云服务器上面，访问速度得到了跨越式的提升。 2021年1月8日，获得网安备案号 2021年1月21日，第四次博客文章分类调整 收藏本博客你可以使用RSS阅读器（比如irreader）来订阅本博客的RSS源 也可以收藏在书签栏，或者使用pinbox来收藏","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"站点总目录","text":"前言这是本博客站点的文章目录索引，如果你想在本站逛一逛，可以从这里开始。 如果想要搜索特定内容，请结合标签、分类和站内搜索功能。部分博客有对应的 B 站视频，以及 github 库，详见各自文章的开头传送门。 此目录并非包含本站所有文章，比如日志随笔之类的不一定会放到目录，还可能是因为我懒得更新这个目录 收录到此目录的一般是一个系列的文章。 python 爬虫 python 爬虫学习笔记 1 简易爬虫：我的第一篇爬虫博客（2019-02-08），讲了一个爬取小说的简单爬虫 python 爬虫学习笔记 2 模拟登录与数据库 python 爬虫学习笔记 3 封装爬虫类 python 爬虫学习笔记 4 模拟登录函数的优化 python 爬虫学习笔记 5 爬虫类结构优化 练习利用 Scrapy 爬取 b 站排行榜：开始学 python 的 Scrapy 框架了，参考书是崔庆才的《python3 网络爬虫开发实战》。跟着教程敲完之后，又试着按照一样的逻辑去爬取了 B 站排行榜的数据。 学校信息门户模拟登录之密码加密：以前写的爬虫无法登录到学校的信息门户上去了，因为门户的新 JS 代码将表单的密码先加密了一次，再将其与别的表单数据 POST 过去。使用的是 AES 加密的 CBC 模式。当时我对密码学知识还没有太多了解，所以如果有不太对的地方欢迎留言 学校信息门户模拟登录：将登陆我的学校信息门户的部分专门封装成一个模块，需要的时候导入。 爬取微信公众号文章 1 获取文章链接：通过已有的微信公众号个人订阅号来获取某个公众号的所有文章链接。缺点是需要手动登录并将 cookies 复制过来。 爬取微信公众号文章 2 获取页面失败：其实没有获取失败，只是因为用的控制台 print 的字符有数量限制，没显示完全导致误会。 Scrapy 爬虫框架（1）一个简单的可用的爬虫：为了做一个疫情新闻爬虫而复习 Scrapy python 爬虫解析库 BeautifulSoup 速查 课设或上机作业思路分享 简易倒排索引：智能信息检索作业 java 基于 AWT 的对战小游戏：java 课设，主要内容在B 站的视频说明 MFC 习题|RGB 颜色模型演示程序：计算机图形学的某个选做课后习题 【课设总结】基于 LAN 的即时通信软件：python 的 tkinter 程序，计算机网络的课设。 【作业总结】python 写的 DES 替代算法的 gui 小工具：信息安全上机作业 【作业总结】声卡数据采集及处理：计算机网络测控 【编程练习】java 简易学生管理系统：数据库基础上机练习 出于兴趣弄的 【编程练习】明日非舟抽卡模拟器（1）按照概率抽取干员星级 【编程练习】明日非舟抽卡模拟器（2）xml 文件解析 c++学生信息管理系统（一）：不是作业，是几个学期后想要试试看写原本的项目 hexo 日记本：用 hexo 搭建一个本地的日记本（现在并没有在用了，因为新建和预览都比较麻烦） 基于React+Electron的CraftTweaker脚本生成器：minecraft自定义合成表 解决方案 python 相对路径是相对于哪里 python 读取 ini 文件失败的原因 MFC 用对话框获取输入 更改 git 仓库已经 commit 的用户名和邮箱信息 建新 hexo 博客后继续更新旧 hexo 博客的方法 WIN10 共享文件夹 notepad++添加文件关联","link":"/catalogue/index.html"},{"title":"contact","text":"","link":"/contact/index.html"},{"title":"友情链接","text":"点击名字可以进入他们的博客 暮冥 一位ACM大佬，同时也是他让我有了建立个人博客的想法 博客主要内容：算法题解 更新频率：高（一个月好几篇） “徘徊在理想和现实的假象主义者” Leesin 一个或许在文学上比较有天赋的程序猿？ 博客主要内容：Linux 更新频率：高 问及要什么简介的时候， “简介：一个笨比” 他如是说道。 封掣 一位擅长前端的刀客塔 博客主要内容：前端网页设计、python、nodejs 更新频率：低（年更的鸽子） “手拿锟斤拷，疾呼烫烫烫” 半岛铁盒 一个转专业到计科的好学的学弟 博客主要内容：C/C++编程 更新频率：一月数篇 “永远相信美好的事情即将发生” 阳光下的少年(StringOD) 博客主要内容：java 更新频率：中（月更） “一个不断努力改变自の少年”","link":"/friends/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"在hexo的Icarus主题页面底部加入备案号","text":"2020年12月31日提交的ICP备案申请，在今天（2020年1月7日）通过啦！ 接着就是要把备案号添加到博客页脚。 参考的资料链接为：Hexo博客icarus主题定制篇 定制备案icarus主题目前没有备案的扩展点，官方后续应该后支持这个功能，我先自己扩展一个用用。 编辑文件node_modules\\hexo-theme-icarus\\layout\\common\\footer.jsx 12345678910111213141516171819const { logo, logoUrl, siteUrl, siteTitle, siteYear, author, links, showVisitorCounter, visitorCounterTitle, /* 添加下面这行代码 */ beian } = this.props;&lt;a href=&quot;https://github.com/ppoffice/hexo-theme-icarus&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Icarus&lt;/a&gt;{/* 添加下面这行代码 */}&lt;br /&gt;&lt;a href={beian.url}&gt;{beian.title}&lt;/a&gt;123456789101112131415161718 配置_config.icarus.yml： 1234beian: title: xxxxxx备案号 url: xxxurl123 上面这部分是关于参考博客的原文的引用。 我打开的是themes\\icarus\\layout\\common\\footer.jsx ，应该是安装的时候用的方式不同，博主用的应该是插件式的方式安装Icarus主题。不过都一样。 我第一次尝试的时候只添加了&lt;br /&gt;&lt;a href={beian.url}&gt;{beian.title}&lt;/a&gt;这一部分代码，没看到上面，随后hexo报错： 1err: ReferenceError: beian is not defined beian未定义？我已经在配置文件中定义了beian这个配置项啊。随后看到了上面那部分，原来是因为，虽然配置传入了Footer组件的属性，但是并未被解构赋值取出来，所以需要在一开头把beian这一项取出来。 然而，即使我这样做了，还是出现了问题： 1err: TypeError: Cannot read property 'title' of undefined 这说明beian还是未定义，是哪里出现问题了呢？ 我发现这个文件中除了Footer这个react组件的定义之外，还有如下代码： themes\\icarus\\layout\\common\\footer.jsx12345678910111213141516171819202122232425262728module.exports = cacheComponent(Footer, 'common.footer', props =&gt; { const { config, helper } = props; const { url_for, _p, date } = helper; const { logo, title, author, footer, plugins } = config; const links = {}; if (footer &amp;&amp; footer.links) { Object.keys(footer.links).forEach(name =&gt; { const link = footer.links[name]; links[name] = { url: url_for(typeof link === 'string' ? link : link.url), icon: link.icon }; }); } return { logo, logoUrl: url_for(logo), siteUrl: url_for('/'), siteTitle: title, siteYear: date(new Date(), 'YYYY'), author, links, showVisitorCounter: plugins &amp;&amp; plugins.busuanzi === true, visitorCounterTitle: _p('plugin.visitor_count', '&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;0&lt;/span&gt;'), };}); 可以发现，这段代码的前面有个config，并且解构赋值了几个在配置文件中存在的字段，我想，这应该就是读取配置并且将它们作为属性传给Footer组件的代码了，所以我在这里也做了修改： themes\\icarus\\layout\\common\\footer.jsx1234567891011121314151617181920212223242526272829module.exports = cacheComponent(Footer, 'common.footer', props =&gt; { const { config, helper } = props; const { url_for, _p, date } = helper; const { logo, title, author, footer, plugins,beian } = config;//在这里添加beian const links = {}; if (footer &amp;&amp; footer.links) { Object.keys(footer.links).forEach(name =&gt; { const link = footer.links[name]; links[name] = { url: url_for(typeof link === 'string' ? link : link.url), icon: link.icon }; }); } return { logo, logoUrl: url_for(logo), siteUrl: url_for('/'), siteTitle: title, siteYear: date(new Date(), 'YYYY'), author, links, showVisitorCounter: plugins &amp;&amp; plugins.busuanzi === true, visitorCounterTitle: _p('plugin.visitor_count', '&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;0&lt;/span&gt;'), beian//并且在这里返回出去 };}); 完成这些就ok了，hexo clean &amp; hexo s之后，在博客最底部可以看到备案号。","link":"/posts/hexo-Icarus-beian-in-footer/"},{"title":"第四次博客文章分类调整","text":"之前的分类过于模糊，导致写完文章不知道该放在哪个分类，所以再次调整分类。 第一次分类调整 第二次分类调整 第三次分类调整 原本的文章分类 分类 内容 复盘总结 对过程进行回顾，总结经验，优化流程。 学习笔记 知识点总结等都放在这里。 解决方案 对某个特定问题的解决办法。 日志随笔 随笔，博客更新日志等。 目录索引 将本博客的文章定期进行汇总分类。 分类之间的一些区别： 复盘总结：以叙述过程与思路为主，一般含有步骤总结，思路记录（比如：我是如何想到这一步的？），一般不含对知识点的讲解。该分类下是比较抽象的文章 学习笔记：以介绍结果与设计为主，长的像教程。可能含有大量代码，一般含有新知识点的总结说明，我在b站上面录了视频的项目对应的博客文章一般也属于这个。该分类下是比较具体的文章。 解决方案：以介绍问题及其解决方法为主，比起学习笔记，更适合作为教程。它将复盘总结中的一些经验提取出来，又不像学习笔记一样冗长复杂。 调整分类前，“过程复盘”这个分类占了五分之三的内容，而其他分类比较少，比较不平衡，而且分类的标准太模糊，以至于我经常不知道该放到哪里去。 调整之后，“知识整理”、“算法理解”归入“学习笔记”，“工具使用”归入“解决方案”，减少了分类数量，并且明确了分类标准。按照新标准对文章调整分类，“学习笔记”和“复盘总结”各占二十多篇，不再是“指南针面板”了 调整后的文章分类 分类 内容 项目总结 课设、练习等或大或小的项目的总结，一般会写设计思路，遇到的问题等 学习笔记 目的是回顾知识的笔记 解决方案 对某个特定问题的解决办法。 博客站务 与该博客站点的搭建、部署、修改、索引相关的文章 日志随笔 杂记、随笔（定期总结之类的一般发我公众号不发这里） 分类变化说明有些分类名称没变，但是含义变了。 “复盘总结”变成了“项目总结”。考虑到所有的博客都有一定的复盘性质，不好分，所以改为“项目总结”，从而“内容包括项目”的文章就要放在该分类下。 何谓项目？美国项目管理协会（PMI）对项目的定义是：“为创造独特的产品、服务或成果而进行的一次性努力。”，具有目的性、一次性、临时性、独特性、整体性的特点。（参考：项目到底是什么-知乎） 我写的课设以及一些练习就有这样的特点，能产出代码成果、做完之后就结束、有规定的完成时间等，这些项目的总结文章，写完之后不一定会再去看，写完了发出来类似归档。 “学习笔记”名称未变，但是内容划分规则变了。不再介绍成果，而是纯粹的知识点笔记梳理，有成果的文章都归类到“项目总结”中去了。这样可以避免两个分类难以区分的情况。这里的文章不同于“项目总结”归档式的文章，而是可以时时回顾的“笔记”。 “解决方案”未变。 “目录索引”并入新建的分类“博客站务”。目录索引这一分类文章不多，没必要单独开一个分类，而博客站点相关的内容不能仅仅使用一个hexo标签来标记。 “日志随笔”中博客更新相关内容并入“博客站务”。 调整之后，除了“项目总结”仍然是二十多篇、读书笔记是新增的只有一篇之外，其他的分类下文章数目大部分是十篇左右，比起调整前分布更加均匀。 文章分类流程按顺序判定： 是否与博客站点相关？是，则归类“博客站务”； 是否含有成品？是，则归类“项目总结”； 是否是某个特定问题的解决方案？是，则归类“解决方案”； 是否需要回顾或者以后可能用的到？是，则归类“学习笔记”； 以上全否，放入“日志随笔”","link":"/posts/adjust_categories_4/"},{"title":"git管理的Android项目忽略密码或token的方法","text":"在照着Android教材《第一行代码 第三版》写天气预报app项目的时候，我发现如果把开发者token写在代码里面，用git管理的时候就会把token暴露出来，即使后面删掉，也会留在commit历史中。而.gitignore一般是忽略整个文件，没办法忽略单独一行。 所以可以将密码或者开发者token单独放在一个文件中，用.gitignore忽略它，并且在使用的时候读取其中的token。 解决方案 在app/src/main/res/values目录下新建一个资源文件tokens.xml，内容如下： 1234&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;resources&gt; &lt;string name=&quot;token&quot;&gt;TAkhjf8d1nlSlspN（这里改成你的token）&lt;/string&gt;&lt;/resources&gt; 在使用的时候可以用R.string.token来直接访问，也可以将它存在一个全局可得的地方。 把上面那个文件加入.gitignore。 注意创建好之后不要让你的IDE自动把这个文件git add了，否则.gitignore不起作用，如果你已经git add了，就使用下面这条命令恢复。 1$git reset HEAD app/src/main/res/values/tokens.xml","link":"/posts/android-project-gitignore-token/"},{"title":"利用Word域代码实现将形如“图一-1”的题注修改为“图1-1”","text":"问题描述在用word编写毕业论文时，遇到了这样一个问题：通过多级列表的设置将一级标题设置为汉字数字之后，若需要设置包含章节号的题注（形如“图1-1”）时，则会变成“图一-1”的形式。本篇文章解决的就是将形如“图一-1”的题注通过设置域代码，在不修改一级标题格式的情况下改为“图1-1”。 参考链接 word里面，如何在章节编号为第一章、第二章这种情况，实现图根据章节编号并且形式为图1.1、图2.1？ Word 自动更改题注章节编号格式“图一.1”为“图1.1” [word技巧]把标题、图表题注编号由“一.1”改为”1.1” 一篇文章教会你使用word域代码（seq field code ） ：这个方法也是可以的，不过本文没有采用。 设置域显示格式的开关-微软官方 word将“图一.x”修改为“图1.x”-Bilibili 域代码：Quote 域-微软官方 STYLEREF域代码官方文档链接 什么是域代码使用组合键 Alt+F9 ，可以显示或隐藏文档中所有域代码 ： 从上图中可以看到，原本的“图 一-1”已经变成了“图 { STYLEREF 1 \\s }-{SEQ 图 * ARABIC \\s 1}”，如果你此时直接复制它们，会发现粘贴出来的仍然是“图 一-1”，而将光标放在花括号中，则会将花括号括住的内容选中成为一个整体。其中花括号括住的部分就是“域代码” 。 你使用“添加题注”的对话框为图片添加题注时，插入的实际上就是这些“域代码”，你使用 Ctrl+F9组合键（会生成域代码的花括号，手动输入花括号是不行的）插入题注效果是一样的。 在这里 {STYLEREF 1 \\s} 代表了章节号，也就是汉字数字“一”和“二”， {SEQ 图 \\* ARABIC \\s 1}代表了图的题注编号。 其中 STYLEREF 和SEQ 是“域”的名字，而后面的内容则是“域”的参数与“格式开关”（即域的格式选项）。 {STYLEREF 1 \\s} 代表“插入具有样式名为‘1’的文本，并在指定标题级别下面重新开始（ \\s，此处未指定标题级别）”。 {SEQ 图 \\* ARABIC \\s 1}代表“插入名为’图’的序列的下一个编号，将结果显示为阿拉伯基数（ \\* ARABIC），并在一级标题下面重新开始编号（ \\s，此处标题级别为1，即若是到了下一个一级标题下，则会重新从1开始编号）”。 得知了word题注是用“域代码”实现的事实后，现在我们要做的事情就是将{STYLEREF 1 \\s}的输出结果从汉字数字转变为阿拉伯数字，尝试将\\* ARABIC开关加入其中，似乎并没有效果。 我在网上搜索到了另一个解决方案，利用迂回的方式将其转化，见：[word技巧]把标题、图表题注编号由“一.1”改为”1.1” 解决方案将{STYLEREF 1 \\s}修改为 { QUOTE &quot;一九一一年一月{ STYLEREF 1 \\s }日&quot; \\@&quot;D&quot; }就可以了，注意花括号仍然得是使用 Ctrl+F9组合键生成的花括号。 我找到的文章并未说明其原理，但了解了域代码相关知识后，也不难理解原理。 首先找到 QUOTE域的相关说明：域代码：Quote 域-微软官方 1{ QUOTE &quot;LiteralText&quot; } “LiteralText”：插入的文本，必须加引号。它可以包含除 AutoNum、AutoNumLgl、AutoNumOut 或 Symbol 以外的所有其他域。 也就是说，QUOTE &quot;一九一一年一月{ STYLEREF 1 \\s }日&quot; 这一部分是将“一九一一年一月{ STYLEREF 1 \\s }日”插入到域代码所在位置，如果是第一章，那么最终结果就是一九一一年一月一日。 看到这里，也许你已经猜到后面那个\\@&quot;D&quot;开关是在干什么了： 设置域结果格式-微软官方日期-时间格式开关 (\\ @) 指定如何显示日期或时间。 例如, switch \\ @ “dddd, mmmm d, yyyy” 字段{ DATE \\ @ “dddd, MMMM d, yyyy” }显示 “星期五, 2019 年11月23日”。结合以下日期和时间说明: day (d)、month (M) 和 year (y);小时 (h) 和分钟 (m)-生成日期时间格式。你还可以包含文本、标点和空格。 字母 d 显示月份中的日期或一个星期中的某一天。 字母 d 可以大写或小写。此格式项目将某个星期或月份的某一天显示为数字；对于单位数日子，数字前面不加 0（零）。 例如，某月的第 6 天显示为 6 。 所以该开关的意思是，将最终结果中的“天”给显示出来，而我们前面的内容得到的是一九一一年一月一日，那么输出结果就是 1，这样就通过日期转换将汉字数字转换为阿拉伯数字了。 这个日期无关紧要，只要格式是中文日期即可，例如我改为 {QUOTE “二零二一年四月{ STYLEREF 1 \\s }日” \\@”D”}也没有关系。 之后再使用组合键 Alt+F9 ，就可以隐藏域代码，只显示域代码的结果了。 优化虽然问题解决了，但是每次都要输入这样的域代码非常费劲。我在B站找到了一个视频，up主的解决方案很好：word将“图一.x”修改为“图1.x”-Bilibili。 他使用了word的另一个好用的功能——构建基块。 选中刚刚写好的题注 使用组合键 Alt+F3 ，会弹出一个名为“新建构建基块”的对话框，修改构建基块的名称。例如修改为“图注”。 点击“确定”保存 之后如果想要插入这样的题注，那么直接输入该构建基块的名称（此处为“图注”二字），word就会在你输入的地方显示一个提示“按Enter插入”，此时按下Enter键，就可以插入这一个构建基块了。","link":"/posts/2028856356/"},{"title":"从markdown到nga bbscode的转换程序","text":"NGA（艾泽拉斯国家地理）论坛使用一种自定义的名为 bbscode 的代码来排版帖子内容，类似HTML，它也是一种标记语言，对bbscode的详细介绍可见：[NGA常用BBS代码][奥运帖]Project N —— 《从入门到精通：排版的艺术 Ver.3》。 这种论坛自定义标记语言可以和markdown、html进行相互转换。例子如下: 1234567[h]标题[/h][b]加粗文字[/b][list][*] 列表项[*] 列表项[/list][quote]引用块[/quote] 在使用NGA论坛的时候遇到了将markdown文本转换为bbscode的需求，所以打算用python写一个简单的转换程序。由于不涉及复杂的GUI，本项目使用tkinter来编写界面。 项目地址： [github仓库地址] [gitee仓库地址] NGA论坛内本工具软件的发布帖 效果 自定义包自定义包 bbscode结构非常简单，只含有 __init__.py和一个python文件 converter.py 。 converter.py中含有 md_to_bbscode这一核心转换方法，参数为markdown文本字符串，返回bbscode字符串。 这个转换函数的原理非常简单，只用到了python的一个正则表达式替换方法 re.sub，它的参数分别为： pattern：用于匹配替换内容的正则表达式 repl：用于替换匹配结果的字符串（在其中可以使用\\匹配组下标表示匹配组，从1开始），或者用于处理匹配结果的函数 string：被处理的字符串 count：可选，模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。 flags：可选，正则匹配模式 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import redef replace_quote(matched): quote = matched.group(1) quote = re.sub(r&quot;&gt; (.*?)&quot;,&quot;&quot;,quote) quote = &quot;[quote]\\n{}\\n[/quote]&quot;.format(quote) return quotedef replace_list(matched): l = matched.group(1) l = re.sub(r&quot;[-*] &quot;,&quot;[*]&quot;,l) l = &quot;[list]\\n{}\\n[/list]&quot;.format(l) return ldef replace_italic(matched): # 到了第53个中文字符的时候NGA论坛就会报错：一二三四五六七八九十一二三四五六七八九十一二三四五六七八九十一二三四五六七八九十一二三四五六七八九十一二三/* bbscode i too long */ # 所以需要每50个字符就分一个[i]标签 italic = matched.group(1) step = 50 italics = [italic[i:i+step] for i in range(0,len(italic),step)] italic = '' for item in italics: italic +=&quot;[i]{}[/i]&quot;.format(item) return italicdef md_to_bbscode(md_str:str): ''' 将markdown字符串转换为bbscode字符串 ''' bbscode = md_str # 链接 bbscode = re.sub(r&quot;[^!]\\[(.*?)\\]\\((.*?)\\)&quot;,r&quot;[url=\\2]\\1[/url]&quot;,bbscode) # 图片 bbscode = re.sub(r&quot;\\!\\[(.*?)\\]\\((.*?)\\)&quot;,r&quot;[img]\\2[/img]&quot;,bbscode) # 标题，注意设置flag为MULTILINE以改变^的语义 bbscode = re.sub(r&quot;^(#+)\\s?(.*)&quot;,r&quot;[h]\\2[/h]&quot;,bbscode,flags=re.MULTILINE) # 加粗 bbscode = re.sub(r&quot;\\*\\*(.*?)\\*\\*&quot;,r&quot;[b]\\1[/b]&quot;,bbscode) # 斜体 bbscode = re.sub(r&quot;\\*(.*?)\\*&quot;,replace_italic,bbscode) # 下划线 bbscode = re.sub(r&quot;&lt;u&gt;(.*?)&lt;/u&gt;&quot;,r&quot;[u]\\1[/u]&quot;,bbscode) # 删除线 bbscode = re.sub(r&quot;~~(.*?)~~&quot;,r&quot;[del]\\1[/del]&quot;,bbscode) # 引用块 bbscode = re.sub(r&quot;((&gt; (.*)\\n?)+)&quot;,replace_quote,bbscode) # 列表 bbscode = re.sub(r&quot;(([-|*] (.*)\\n?)+)&quot;,replace_list,bbscode) return bbscode 无序列表的替换从代码可以看出，大部分markdown代码都可以直接转换为bbscode，但对于列表、引用块来说，它们对应的bbscode除了项目符号之外，还需要在两侧加上对应的标签，这就无法直接替换，需要编写自定义repl函数了。 以无序列表的转换为例，markdown的无序列表代码如下： 12345- 列表项1- 列表项2* 列表项a* 列表项b 以上两种方式都是无序列表。需要将它们转换为： 123456789[list][*] 列表项1[*] 列表项2[/list][list][*] 列表项a[*] 列表项b[/list] 首先需要用正则表达式匹配到每一个列表项，匹配单个列表项： [-|*] (.*)\\n? 如果想要匹配多行列表项，就需要使用循环匹配符号 +，至少匹配一项。即：([-|*] (.*)\\n?)+ 但是此时取匹配组1是取不到所有列表项的，在外面再套一层括号，这时的匹配组1就是我们要的整个无序列表了。 在替换函数 replace_list中，参数为正则表达式的匹配对象，将项目符号替换并在前后添加 [list]标签即可。 12345def replace_list(matched): l = matched.group(1) l = re.sub(r&quot;[-*] &quot;,&quot;[*]&quot;,l) l = &quot;[list]\\n{}\\n[/list]&quot;.format(l) return l 多行引用转bbscode引用块的原理相同，不赘述。 界面需要编写的界面只有一个多行输入框加上按钮，直接放代码： 1234567891011121314151617181920212223import tkinter as tkfrom bbscode import converterroot = tk.Tk()root.title(&quot;bbscode转换器&quot;)# 输入框inputText = tk.Text(root,height=20,width=100)inputText.pack()# 转换按钮def md_to_bbscode(): md_str = inputText.get('1.0',tk.END) bbscode = converter.md_to_bbscode(md_str) inputText.delete('1.0', tk.END) inputText.insert('1.0',bbscode)convertBtn = tk.Button(root,text=&quot;markdown转换为bbscode&quot;,command=md_to_bbscode)convertBtn.pack()root.mainloop()","link":"/posts/markdown-bbscode-converter/"},{"title":"《算法笔记》C与C++语言相关","text":"这是一篇学习笔记，基于胡凡主编的《算法笔记》的第二章“C/C++快速入门”。 在学习那一章的过程中，我将其中之后用的到的内容整理为这篇笔记，适合了解C和C++语言的人用于复习其语法中与做算法题相关的特性与技巧。 本文中部分内容经过顺序调整和补充，不完全按照原书内容。详细内容请看原书。 变量类型整型%d为int输出格式。 %lld为long long输出格式 32位或者$10^9$以内的整数：int 64位或者$10^{18}$以内的整数：long long。且字面量后面要加上LL后缀 浮点型%f为float和double的输出格式。 %lf为double输入格式。 都用double型就好。float型只有6-7位有效精度，double型有15-16位。 字符型%c为char型输出格式。 %s为char数组输出格式。 布尔型c++中直接用，c中得添加stdbool.h头文件。 整型常量赋值给布尔变量时0为false，非0为true。 作为整型数据输出时，true为1，false为0。 强制类型转换12(新类型名)变量名//C中的转换新类型名(变量名)//C++才能用 无穷大的表示无穷大INF可以设置为int型的最大值，即$(1&lt;&lt;31)-1$。 但更常用$2^{30}-1$以避免相加之后溢出，它的十六进制形式：0x3fffffff 12const int INF = (1&lt;&lt;31)-1;const int INF = 0x3fffffff; 条件表达式的简化 条件表达式为表达式!=0可以省略!=0 条件表达式为表达式==0时可以省略==0并取反，即变为!表达式 常用math函数头文件:math.h 函数 说明 fabs(double x) 对double变量取绝对值 floor(double x)、ceil(double x) 对double变量向下取整、向上取整，但返回值为double型 pow(double r,double p) 返回$r^p$ sqrt(double x) 返回x的算术平方根 log(double x) 返回$lnx$,需要用换底公式$\\log_ab=\\frac{lnb}{lna}$得到其他底数的对数 sin(double x)等三角函数 asin(double x)等反三角函数 round(double x) 返回保留整数部分的四舍五入后的x，但返回值为double型 常用字符串函数头文件：string.h 函数 说明 strlen(字符数组) 返回字符串长度，不含\\0 strcmp(字符数组1,字符数组2) 按字典序比较大小，串1大于串2返回正整数，小于则返回负整数，等于则返回0 strcpy(字符数组1,字符数组2) 将字符数组2的内容复制到字符数组1，包括\\0 strcat(字符数组1,字符数组2) 将字符数组2接到字符数组1后面 数组数组初始化定义数组时初始化12345678910/*一维数组*/int a[10] = {1,2,3,4};//其余元素（a[4]~a[9]）被赋值为0int b[10] = {0};//声明一个长度为10的数组并将a[0]赋值为0，并使得其余元素默认为0//若不赋予初值，则元素初值为随机值int c[10] = {};//c++才能这么写，c中会报错/*二维数组*/int d[5][6] = {{3,1,2},{8,4},{},{1,2,3,4,5}};//其余元素被赋值为0，同样的，空{}在c中报错/*字符数组*/char str1[6] = {'H','e','l','l','0','\\0'};//同整数数组char str2[6] = &quot;Hello&quot;//这种方式字符串以\\0结尾 若数组大小过大（$10^6$级别），需要将其定义在主函数外面。 因为函数内部局部变量使用系统栈，空间较小，容易栈溢； 而函数外部全局变量使用静态存储区，空间较大。 123456#include &lt;stdio.h&gt;int a[1000000];//10^6级别定义在外部int main(){ return 0;} 利用memset函数初始化头文件：string.h 用于给某个范围内的内存区域的每个字节赋相同的值。 123memset(首地址,每个字节的值,区域长度);//初始化数组。多维数组与之相同memset(数组名,值,sizeof(数组名));//给数组的每个元素赋相同的值。一般赋值0或-1，不容易出错。 由于0的补码为全0,-1的补码为全1，不容易赋值错误，尽量只用memset设置这两种初值，赋其他值使用fill函数。 以数组作为函数参数 参数中数组的第一维可以省略。但第二维以及更高维的长度不可省略。 数组作为参数时，对数组元素的修改等同于对原数组元素的修改。（我的理解：数组名仍然是值传递，但是复制给形参的只不过是数组首地址，根据这个首地址对数组元素寻址到的数组元素就是原本的数组元素） 浮点数比较由于浮点数存储的误差，不能直接用==来比较两个浮点数是否相等，需要用一个极小数eps来修正。 123456789const double eps = 1e-8;//10^-8//为了方便使用，可以定义如下的宏#define Equ(a,b) ((fabs((a)-(b)))&lt;(eps))#define More(a,b) ((a)-(b)&gt;(eps))#define Less(a,b) ((a)-(b)&lt;(-eps))#define MoreEqu(a,b) ((a)-(b)&gt;(-eps))#define LessEqu(a,b) ((a)-(b)&lt;(eps))//圆周率const double PI = acos(-1.0); 复杂度一般的OJ系统一秒运算次数约为$10^7-10^8$. 因此$O(n^2)$的复杂度在n=1000时是可以承受的（$10^6$级别），n=100000时是不可承受的（$10^{10}$级别） 指针123456int *p1,p2;//注意：p1为int*，但p2为intint *p3,*p4;//这样才是将二者都定义为int*int a=1,b=2;int *p5 = &amp;a, *p6 = &amp;b;//用取址符&amp;取变量地址并赋值给指针变量(*p5)++;//将p5指向的存储空间内的值自增1printf(&quot;%d %d&quot;,*p5,*p6);//用取值符*取地址对应的值，这里输出&quot;2 2&quot; 指针是一个unsigned类型的整数。 指针变量可以进行加法，对int*p来说，p+1代表下一个int型变量地址。支持自增操作。 指针变量可以进行减法，减法结果是两个地址偏移的距离，距离以指针的基类型为单位。支持自减操作。 指针与数组数组名称可作为数组首地址使用，即对于int数组a：a==&amp;a[0]，a+i==&amp;a[i]，*(a+i)==a[i] 123int a[10]={0};int *p=a,*q=&amp;a[5];printf(&quot;%d&quot;,q - p);//输出5而非20，因为这里的差值以int为单位 引用用于产生变量的别名，无法对常量使用。在函数参数类型后加上&amp;，这样就可以将形参作为实参的别名，对形参的修改可以影响到实参。 这是c++的语法，c中会报错。 123void change(int &amp;x) { x = 1;//可以改变传入的参数} 指针的引用： 123456void swap(int* &amp;p1,int* &amp;p2){//交换的是传入的两个指针 int*temp = p1; p1 = p2; p2 = temp;} 结构体定义1234567891011//定义举例struct student{ int id; char name[20]; student* next;//无法定义自身类型，但是可以定义自身类型的指针。C语言中会报错，C++不会报错。}stu,*p;//定义完之后可以同时定义对应的变量p = &amp;stu;//访问结构体的元素stu.id = 1;(*p).id = 2;p-&gt;id = 2; 初始化构造函数使用构造函数（C++才有，C没有）。默认会生成无参构造函数，但如果自己定义了，那么就不会生成默认的无参构造函数。构造函数可以重载。 12345678struct student{ int id; char gender; student(int _id,char _gender){ id=_id;gender=_gender; }};student stu = student(1,'M'); 或者用简化版： 123456struct student{ int id; char gender; student(int _id,char _gender):id(_id),gender(_gender){}};student stu = student(1,'M'); 初始化列表12345struct student { int id; char gender;};student stu = { 1,'M' };//顺序对应即可 复制可以直接用=复制相同类型的结构体变量，C和C++均可。但是这种方式是浅拷贝，对指针成员只复制地址，不复制指向的内容。 123456789101112#include &lt;stdio.h&gt;struct student { int id; char gender;}stu1,stu2;int main(){ stu1.id = 1; stu1.gender = 'M'; stu2 = stu1; printf(&quot;%d %c&quot;, stu2.id, stu2.gender);//输出&quot;1 M&quot;} 输入输出scanf输入12345scanf(&quot;格式控制串&quot;,变量地址);//变量前记得加&amp;取地址，数组名称本身就是地址scanf(&quot;%d:%d:%d&quot;,&amp;hh,&amp;mm,&amp;ss);//输入&quot;13:45:20&quot;格式的数据scanf(&quot;%d%d&quot;,&amp;a,&amp;b);//输入&quot;3 4&quot;这类空格隔开的数字时，可以省略空格//因为除了%c之外，对其他格式符的输入以空白符为结束标志//字符数组使用%s，读入时以空格和换行为结束标志，因此scanf无法直接读入带空格或换行的字符串到一个字符数组中 scanf的返回值为成功赋值的变量个数，如果遇到错误或者EOF，则返回值为EOF printf输出double输入用 %lf，输出用%f。 助记：读进来的时候要严格一些，需要知道你是double还是float，但是输出的时候没那么严格，因为可以隐式转换。就像小区保安需要你刷卡进小区，但是出小区时不管你是不是住户，直接给你开门就行。 默认输出6位小数，不足六位以 0 补齐,超过六位按四舍五入截断 1234567#include &lt;stdio.h&gt;int main(){ double a; scanf(&quot;%lf&quot;, &amp;a);//123456789.123456789 printf(&quot;%f&quot;, a);//123456789.123457} 实用输出格式： 输出格式 说明 %md 使不足m位的int变量以m位右对齐输出，高位空格补齐。超过m位保持不变。 %0md 同%md，只不过高位用0补齐而不是空格 %.mf 让浮点数保留m位小数输出，四舍六入五成双，“保留m位小数”用这个即可。不考虑怎么舍入 getchar和putchar分别为输入和输出单个字符，可接收换行符。 123char c;c = getchar();putchar(c); gets和puts分别为输入和输出一行字符串，并存放在一维数组中。 puts输出时自带换行。 123456789#include &lt;stdio.h&gt;int main(){ char a[] = &quot;abc&quot;; char b[] = &quot;def&quot;; puts(a); puts(b);//输出结果里b字符串换了一行来显示 printf(&quot;%d&quot;, sizeof(a));//输出4而不是3，所以这种初始化方式末尾是带有\\0的} 输出： 123abcdef4 gets以换行符结束，不同于scanf以空白符结束，所以可以读入带空格的字符。 因此scanf完一个整数后，如果要使用gets，需要先用getchar接收整数后的换行符。 gets与scanf都会自动在读入的字符串末尾添加\\0 sscanf和sprintf头文件：string.h 即在scanf和printf前面再加一个字符数组参数，输入输出的源头与目的就变成了该字符数组，用法同scanf和printf cin和cout头文件：iostream 命名空间：std C++输入输出函数，速度比不上scanf和printf，在算法题中一般不用。 12345cin&gt;&gt;n&gt;&gt;c&gt;&gt;a&gt;&gt;b;//可以连续读入多个变量，无需指定类型char str[100];cin.getline(str,100);//读入一整行需要用getline函数string str2;//STL中的string容器getline(cin,str); 1234cout&lt;&lt;a&lt;&lt;b&lt;&lt;c&lt;&lt;d&lt;&lt;endl;//可以连续输出多个变量，无需指定类型。endl表示换行//格式化输出#include &lt;iomanip&gt;cout &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setprecision(2) &lt;&lt; 123.4567 &lt;&lt; endl;//输出123.46","link":"/posts/c-and-cpp-grammar-in-algorithm-note/"},{"title":"自制的第一个vscode语言扩展插件","text":"最近迷上了TRPG（Tabletop Role-playing game，桌上角色扮演游戏），即俗称的“跑团”。玩家在主持人的引导下，扮演自己的游戏角色进行冒险。在结束之后，会有想要将这个过程记录下来的欲望，从而有了各种各样的“跑团replay视频”。 制作跑团replay视频比较复杂，但回声工坊这一高效工具的出现，让这个过程变得非常简单，只需要找好媒体素材（角色立绘、背景图片、BGM、音效等）以及处理一下跑团Log（即跑团游戏记录）就可以很快输出一集视频。 为了更加方便跑团replay视频的制作，我编写了一个vscode插件——TRPG Replay Generator Log——来方便跑团Log的处理。 本文对编写这个插件的过程做一个记录和总结。 参考链接 Visual Studio Code Syntax Highlight Guide Visual Studio Code publishing extension TextMate language grammars 目标回声工坊这个软件所做的工作其实是根据输入的特定格式的Log文件、媒体定义文件、角色配置文件，将准备好的各种素材按照一定的规则拼接在一起。 回声工坊的Log文件的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 综合演示&lt;set:formula&gt;:sincurve&lt;set:am_method_default&gt;:&lt;pass_up_black=20&gt;&lt;set:tx_method_default&gt;:&lt;w2w=1&gt;&lt;set:bb_method_default&gt;:&lt;replace=0&gt;&lt;set:BGM&gt;:BGM1&lt;set:speech_speed&gt;:500&lt;background&gt;&lt;replace=30&gt;:bg1[张安翔]:^本视频是DanDDXuanX 编写的#TRPG-Replay-Generator的基本演示工程。{SE1;*3.5}[KP]:项目链接：#https://github.com/DanDDXuanX/TRPG-Replay-Generator{SE1;5}&lt;set:speech_speed&gt;:300&lt;hitpoint&gt;:(张安翔,10,10,9)[张安翔]:^本工具基于python3 和 pygame2.0，在windows10系统上开发。#演示使用的媒体素材来自网络，侵删。{SE1;5}[张安翔]:那么，演示开始。{SE1;5}&lt;dice&gt;:(测试姓名1 力量,100,75,3),(测试姓名2 sancheck,100,60,25),(测试姓名3 图书馆,100,75,85),(测试姓名4 侦察,100,60,100)&lt;hitpoint&gt;:(张安翔,10,9,5)&lt;dice&gt;:(测试姓名1 力量,100,75,3),(测试姓名2 sancheck,100,60,25),(测试姓名3 图书馆,100,75,85),(测试姓名4 侦察,100,60,100)&lt;dice&gt;:(1d8,8,NA,4),(1d4,4,NA,4)&lt;hitpoint&gt;:(短,4,4,1)&lt;hitpoint&gt;:(用来测试的一极长文本,4,1,4)&lt;background&gt;&lt;cross=60&gt;:bg2&lt;set:speech_speed&gt;:250&lt;set:am_method_default&gt;:&lt;replace=0&gt;&lt;set:tx_method_default&gt;:&lt;all=0&gt;&lt;set:am_dur_default&gt;:10&lt;set:tx_dur_default&gt;:7&lt;set:BGM&gt;:stop[张安翔]:在对话行里建立最基本的发言小节，播放基本音效。{SE1;5}[KP]&lt;black&gt;:使用切换效果修饰符，指定切换模式为渐隐。{SE1;5}&lt;hitpoint&gt;:(张安翔,10,5,7)[张安翔]&lt;black=30&gt;:在切换效果修饰符中，指定切换时间为30。{SE1;5}[KP]&lt;black&gt;:使用文本效果修饰符，指定文字显示模式为逐字显示。&lt;w2w&gt;{SE1;5}[张安翔]&lt;black&gt;:在文本效果修饰符中，指定单位时间为2。&lt;w2w=2&gt;{SE1;5}&lt;hitpoint&gt;:(张安翔,10,7,4)[张安翔,KP.double]&lt;black&gt;:在角色框里指定多位角色，实现多人同框。&lt;w2w=2&gt;{SE1;5}[KP.double,张安翔]&lt;black&gt;:置于首位的角色为主要发言人，其余角色设置为半透明。&lt;w2w=2&gt;{SE1;5}&lt;set:BGM&gt;:BGM1[旁白]&lt;black&gt;:没有立绘的文本框同样以角色的形式在角色表里定义，可以作为旁白或者骰子使用。&lt;w2w=2&gt;&lt;hitpoint&gt;:(张安翔,10,4,9)&lt;set:BGM&gt;:stop&lt;background&gt;&lt;black=60&gt;:bg1[张安翔(60),KP.double]&lt;replace=0&gt;:调整角色的透明度参数，手动设置立绘透明度。&lt;w2w=5&gt;{SE1;5}[张安翔.scared,KP.double]:指明角色的subtype，展示差分立绘。&lt;w2w=5&gt;{SE1;5}[张安翔,KP.double]:在发言文本中以井号作为换行符；#设置手动换行模式；#并逐行显示内容。&lt;l2l=5&gt;{SE1;5}[旁白]&lt;black&gt;:———————演示结束——————&lt;hitpoint&gt;:(张安翔,10,9,0) 回声工坊的作者用的是Sublime，所以他只写了适用于Sublime的语法高亮文件，用vscode编辑跑团Log的我就没法享受到语法高亮了。 于是我打算照着作者发在交流群里的Sublime语法高亮文件来写一个vscode语法高亮文件之类的东西，不过后来发现还是得开发一个语言扩展才行。 找到了这样一篇官网的文档：Visual Studio Code Syntax Highlight Guide-官网文档，接着开始开发vscode扩展。 搭建环境安装脚手架工具按照Your First Extension这篇文章中说的那样，首先安装Node.js和Git，接着用下面的命令安装Yeoman和VS Code Extension Generator： 1npm install -g yo generator-code Yeoman是个脚手架工具，可以用简单的指令快速搭建好开发环境。安装完毕之后，使用如下指令唤出一个命令行菜单，用上下箭头按键来选择要搭建的环境。 1yo code 选择要搭建的扩展借用官网文档中的图片： 输入一些基本信息 从回声工坊的作者写的sublime语法高亮文件RepGenLog.sublime-syntax中可以知道他将回声工坊的log文件的扩展名定义为“.rgl”，也就是Replay Generator Log的首字母缩写（一开始我还记错成“.rpl”，以为是“replay”的缩写），所以这个语言扩展的名字就定为了“TRPG Replay Generator Log”，语言名称也定为“rgl” 因为官网的文档已经说的很详细了，这部分就不细说了，不想单纯复制粘贴。 package.json文件生成好的文件当中，比较重要的就是这个package.json文件了，因为这个扩展插件的基本信息都在这个里面，主要的文件的路径也是在这里配置。 1234567891011121314151617181920212223242526{ &quot;name&quot;: &quot;trpg-replay-generator-log&quot;, &quot;displayName&quot;: &quot;TRPG Replay Generator Log&quot;, &quot;description&quot;: &quot;Syntax highlighting and code snippets for TRPG-Replay-Generator-Log language&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;engines&quot;: { &quot;vscode&quot;: &quot;^1.67.0&quot; }, &quot;publisher&quot;: &quot;yxChangingSelf&quot;, &quot;categories&quot;: [ &quot;Programming Languages&quot;,&quot;Themes&quot;,&quot;Snippets&quot; ], &quot;contributes&quot;: { &quot;languages&quot;: [{ &quot;id&quot;: &quot;rgl&quot;, &quot;aliases&quot;: [&quot;rgl&quot;, &quot;rgl&quot;], &quot;extensions&quot;: [&quot;.rgl&quot;], &quot;configuration&quot;: &quot;./language-configuration.json&quot; }] ,&quot;grammars&quot;: [{ &quot;language&quot;: &quot;rgl&quot;, &quot;scopeName&quot;: &quot;source.rgl&quot;, &quot;path&quot;: &quot;./syntaxes/rgl.tmLanguage.json&quot; }] }} 这里注意其中的contributes，这里配置了languages和grammars两个属性。 前者配置了语言相关的内容，包括id、与该语言关联的文件扩展名以及语言配置文件的路径”./language-configuration.json”。 后者配置了语法相关的内容，包括展示给人看的语言名称、根scope以及语法定义文件的路径”./syntaxes/rgl.tmLanguage.json”。 因为目前只需要语法高亮，可以先看后面这个文件。 标记化（Tokenization）要实现语法高亮，首先需要将这个语言标记化，学过编译原理的应该知道这就是词法分析那一步，也就是将输入划分为一个个词法单元（Token），告诉计算机每一个词法单元是哪一类。（Breaking text into a list of tokens） Each token is associated with a scope that defines the context of the token. A scope is a dot separated list of identifiers that specify the context of the current token. The + operation in JavaScript, for example, has the scope keyword.operator.arithmetic.js. 这里的scope就是我们需要为token打上的“标记”了。 简单来说，就是我们需要先将各种token分好类，之后才方便将同类的东西染上相同的颜色。 TextMate VS Code 使用 TextMate 语法作为语法标记引擎。为 TextMate 编辑器发明，由于开源社区创建和维护的大量语言包，它们已被许多其他编辑器和 IDE 采用。 TextMate的语法详见：TextMate language_grammars 详细的就不说了，只说用到的部分。 主要有两种形式： 1234{ &quot;name&quot;: &quot;comment.line&quot;, &quot;match&quot;: &quot;^#.+$&quot;} 就是将name所定义的scope分配给match用正则表达式匹配出对应的token。 另一种形式是： 1234567891011{ &quot;name&quot; :'string.quoted.double.untitled', &quot;begin&quot; : &quot;\\&quot;&quot;, &quot;end&quot; : &quot;\\&quot;&quot;, &quot;patterns&quot; : [ { &quot;name&quot; = 'constant.character.escape.untitled', &quot;match&quot; = &quot;\\\\.&quot; } ]} begin和end定义了首尾，将其中所有的内容分配为name定义的scope，其中的patterns属性是在被begin和end框定的范围内继续进行标记。 调试写好之后用f5运行一个加载了该扩展的vscode窗口来检查写的是否正确，可以在ctrl+shift+p调出来的命令面板中输入Developer: Inspect Editor Tokens and Scopes来开启Scope inspector这个东西，它可以显示光标所在位置的token的scope，方便检查 最后写好的语法高亮文件rgl.tmLanguage.json: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485{ &quot;$schema&quot;: &quot;https://raw.githubusercontent.com/martinring/tmlanguage/master/tmlanguage.json&quot;, &quot;name&quot;: &quot;rgl&quot;, &quot;patterns&quot;: [ {&quot;include&quot;: &quot;#comments&quot;} ,{&quot;include&quot;: &quot;#dialog&quot;} ,{&quot;include&quot;: &quot;#command&quot;} ,{&quot;include&quot;: &quot;#error&quot;} ], &quot;repository&quot;: { &quot;comments&quot;:{ &quot;patterns&quot;: [{ &quot;name&quot;: &quot;comment.line&quot;, &quot;match&quot;: &quot;^#.+$&quot; }] }, &quot;dialog&quot;:{ &quot;patterns&quot;: [{ &quot;name&quot;: &quot;entity.name.function&quot;, &quot;begin&quot;: &quot;(?=^\\\\[)&quot;, &quot;end&quot;:&quot;\\n&quot;, &quot;patterns&quot;: [{ &quot;name&quot;: &quot;variable.parameter&quot;, &quot;match&quot;: &quot;^\\\\[([\\\\ \\\\w\\\\.\\\\;\\\\(\\\\)\\\\,]+)\\\\]&quot; } ,{ &quot;name&quot;: &quot;punctuation.colon&quot;, &quot;match&quot;: &quot;\\\\B:&quot; } ,{ &quot;name&quot;: &quot;keyword.operator&quot;, &quot;match&quot;: &quot;(\\\\^|#)&quot; } ,{ &quot;name&quot;: &quot;storage.type&quot;, &quot;match&quot;: &quot;&lt;\\\\w+(\\\\=\\\\d+)?&gt;&quot; } ,{ &quot;name&quot;: &quot;string.quoted.double&quot;, &quot;match&quot;: &quot;({.+})?$&quot; } ] }] }, &quot;command&quot;:{ &quot;patterns&quot;: [{ &quot;name&quot;: &quot;entity.name.function&quot;, &quot;begin&quot;: &quot;(?=^&lt;(set:[^&gt;]+|background|dice|hitpoint)&gt;)&quot;, &quot;end&quot;:&quot;\\n&quot;, &quot;patterns&quot;: [{ &quot;name&quot;: &quot;keyword.control&quot;, &quot;match&quot;: &quot;^&lt;(set:[^&gt;]+|background|dice|hitpoint)&gt;&quot; },{ &quot;name&quot;: &quot;punctuation.colon&quot;, &quot;match&quot;: &quot;\\\\B:&quot; } ,{ &quot;name&quot;: &quot;constant.numeric&quot;, &quot;match&quot;: &quot;\\\\b(-)?\\\\d+$\\\\b&quot; } ,{ &quot;name&quot;: &quot;keyword.declaration.function&quot;, &quot;match&quot;: &quot;(linear|quadratic|quadraticR|sigmoid|right|left|sincurve)&quot; } ,{ &quot;name&quot;: &quot;storage.type&quot;, &quot;match&quot;: &quot;&lt;\\\\w+(\\\\=\\\\d+)?&gt;&quot; } ,{ &quot;name&quot;: &quot;variable.parameter&quot;, &quot;match&quot;: &quot;\\\\((.+?),(\\\\d+),([\\\\d]+|NA),(\\\\d+)\\\\)&quot; } ] }] }, &quot;error&quot;:{ &quot;patterns&quot;: [{ &quot;name&quot;: &quot;invalid.illegal&quot;, &quot;match&quot;: &quot;^[\\\\t\\\\ ]+$&quot; }] } }, &quot;scopeName&quot;: &quot;source.rgl&quot;} 主题化（Theming）标记好了所有的元素之后，就可以开始给它们染色了，也就是“使用主题或用户设置将标记映射到特定的颜色和样式”（Using themes or user settings to map the tokens to specific colors and styles） 其实没有这一步也是可以的，因为标记了这些token之后，运行时可以看到已经染好色了，这是正在使用的vscode主题根据这些标记染的色。 不过为了和回声工坊作者的语法高亮显示效果尽量一致，我自定义了一个主题rgl theme，调整配色。 因为不知道怎么在项目中创建主题，官网文档里面也只是说在一开始的时候用脚手架创建，我就用yo code命令创建了一个自定义主题的插件的项目，对比两个项目的不同，接着合并两个项目。 在package.json里面新增了themes这一项，指定了主题定义文件的路径，最后再在自动生成的文件中修改需要修改的颜色就行了。 12345678910111213141516171819202122{ &quot;contributes&quot;: { &quot;languages&quot;: [{ &quot;id&quot;: &quot;rgl&quot;, &quot;aliases&quot;: [&quot;rgl&quot;, &quot;rgl&quot;], &quot;extensions&quot;: [&quot;.rgl&quot;], &quot;configuration&quot;: &quot;./language-configuration.json&quot; }] ,&quot;grammars&quot;: [{ &quot;language&quot;: &quot;rgl&quot;, &quot;scopeName&quot;: &quot;source.rgl&quot;, &quot;path&quot;: &quot;./syntaxes/rgl.tmLanguage.json&quot; }] ,&quot;themes&quot;: [ { &quot;label&quot;: &quot;rgl theme&quot;, &quot;uiTheme&quot;: &quot;vs-dark&quot;, &quot;path&quot;: &quot;./themes/rgl theme-color-theme.json&quot; } ] }} 发布详细步骤参考：Visual Studio Code publishing extension-官网文档 简要步骤（请查看官网文档，这里仅仅是简化步骤）： 安装VSCE。vsce是“Visual Studio Code Extensions”的缩写，是一个用于打包、发布和管理 VS Code 扩展的命令行工具。 在Azure DevOps中创建自己的组织，需要微软账号 在组织主页获取Personal access tokens，这个token需要开放Marketplace下的Manage权限 创建发布者，需要和刚才创建组织时登录的是同一个微软账号 使用vsce login &lt;publisher name&gt;命令，并用之前获取的Personal access tokens来验证 在扩展插件的文件夹内使用vsce publish命令发布扩展 看起来很复杂，但实际上做起来很快，没有遇到什么困难（除了纠结用什么名字之外） 前面的步骤都完成之后，以后发布新版本就只需要最后一步，即使用vsce publish命令发布扩展，很方便。","link":"/posts/vscode-extension/"},{"title":"Hexo部署博客的过程记录","text":"建立 Hexo 博客的相关知识整理成的笔记，不太全面。 缘起这部分算是年终总结一样的东西吧。 在 2018 年 8 月底的时候，我还是对域名、服务器等名词没有了解的一个 web 小白，那时一个朋友在群里发了一个非常好看的个人博客，我一下子就被吸引了，羡慕但是又没有能力自己弄，感觉太难了。当时我只学过一点 HTML 和 CSS，javaScript 还未怎么学，而且已经很久没有练习过，已经忘得差不多。 那个朋友东给我发了一个《基于 CentOS 搭建 WordPress 个人博客》的页面，东说他想弄，已经租了个腾讯云服务器，问我有没有兴趣。我当时还是蛮犹豫的，对于我来说难度还是很大的，那个网页上并不是个教程，说的内容我大部分看不懂。不过我还是想整一个的，于是尝试去学。 我属于那种“如果不能基本上理解一个概念，那么就会完全拒绝相关的知识输入，即便已经记住了也不会长久”的学习类型，而且以前又比较自闭，不想问别人，只在网上查找已有的问题答案，所以学习起来特别困难。 买了域名，备了案，租了学生价服务器，照着教程《新手如何用腾讯云服务器搭建一个 wordPress 博客-简书》鼓捣了好久终于弄出来一个 wordPress 博客。但我当时仅仅是“知其然而不知其所以然”，并不认为自己学到了什么，弄好了主页就一直搁置在那里，感觉心疼租服务器的钱但是又没办法。开学了又有很多事情要忙，大学并不像高中的时候想象的那么悠闲。 直到一个学期结束我才考虑起开始重新弄个博客。经过了一个学期，我学会了更多的东西，把上个暑假的建博客的流程给理解了应该没什么问题。 我开始整理以前编程留下的笔记。以前使用的是 vnote，但是我觉得界面不太好看，而且功能大多用不上，遇到问题百度也搜不到，碰巧它这时又不知道出了什么毛病，于是换成了 Typora，把笔记重新筛选了一遍。分类尽可能少，渐渐地开始“一元化”笔记。 随后又想起了以前只学了一点的 git。没有一次性学完它，导致我没有去用它，顶多只是使用网页版 github 上传一下代码点亮小绿块让自己爽一下，也搁置了很久。说起来我真是喜欢半途而废。 不如把这整理好的笔记传到 github 上面备份吧，感觉比网盘备份 b 格高。刚好前几天学 Python 的时候找到了廖雪峰的 git 教程，这让我有些后悔没有听另一个朋友朱的推荐。 整 github 的时候又发现了 github page 的功能，想起来 github 也可以搭博客，所以今天（2019-2-6）就研究了一整天搭好了这个博客。挑了个和我以前羡慕的个人博客相同的主题，美滋滋，成就感爆棚。 好了，接下来我来分享一下我是如何搭建这样一个博客的。不保证零基础能看懂。 Hexo——一个博客框架和 WordPress 差不多，都是用来搭建博客的一个框架。但是问题来了—— 框架，又是啥？ 自学计算机类的知识最大的问题就在于百度到的东西需要各种各样的前置知识，很难一下子理解那是什么意思，越听越迷糊。不管在看这篇博客的你知不知道框架的意思，反正上个暑假的我是不明白的。而且这是简称，光百度一个“框架”好像又搜不到明确的定义。 这个障碍一直妨碍着我对bootstrap、vue、MFC、QT等框架的准确理解，后来我才知道，软件框架到底是个啥 简而言之，在我的理解里面，框架，就是可以复用的代码，就是“不要重复造轮子”中的“轮子”，就是别人已经写好的封装了各种复杂 API 的库。框架可以帮你完成一些基础语法本身也可以完成的事情，让你不必在建房子的时候从烧砖开始，而是可以解放思维直接开始画楼房设计图。 Hexo，就是一个可以帮助你生成静态网页的一个工具，所有的核心功能比如打标签归档加时间，以及界面美化工作都帮你做好了，你可以专注于博客内容的创作，而不必学习如何“烧砖”（写前端代码）。网上搜索“hexo”，可以找到它的官网。hexo 的官网文档做得非常好，不仅提供准确的中文版文档，还附有视频，让我学得非常之愉快。 不过作为一个“楼房设计工程师”，你还是需要一些其他的帮手来帮助你“建房子”。 在 Hexo 官网的文档里面有详细的教程教你如何安装必须的东西，我在这里只讲一些理解性的东西，详细的指令不多讲。 安装 Hexo 的时候你需要俩工具： node.js git node.jsnode.js-百度百科 Node.js 是一个让 JavaScript 运行在服务端的开发平台，实质是对 Chrome V8 引擎进行了封装。 引用自node.js 和 JavaScript 的关系-博客园 JavaScript 是一门语言 node.js 不是一门语言，也不是一种特殊的 JavaScript 方言 - 它仅仅就是用于运行普通 JavaScript 代码的东西 所有浏览器都有运行网页上 JavaScript 的 JavaScript 引擎。Firefox 有叫做 Spidermonkey 的引擎，Safari 有 JavaScriptCore，Chrome 有 V8 node.js 就是带有能操作 I/O 和网络库的 V8 引擎，因此你能够在浏览器之外使用 JavaScript 创建 shell 脚本和后台服务或者运行在硬件上 个人理解：node.js 是 javaScript 的解释器 为啥要安装它呢？应该是为了使用 node.js 的 npm（Node Package Manager，是一个 node.jS 包管理和分发工具）,可以理解为一个安装程序，可以给你安装官方已经整合好的包。当然其他作用我也不知道。 如果已经有 git 和 node.js，直接使用下面指令进行安装： 1`$ npm install -g hexo-cli` 虽然前面有个 linux 系统的 shell 的命令提示符，但是安装好 node.js 之后用 windows 系统的 cmd 里面也是可以用的。至于打开 cmd，win+R 打开运行窗口输入“cmd”，回车就出现了。记得输入时不要输入前面的$符号，那是命令提示符。 git——版本控制系统git 的安装和使用就不多说了。用于将 Hexo 生成好的页面给推送到 github 这个远程库里。至少要知道 git 的一些基本概念。 Hexo 的使用这 Hexo 安装好之后你可以在 cmd 使用它的指令。 初始化初始化 Hexo 的指令（命令提示符不写了，下同）： 1hexo init 指定目录（省略则初始化当前目录） 初始化 hexo 之后会在你指定的目录生成一大堆文件，这些文件和文件夹是从它的官方 github 库里面 clone 下来的，这也是一开始要下好 git 的原因。 比较重要的几个文件是： _config.yml 配置文件，使用 YAML 来写的数据文件 scaffolds 模板文件夹，存放新文章的模板 source 文章，图片，草稿等资源都放在这里 themes 主题文件夹，Hexo 根据主题生成静态页面 新建文章1hexo new [layout] &lt;title&gt; 生成静态页面1hexo generate 或者简写成 1hexo g 前文说过，Hexo 是用来帮助你生成静态网页的一个工具，就是用这个指令。这个指令将目前编写好的文章以及主题等东西给包装好，生成用于上传到你的网站上（这里我们用 github page）的网页。至于此命令的详细说明，请看 Hexo 文档。 部署网站说实话我在看文档的时候没看懂“部署网站”是啥意思，后来知道了，这就是将hexo generate生成的静态页面推送到你的 github 库里面去的意思。 指令是： 1hexo deploy 也可以简写成： 1hexo d deploy可以与generate共同简写成： 1hexo d -g 或者 1hexo g -d 一个意思，都是先生成静态页面，再部署网站。 本地测试1`$ hexo server` 在自己电脑上运行服务器来查看博客的效果，默认情况下，访问网址为： http://localhost:4000/ 其余指令我目前还没用到，详情请见Hexo 文档 github page在 github 仓库的 setting 里面，有一栏叫做 github page，在其中的 source 选项内选择作为数据源的分支，一般将博客部署在 master 分支，所以选择 master 作为数据源。 你可以选择两种方式来给你用来存放博客数据的仓库起名字，第一种就是你百度经常看到的：你的用户名.github.io的形式，这种形式会让你在选择好数据源之后提示： 1Your site is published at https://你的用户名.github.io/ 然后你可以使用给出的链接来打开你的博客，点击链接，会默认打开你数据源分支内的 index.html 文件作为主页，如果没有这个文件就会404：找不到页面，当然，Hexo 会帮你生成好 index.html，只要你把生成好的页面给 push 上 github 就可以。如果你知道包含哪些文件的话，自己手动上传应该也 ok。 有了这种方式，其实你甚至可以不需要 Hexo，自己写 html 页面也能做一个博客，不过这样就像前文说的从“烧砖”开始建楼了。 第二种起名方式就是不按照第一种来，随便起，比如用户名是HaneChiri，创建的仓库名叫blog,那么选择完数据源分支之后呢，得到的提示可能是： 1Your site is published at https://hanechiri.github.io/blog/ 这样需要写的网址就会长一些，要加上仓库名。试了一下这样是可以的。我的两个仓库就分别使用了以上两种方式。 markdown 的图片这里的文章使用的是 markdown 语法，一个比较容易学习的标记语言，可以让你手不离键盘地完成排版，我现在就是在用 markdown 来写.md 文件，然后放进 source 文件夹的_post 子文件夹里面，之后再上传。 markdown 可以方便的插入图片和超链接。但是图片一般来说是利用相对路径放在.md 文件的附近的，生成静态页面的时候图片的路径又会被打乱，导致图片显示失败。 Hexo 文档里面提供了几种方式来插入图片，比如插件。但是那种方式无法实时预览，而且难弄。 所以干脆使用外部图片链接，在 github 上面再建立一个仓库用来存放图片，提供链接给博客使用。 要这样使用的前提是去开启 github page 这个设置。 比如用户名是HaneChiri，创建的仓库名叫blog_images，那么在这个仓库根目录下的图片avatar.jpg的链接就是 1https://hanechiri.github.io/blog_images/avatar.jpg 而不是 1https://github.com/HaneChiri/blog_images/avatar.jpg 后者是浏览编辑这个图片的链接，而不是图片本身。 上传之后无法访问这个链接也不要急，等几分钟就可以了。 参考教程 【持续更新】最全 Hexo 博客搭建+主题优化+插件配置+常用操作+错误分析-遇见西门 步骤总结由于网上教程很多，我在这里只是简单把我部署博客的步骤总结一下： 开一个 github 空仓库（注册和新建仓库应该不用多说） 在一个本地空文件夹内初始化 hexo 此文件夹内，与远程库建立关联（其实这一步可以不必，不过以后可能用得到，先弄着吧） 给_config.yml文件内deploy属性设置好type（: git，记得冒号后面有个空格）、url（github 仓库的链接）和branch（推送到的分支，一般用 master） 修改其他配置比如title、author、new_post_name、language、post_asset_folder 安装一个 git 部署的东西npm install --save hexo-deployer-git 生成并在本地测试页面效果 生成并部署网站hexo d -g 新建，编辑文章然后重复上一步","link":"/posts/hexo_deploy_log/"},{"title":"python爬虫学习笔记1简易小说爬虫","text":"学了 python 语法之后在 b 站搜索练手的小项目，发现了这个视频：Python 实用练手小项目（超简单） 视频里面讲解了一个爬取图片网站图片的小爬虫。后面用到了我还没学的数据库，不过前面的部分是已经学了的，于是我就打算写一个不用数据库的，爬取某个盗版小说内容的爬虫。 声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处。 项目描述爬虫，在我理解中就是模拟人的浏览行为来获取网站上的信息的脚本，爬虫能得到的信息，一般情况下人也有权限可以得到。 盗版小说网站，不需要登录就可以看到小说内容，内容是写死在 html 文件里面的，通过右键菜单的查看源代码就能够查看到小说内容，很适合拿来练手。 再次声明：本人不会将得到的小说内容作任何商业用途，也请阅读此文章的各位读者遵纪守法，此文章只用作学习交流，原创内容，转载请注明出处。 思路爬虫的思路是向服务器发出请求，并收到服务器回复的数据，接着从获取的数据中取得想要的信息，保存在数据库中。 由于是小说，就直接保存在文本文件当中。 所以分为以下几步： 发出请求 接收数据 提取信息 保存数据 编程原理发出请求和接收数据发出请求需要一个库，名字叫做requests，它是基于 python 自带的urllib库写的第三方库，差不多就是升级版的意思吧。 要注意是requests，不是request，结尾有个 s，确实存在一个不带 s 的库，注意区分。 可以使用下面的命令进行安装： 1pip install requests pip 是 Python 包管理工具，总之有了这个玩意，你不用管它从哪里下载，在哪里安装，总之就告诉它要安装啥，它就帮你安排得明明白白的。以后会遇到很多这样的东西，比如 npm 啥的。 命令在 cmd 里面输就行了，如果电脑上没有这东西就百度一下怎么下载，一般来说安装了 python 应该就有了。 如果使用的是 pyCharm 这种 IDE，那就可以直接在代码 import 这个库，等库的名字变红再在旁边找安装按钮，很方便的。 这个库里面有个 get 函数，是采用 get 的方式（除此之外还有 post 方式，学 html 表单的时候应该有学到）来向服务器发出访问请求，并将获得的数据作为返回值。 1234import requests#省略代码r = requests.get(url)#url是你要访问的网址print(r)#如果输出是&lt;Response [200]&gt;，那么就是访问成功了 此时返回变量是请求对象，要从中获取数据，就需要使用它的两个属性text和content r.text是数据的 html 形式，r.content是字节流的形式。二者的区别 前者返回文本格式（即二进制格式经过编码后），后者返回二进制格式。后者一般用于图片的保存。 我们需要获取的是文本内容，因此需要前者。 1html=r.text 提取信息我们打开笔趣阁（一个盗版小说网站）的一个小说页面，随便选一章点进去，查看源代码，发现小说的内容是放在一个&lt;div&gt;里面的： 1234&lt;div class=&quot;content&quot; id=&quot;booktext&quot;&gt; 小说内容 &lt;center&gt;翻页信息&lt;/center&gt;&lt;/div&gt; 其他章节也是如此，所以就可以利用这个规律将其提取出来，用的就是正则表达式。 正则表达式使用正则表达式需要使用一个内置的库re，根据上面的规律可以写出下面的正则表达式： 123456789import rereg = r'&lt;div class=&quot;content&quot; id=&quot;booktext&quot;&gt;(.*?)&lt;center&gt;'#正则表达式reg = re.compile(reg)#将字符串转换为正则表达式对象，加快匹配速度content= re.findall(reg, html)#返回一个列表，列表项为匹配到的内容if content==[]:#未匹配到小说内容 print(&quot;获取失败！&quot;)else: content=str(content[0])#将列表转换为字符串 re.compile()函数 编码转换但是我写到这里的时候遇到了一个问题，就是获取到的内容是乱码。一看到乱码就应该想到是编码出了问题。 右键菜单查看网页编码，是GBK编码，需要转换编码。现在的情况是，网页利用GBK的编码来“加密”了小说文本，而我们需要用同样的方式来“解码”。需要用到decode函数 1html=r.content.decode(&quot;GBK&quot;, &quot;ignore&quot;)#转换编码 将获得的二进制数据按照网页原本的编码GBK来解码，就能获取到正确的内容了。 去除分隔字符此时提取到的内容还有这很多 HTML 实体，比如&amp;nbsp;和&lt;br /&gt;，注意到它们的分布也有规律： 1234&lt;div class=&quot;content&quot; id=&quot;booktext&quot;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;小说内容&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;小说内容&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;……省略……&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;大雪落下，悄然覆盖着这一切。&lt;br /&gt; &lt;center&gt;&lt;/center&gt;&lt;/div&gt; 除了开头和结尾之外，都是以&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;进行分隔的。 可以利用split()函数将其分割之后重新组合， 也可以使用字符串的替换函数replace() 1content=content.replace(&quot;&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;,&quot;\\n\\n &quot;) 保存数据保存在文本文件中就 ok 了： 123with open(fileName,'w') as fout:#fileName为保存路径加文件名 fout.write('\\n\\n=====================\\n\\n' + fileName + '\\n\\n=====================\\n\\n') fout.write(content) 获取单章节内容代码12345678910111213141516171819202122232425262728293031323334353637import requestsimport reimport osdef getNovelByURL(url,fileName): ''' :param url: 网页的url :param fileName: 保存数据的文件的名字 :return: -1为失败，0为成功 ''' #筛选文件名内非法字符 #调试的时候前面几百章都行突然一章不行，发现是因为章节名字里面有非法字符 reg=r'[\\/:*?&quot;&lt;&gt;|]' fileName=re.sub(reg,&quot;&quot;,fileName)#利用正则表达式去除非法字符 # 获取网页 r = requests.get(url) html = r.content html = html.decode(&quot;GBK&quot;, &quot;ignore&quot;) # 获取网页中小说内容 reg = '&lt;div class=&quot;content&quot; id=&quot;booktext&quot;&gt;\\n&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(.*?)&lt;br /&gt;\\n&lt;center&gt;' reg = re.compile(reg)#预编译 content = re.findall(reg, html) #保存到文件 if content==[]: print(&quot;获取失败！&quot;) return -1 else: content=str(content[0])#转换为字符串 content=content.replace(&quot;&lt;br /&gt;&lt;br /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;,&quot;\\n\\n &quot;) with open(fileName,'w') as fout: fout.write('\\n\\n=====================\\n\\n' + fileName + '\\n\\n=====================\\n\\n') fout.write(content) print(&quot;成功爬取（{}），存储在{}&quot;.format(url,os.path.dirname(__file__)+'/'+fileName)) return 0 获取全部章节内容的思路盗版小说网站章节的 url 有个规律，就是 url 的最后一串数字是连续的，照这个规律，知道第一章的 url，就可以获得后续章节的 url。于是我着手写这么个函数： 123456789def getNovelByIndexInc(url, number=1): ''' 此函数用于通过已知的起始url来获取仅有尾部索引不同且连续的一系列网页内的小说， 不连续时会跳过获取失败的网址，不过有可能连续几千个网址都是无效网址，所以慎用此函数 或改用getNovelByContentPage函数 :param url:起始章节的url :param number: 要获取的章节数 :return:无 ''' 从我写的注释里面也可以看出，我失败了。 一开始的一百多章还是没什么问题的，只有偶尔几个网址是无效网址，但是后面爬取的时候等了十分钟还没爬取到下一章，一直输出“无效网址”，我查看了那断片的两个连续章节之后才发现，最后的一串数字差了几万。不会是因为作者断更吧！ 这种方式不可靠，还是换一种方式。 那么要如何可以改进呢？ 我写了另一个函数： 1234567def getNovelByContentPage(url,path='novel'): ''' 通过获取目录页面链接与标题，进一步调用获取已知链接页面的函数来保存页面内容 :param url: 书籍目录页面 :param path:保存路径，默认为同目录下的novel文件夹 :return:-1为失败，0为成功 ''' 网站的书籍页面会有一个目录，而目录下隐藏的就是我需要的全部章节的链接呀！ 这个函数用到的内容上面也都讲到了，就直接放代码吧。 获取全部章节内容的代码123456789101112131415161718192021222324252627282930313233343536import requestsimport reimport osdef getNovelByContentPage(url,path='novel'): ''' 通过获取目录页面链接与标题，进一步调用获取已知链接页面的函数来保存页面内容 :param url: 书籍目录页面 :param path:保存路径，默认为同目录下的novel文件夹 :return:-1为失败，0为成功 ''' # 获取网页 r = requests.get(url) html = r.content#获取网页二进制内容 html = html.decode(&quot;GBK&quot;, &quot;ignore&quot;)#转换编码 # 获取网页中小说内容 reg = '&lt;dd&gt;&lt;a href=&quot;(.*?)&quot; title=&quot;(.*?)&quot;&gt;.*?&lt;/a&gt;&lt;/dd&gt;'#获取链接和标题 reg = re.compile(reg, re.S) info= re.findall(reg, html) #由于是分组匹配，得到的列表中每个元素的[0]是链接，[1]是标题 #保存到文件 if info==[]: print(&quot;获取章节目录失败&quot;) return -1 else: if not os.path.exists(path):#检查目录是否已经存在 os.makedirs(path) for i in info: realpath=path+&quot;\\\\&quot;+i[1]+&quot;.txt&quot; if os.path.exists(realpath):#避免重复爬取 continue else: getNovelByURL(i[0],realpath)#调用获取单页面内容的函数 return 0","link":"/posts/python_spider_note1simple_spider/"},{"title":"为博客增加访问统计","text":"用 CNZZ 统计网站访问量 我用的主题是 shana，网站统计的配置部分是这样的： 12345# 网站统计# 站长统计 填写id# eg: # CNZZ: 123456789CNZZ: 百度了一下发现 CNZZ 和百度统计都可以统计网站访问量。当然想统计呀，这样就更有动力来写了。 尝试了百度统计一个多小时之后还没弄好，我就开始试 CNZZ，毕竟主题的作者直接写在配置里面了，还是按照规矩来吧。 CNZZ 不是中国站长（cnzz.cn）那个，而是友盟（cnzz.com），我一开始进的是中国站长……找了老半天统计功能才发现进错网站了。 步骤 注册一个 cnzz 账号 填写网站信息 复制统计代码 粘贴统计 id 到配置文件 粘贴统计代码到需要统计的页面开头 粘贴代码到哪里又是个问题，根据前面尝试弄百度统计的经验，在主题文件夹下的\\layout\\_partial内是用于生成页面的代码，摸索一阵后发现应该粘贴到head.ejs里面以达到生成在页面前面的效果。 一开始没显示“站长统计”的字样我以为是无效，甚至还去 issue 里面问 shana 的作者怎么弄。 后来发现，原来是 shana 主题在切换背景图片的时候会掩盖字样……好吧是我太心急了。 今日收获hexo 的页面生成方式theme\\&lt;themeName&gt;\\layout\\_partial下的文件都是.ejs 文件，应该是“扩展的 js”文件，用于生成相应的页面。 例如head.ejs中专门存储生成 html 文件的&lt;head&gt;部分 more文章一开始是全部展开的，浏览起来比较难受，查了之后发现其实只需要在文章中加上一个标记就可以折叠。 .md 文件里面是下面这种结构： 12345显示出来的文章提要&lt;!--more--&gt;正文","link":"/posts/hexo_visit_count/"},{"title":"c++学生信息管理系统（一）","text":"尝试重新设计与编写大一第一学期的 c++课设——学生信息管理系统。本文作简单思路分析与代码分享。B 站视频内录制了从头开始写的整个过程：课程设计|c++控制台简易学生信息管理系统 思路要求：能够录入，显示，查找，删除，文件存取学生信息 以当时的知识是以链表来实现的，这次也是使用链表。 首先，创建一个链表结点类用于存放学生的信息，每个对象都是一个学生。 其次，创建一个链表类用于将结点连接起来。 最后，利用链表类已经创建好的各种接口，在 main 函数中进行装配，实现所需要的各种功能。 链表结点类 类名：CStudent 属性：姓名、性别、成绩、其余本质相同的属性（如班级号，学号）省略。 方法：以不同方式显示该学生所有信息、手动录入学生信息 类声明123456789101112131415161718192021222324252627282930#pragma once//链表结点类//学生类//属性：姓名、性别、成绩//方法：录入、显示class CStudent{ char name[20]; bool sex;//true为男，false为女 int score;public: //链表需要的指针域 CStudent* next;//=======================================public: //构造函数 CStudent(const char p_name[], bool p_sex, int p_score); CStudent(); //录入与显示 void input(); void show(int method); //get char* getName() { return name; } bool getSex() { return sex; } int getScore() { return score; } //析构函数 ~CStudent();}; 类实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//@fileName &lt;CStudent.cpp&gt;#include &quot;CStudent.h&quot;#include &lt;cstring&gt;#include &lt;iostream&gt;using namespace std;CStudent::CStudent(const char p_name[], bool p_sex, int p_score){//有参构造则自动录入信息 strcpy(name, p_name); sex = p_sex; score = p_score;}CStudent::CStudent(){ input();//如果无参构造，则手动录入信息}void CStudent::input(){ cout &lt;&lt; &quot;请输入学生姓名：&quot; &lt;&lt; endl; cin &gt;&gt; name; //如果遇到cin连续输入出错的问题，可以在每次输入后加个cin.get() cout &lt;&lt; &quot;请输入学生性别（1为男，0为女）：&quot; &lt;&lt; endl; int isex; cin &gt;&gt; isex; sex = isex ? true : false; cout &lt;&lt; &quot;请输入学生成绩：&quot; &lt;&lt; endl; cin &gt;&gt; score;}void CStudent::show(int method){ switch (method) { case 0://横向显示，一行一条记录 cout &lt;&lt; name&lt;&lt;&quot;\\t&quot; &lt;&lt; (sex ? &quot;男&quot; : &quot;女&quot;)&lt;&lt;&quot;\\t&quot; &lt;&lt; score&lt;&lt;&quot;\\t&quot; &lt;&lt; endl; break; case 1://纵向显示，每行一个属性 cout &lt;&lt; &quot;姓名：&quot; &lt;&lt; name &lt;&lt; endl &lt;&lt; &quot;性别：&quot; &lt;&lt; (sex ? &quot;男&quot; : &quot;女&quot;) &lt;&lt; endl &lt;&lt; &quot;成绩：&quot; &lt;&lt; score &lt;&lt; endl &lt;&lt; endl; break; default: break; }}CStudent::~CStudent(){} 链表类类声明12345678910111213141516171819202122232425262728//@fileName &lt;CStudentList.h&gt;#pragma once#include &quot;CStudent.h&quot;//链表类（带头结点的单向链表）//属性：指向头结点的头指针//方法：构造函数（手动输入）、构造函数（传入结点对象数组）、析构函数//方法：显示表、查找、删除、把数据存入文件、从文件中读取数据class CStudentList{ CStudent* head;//头指针public: //构造函数 CStudentList(int n);//手动录入n个学生的信息 CStudentList(CStudent s[],int n);//通过对象数组自动录入n个学生的信息 CStudentList(const char fileName[]);//读取文件中的数据信息来初始化 CStudentList(); //功能 void showList();//显示整个链表的信息 int search(const char name[]);//按名字查找并返回找到的个数 void deleteNode(CStudent*p);//删除指针p指向的结点 int deleteByName(const char name[]);//删除表中第一个匹配的记录，同时返回是否删除成功 //文件读写 void save(const char fileName[]); void open(const char fileName[]); //析构函数 ~CStudentList();}; 类实现构造函数我设计了四个构造函数。 1.如果没有参数，那么就只建立一个空链表，即只有一个头结点的链表。 1234567//@funcName &lt;CStudentList::CStudentList&gt;//@brief &lt;创建空链表&gt;CStudentList::CStudentList(){ head = new CStudent(&quot;HEAD&quot;, 1, 100);//头结点本身的数据并不重要，所以随意填写。 head-&gt;next = NULL;} 2.手动录入信息的构造函数 1234567891011121314//@funcName &lt;CStudentList::CStudentList(int n)&gt;//@brief &lt;创建n个结点的链表，并手动录入信息&gt;//@parameter &lt;n:初始链表结点数目（不计头结点）&gt;CStudentList::CStudentList(int n){ head = new CStudent(&quot;HEAD&quot;,1,100); head-&gt;next = NULL; for (int i = 0; i &lt; n; i++) { CStudent *newNode = new CStudent(); newNode-&gt;next = head-&gt;next; head-&gt;next = newNode; }} 3.通过数组自动录入信息的构造函数 和上一个差不多。 1234567891011121314//@funcName &lt;CStudentList::CStudentList(CStudent s[],int n)&gt;//@brief &lt;创建n个结点的链表，并自动从数组中获取信息&gt;//@parameter &lt;s:结点类对象数组&gt;&lt;n:数组s的长度&gt;CStudentList::CStudentList(CStudent s[], int n){ head = new CStudent(&quot;HEAD&quot;, 1, 100); head-&gt;next = NULL; for (int i = 0; i &lt; n; i++) { CStudent *newNode = new CStudent(s[i].getName(),s[i].getSex(),s[i].getScore()); newNode-&gt;next = head-&gt;next; head-&gt;next = newNode; }} 4.通过文件自动录入信息的构造函数 使用到了另一个成员函数open() 123456789//@funcName &lt;CStudentList::CStudentList(const char fileName[])&gt;//@brief &lt;自动从文件中读取信息&gt;//@parameter &lt;fileName:数据来源文件的名字&gt;CStudentList::CStudentList(const char fileName[]){ head = new CStudent(&quot;HEAD&quot;, 1, 100); head-&gt;next = NULL; open(fileName);} 显示链表123456789101112//@funcName &lt;CStudentList::showList()&gt;//@brief &lt;显示整个链表&gt;void CStudentList::showList(){ CStudent*p = head-&gt;next; cout &lt;&lt; &quot;姓名\\t性别\\t成绩&quot; &lt;&lt; endl; while (p != NULL) { p-&gt;show(0);//以一行一记录的形式显示 p = p-&gt;next;//工作指针向后移动 }} 查询结点1234567891011121314151617181920//@funcName &lt;CStudentList::search&gt;//@brief &lt;按照名字查找数据并显示&gt;//@parameter &lt;name:要查找的学生的名字&gt;//@return &lt;找到的记录数目&gt;int CStudentList::search(const char name[]){ int num = 0; CStudent*p = head-&gt;next; cout &lt;&lt; &quot;---------查找结果---------&quot; &lt;&lt; endl; while (p != NULL)//遍历链表 { if (strcmp(p-&gt;getName(),name)==0)//找到了需要的信息 { num++; p-&gt;show(0); } p = p-&gt;next; } return num;} 查找删除由于删除结点与查找要删除的结点相对独立，因此将删除结点独立出来一个函数，以便查找删除不同属性的数据。 1234567891011121314//@funcName &lt;CStudentList::deleteNode&gt;//@brief &lt;删除指针指向的链表节点&gt;//@parameter &lt;p:要删除的结点的指针&gt;void CStudentList::deleteNode(CStudent*p){ CStudent*p1 = head, *p2 = head-&gt;next; while (p2 != p) { p1 = p1-&gt;next; p2 = p2-&gt;next; } p1-&gt;next = p-&gt;next; delete p;} 以查找姓名的删除函数为例子： 123456789101112131415161718//@funcName &lt;CStudentList::deleteByName&gt;//@brief &lt;按名字查找并删除第一个符合条件的结点&gt;//@parameter &lt;name:要删除的结点的名字&gt;//@return &lt;是否删除成功(成功返回0，失败返回-1)&gt;int CStudentList::deleteByName(const char name[]){ CStudent*p = head-&gt;next; while (p != NULL) { if (strcmp(p-&gt;getName(), name) == 0)//找到了需要的信息 { deleteNode(p); return 0; } p = p-&gt;next; } return -1;} 读取数据123456789101112131415161718192021222324252627282930//@funcName &lt;CStudentList::open&gt;//@brief &lt;从文件中读取数据并以覆盖形式写入链表&gt;//@parameter &lt;fileName:数据文件名&gt;void CStudentList::open(const char fileName[]){ //清空链表 CStudent* p = head-&gt;next; while (p != NULL) { delete head; head = p; p = p-&gt;next; } //未删除head //从文件读取数据 ifstream fin(fileName); while (!fin.eof())//end of file { char name[20]; bool sex=0; int score=0; fin &gt;&gt; name &gt;&gt; sex &gt;&gt; score; //利用头插法把数据插入到链表中 CStudent *newNode = new CStudent(name,sex,score); newNode-&gt;next = head-&gt;next; head-&gt;next = newNode; }} 保存数据123456789101112131415161718//@funcName &lt;CStudentList::save&gt;//@brief &lt;将链表存入文件&gt;//@parameter &lt;fileName:保存到的数据文件名&gt;void CStudentList::save(const char fileName[]){ ofstream fout(fileName);//打开文件，创建文件流对象 //遍历链表 CStudent *p = head-&gt;next; while (p != NULL) { //将数据存入 fout &lt;&lt; p-&gt;getName() &lt;&lt; &quot; &quot; &lt;&lt; p-&gt;getSex() &lt;&lt; &quot; &quot; &lt;&lt; p-&gt;getScore() &lt;&lt;endl; p = p-&gt;next; }} 析构函数1234567891011CStudentList::~CStudentList(){ CStudent* p = head-&gt;next; while (p != NULL) { delete head; head = p; p = p-&gt;next; } delete head;} 菜单菜单比较简单，整个程序主要流程： 显示菜单选项，等待输入选项编号 分支语句，按照不同选项调用链表提供的函数 如果没有选择退出选项就循环 菜单函数示例123456789void menu(){ cout &lt;&lt; &quot;========学生信息管理系统========&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.显示学生信息表&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.查找学生信息&quot; &lt;&lt; endl; cout &lt;&lt; &quot;3.从文件读取&quot; &lt;&lt; endl; cout &lt;&lt; &quot;4.将数据存入文件&quot; &lt;&lt; endl; cout &lt;&lt; &quot;0.退出&quot; &lt;&lt; endl;} 选项分支示例1234567891011121314151617181920212223int main(){ int opt = -1; CStudentList list(&quot;data.txt&quot;); while (opt != 0) { menu(); cin &gt;&gt; opt; switch (opt) { case 1: system(&quot;cls&quot;); list.showList(); break; default: break; } } return 0;}","link":"/posts/cpp_student_info_management_system1/"},{"title":"notepad++添加文件关联","text":"将一些常用 notepad++打开的文件设置为默认 notepad++打开的方法 在研究 hexo 博客的各种功能的时候，总是需要打开配置文件.yml，一开始我是用右键菜单里面的【用 notepad++打开】的方式来打开，后来又遇到了各种.ejs,.styl之类的文件也需要用 notepad++来编辑，就将这些文件类型的默认打开方式设置为 notepad++。 方法一 菜单栏【设置】-&gt;【首选项】 如图选择【文件关联】，找到需要添加的文件类型，如果没有就选择【customize】（自定义）自己输入，然后添加。 方法二 【ctrl+r】打开【运行】输入control（也就是打开控制面板） 小图标查看方式，找到【默认程序】，选择【将文件类型或协议与程序关联】，找到需要的后缀名，选择它的默认程序即可。","link":"/posts/notepadpp_file_association/"},{"title":"换了一个主题","text":"把主题从shana（夏娜）换成了NexT，记录一下这个过程，以及遇到的一些有用的博客链接。流水账，主要保存链接。 缘起刚弄了 hexo 博客很兴奋，于是去鼓捣各种东西，首先选了一个二次元的主题 shana，虽然这个主题我很喜欢，但是想要加目录或者是其他的一些东西，网上根本就搜不到相关的内容，在解决各种问题的过程中，我发现搜索到的几乎都是关于 NexT 这个主题的解决方法，应为这个主题很多人用。 在又一次发现主题的文件被我“弄坏了”（背景图片的幻灯片播放只显示一次）之后，我想还是换成 NexT 吧，这样就能专注于写博客，而不是为设置博客而烦恼。 安装 NexT 主题NexT主题安装和其他主题一样，clone 下来再改一下站点配置文件_config.yml就好了。 然后再设置这个主题的配置文件。这个主题的配置文件与 shana 相比起来不知道详细了多少，各种设置都准备齐全了。没费多少功夫就配置好很好看的站点了。接着就是把站长统计之类的东西设置一下。 cnzz 站长统计，统计访问 leanCloud 数据统计，统计文章阅读数，参考链接：Hexo-Next 搭建个人博客（添加统计访客量以及文章阅读量） 当然我也试着弄了一下 gitment 评论，仍然不行，那么只能继续采用“直接在菜单中给出 issue 页面链接”的方式了。参考链接：Hexo-Next 添加 Gitment 评论系统","link":"/posts/hexo_blog_switch_theme_1/"},{"title":"老鼠和毒药问题","text":"昨天在上完课回宿舍的路上，楠哥提起了一道他在某个基础知识竞赛上遇到的题目，我觉得解法很巧妙，分享记录一下。 题目有 1024 瓶水，其中一瓶有毒，你有 10 只老鼠用于试毒（这里是题目假设，所以别下不了手让老鼠试毒 OVO），老鼠如果喝到毒药，会在一星期后死亡。你有一周时间，如何找出这一瓶毒药？ 解法楠哥说他刚开始想用二分，可是时间上不允许。 也就是把瓶子分两组，每组的瓶子里都倒出一点混合在一起给一只老鼠喝，哪一组的老鼠中毒了，就再把这一组的瓶子分两组，以此类推。但是这样时间上来不及，第一周缩小范围到 512 瓶……第九周 2 瓶，第十周找到。耗时太长。 于是他想到了另一种解法： 给每个瓶子标号，给老鼠也标号 0 到 9。 从逻辑上将 10 只老鼠当成 10 位的二进制数。 将瓶子的编号转换为二进制数，比如第 5 号瓶子转换为第 101 号瓶子，将编号第 0 位（即最右边一位）为 1 的水给 0 号老鼠喝，编号第 1 位（即从右边数第二位）为 1 的水给 1 号老鼠喝，以此类推。 也就是说，0 号老鼠喝了 1,11,101,111……这些瓶子的水，1 号老鼠喝了 10,11，110,111……这些瓶子的水，后面的老鼠也是如此。 如果一周时间到，0 号老鼠嗝屁了，那么就说明有毒的水的编号的第 0 位（最右边的位）为 1；如果 1 号老鼠嗝屁了，就说明有毒的水编号的第 1 位是 1…… 最后根据 10 只老鼠中毒情况，得到一个 10 位的二进制数，这个数转换为十进制就是毒药的编号。 我觉得这个解法很巧妙。 这让我想起了在听我们学校 ACM 协会的某节课的时候提到的状态压缩，也是使用二进制的，不过我当时没听懂，也就没记下来。 老鼠有 10 只，它们的死活可以表示 2^10 种状态，恰好是 1024 种。","link":"/posts/rats_and_poison/"},{"title":"简易倒排索引","text":"智能信息检索这门课程有个上机作业，题目是“实现倒排索引”。 用到了以前没有学的 STL 中的 vector。 经过两次课上写代码（3 小时）加上课后修 bug 的时间（晚上十点到十二点）总共 5 个小时，终于完成了一个简易的倒排索引。因为十点时已经太困，喝了柠檬茶提神结果现在睡不着，所以继续熬夜把博客写完吧。 前言勿抄袭代码，代码仅供参考。转载注明出处 倒排索引简介为了从文档集（collection）中检索出想要的结果，首先要将文档集中的每个词项（term）建立索引，以确定词项所在的文档（document）的 id，从而返回根据关键字查询的结果。 倒排索引的格式大概是下图这样（代码成果图）： 每一个词项后面跟着它在文档集中出现的次数，以及出现过的文档的 id 所组成的一个序列。 例如第一条： 词项 词频 倒排记录表 API 6 4，5，6 就代表API这个词在文档集（六个文件）中出现了六次，这六次分布在文档 4、文档 5 和文档 6。 搜索引擎大致就是这个原理，建立好了索引之后，只需要把你搜索的关键词对应的 posting 求交集然后把对应的文档显示出来就可以了。 数据结构设计文档（Document）文档其实在这里就是文件，对于每个文档，都有一个文档名，以及相对应的文档 ID，它们得绑定好，否则会混乱。因此将它们放在一个结构体里面。 12345struct Document{ string docName;//文档名 int docID;//文档id}; 索引项（IndexItem）同样的，每一个记录的词项、词频和记录表也是绑定的，所以也打包起来。文档 id 的数目不定，又不想自己写链表或者动态数组怕出错，因此采用了 STL（标准模板库）里面的动态数组 vector（向量容器）。 123456struct IndexItem{ string term;//词项 int frequence;//词频 vector&lt;int&gt; posting;//记录表}; 索引类（CIndex）代码应该不难看懂。 12345678910111213141516171819202122class CIndex{ vector&lt;IndexItem&gt; indexList;//索引表 vector&lt;Document&gt; collection;//文档集public: CIndex(); //利用文件名数组初始化文档集 CIndex(string p_collection[], int n); //显示文档集内所有文档的文件名 void showCollection(); //显示当前倒排索引表 void showIndexList(); //索引单篇文档 int indexDocument(FILE*fp, int docID); //索引文档集 int indexCollection(); //排序索引表 int sortIndex(); //索引表合并同类项 int mergeIndex(); ~CIndex();}; 大致思路 扫描一篇文档，将这篇文档对应的文档 ID 加入对应词项的 posting 对文档集中每一篇文档重复第一步，获取所有词项及其对应的 posting 加入索引表，此时每个词项的 posting 中只有一个文档 ID，并且有很多重复的词项记录； 排序索引表； 将重复的项的 posting 合并，并且增加词频，删除重复项。 2019-4-4 补充：想到一个新思路——直接按照 ID 从小到大扫描一遍整个文档集，每扫描一个词项，就在词典中查找这个词项，增加词频，然后把现在正在处理的文档的 ID 加入到 posting，最后再排个序即可。 代码实现有参构造函数初始化文档集 12345678910111213//@name &lt;CIndex::CIndex&gt;//@brief &lt;初始化文档集&gt;//@param &lt;string p_collection[]:文档文件名数组&gt;&lt;int n:数组长度&gt;CIndex::CIndex(string p_collection[], int n){ Document nextDoc; for (int i = 0; i &lt; n; i++) { nextDoc.docName = p_collection[i]; nextDoc.docID = i+1;//编号从1开始 collection.push_back(nextDoc); }} 索引单篇文档大致思路是，一个个字符读取进来，如果是字母就一直读完整个单词，并把这个单词作为词项加入表中。 12345678910111213141516171819202122232425262728293031323334353637//@name &lt;CIndex::indexDocument&gt;//@brief &lt;索引单篇文档&gt;//@param &lt;FILE * fp:已打开的文件指针&gt;&lt;int docID:此文件的编号&gt;//@return &lt;扫描到的词项数量&gt;int CIndex::indexDocument(FILE * fp, int docID){ char ch;//扫描用的变量 IndexItem indexItem;//打包用的变量 int num = 0;//扫描到的词项数量 while (!feof(fp)) {//一次循环获取一个单词 //找到第一个字母 do { ch = fgetc(fp); if (feof(fp)) break;//防止空文件导致的无限循环 } while (!isalpha(ch)); if (feof(fp)) break;//防止因文件后面的空行而索引空字符串 //读取单词，给索引项赋值 while (isalpha(ch)) { indexItem.term += ch; ch = fgetc(fp); } indexItem.frequence = 1; indexItem.posting.push_back(docID);//将本文件的文档ID加入posting //把索引项加入词典 indexList.push_back(indexItem); num++; //清空索引项，准备下一次 indexItem.term=&quot;&quot;; indexItem.posting.clear(); } return num;} 索引文档集索引文档弄好之后，索引整个文档集不过是加个循环而已 123456789101112131415161718//@name &lt;CIndex::indexCollection&gt;//@brief &lt;索引文档集&gt;//@return &lt;词项总数目&gt;int CIndex::indexCollection(){ int num = 0; //打开对应的文件并索引 for (int i = 0; i &lt; collection.size(); i++) { //打开文件 FILE* fp = fopen(collection[i].docName.c_str(), &quot;r&quot;); //索引单篇文档 num+=indexDocument(fp, collection[i].docID); //关闭文件 fclose(fp); } return num;} 排序索引表直接使用&lt;algorithm&gt;头文件里面的sort()函数进行排序，自定义比较函数cmp() 123456789bool cmp(IndexItem a, IndexItem b){ return a.term&lt;b.term;//词项按照从小到大排序}int CIndex::sortIndex(){ sort(indexList.begin(), indexList.end(), cmp); return 0;} 去重12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//@name &lt;CIndex::mergeIndex&gt;//@brief &lt;索引表合并同类项&gt;int CIndex::mergeIndex(){ IndexItem item1,item2; sortIndex(); vector&lt;IndexItem&gt;::iterator it_cur=indexList.begin();//创建迭代器 vector&lt;IndexItem&gt;::iterator it_next = it_cur + 1; vector&lt;int&gt; temp; vector&lt;int&gt;::iterator p1, p2;//用于合并posting的迭代器 while (it_cur != indexList.end()) { if(it_cur+1!=indexList.end()) it_next = it_cur + 1; else break; while((*it_cur).term == (*it_next).term) {//这个循环内处理掉所有与当前词项重复的词项 //将二者的posting排序 sort((*it_cur).posting.begin(), (*it_cur).posting.end()); sort((*it_next).posting.begin(), (*it_next).posting.end()); //有序合并两者的posting p1 = (*it_cur).posting.begin(); p2 = (*it_next).posting.begin(); while (p1 != (*it_cur).posting.end() &amp;&amp; p2 != (*it_next).posting.end()) { if ((*p1) &lt; (*p2))//结果集中加入较小的元素 { temp.push_back(*p1); //这个while用于跳过重复的元素 p1++; } else if((*p1) &gt; (*p2)) { temp.push_back(*p2); p2++; } else { temp.push_back(*p1); //遇到相同的则两个都后移，避免出现重复 p1++; p2++; } } while(p1 != (*it_cur).posting.end())//如果串1没有合并完则将串1后面部分直接复制 { temp.push_back(*p1); p1++; } while(p2 != (*it_next).posting.end()) { temp.push_back(*p2); p2++; } //删除结果集重复部分 temp.erase(unique(temp.begin(), temp.end()), temp.end()); (*it_cur).frequence++;//词频增加 (*it_cur).posting.assign(temp.begin(), temp.end());//将结果复制 indexList.erase(it_next);//删除重复项 temp.clear(); if (it_cur + 1 != indexList.end()) it_next = it_cur + 1; else break; } it_cur++; } /*失败代码 for (int i = 0; i &lt; indexList.size()-1; i++) { item1 = indexList[i]; item2 = indexList[i + 1]; int j = 1;//j是相对于item1的偏移量 while (item1.term == item2.term) { vector&lt;int&gt; temp(item1.posting.size()+item2.posting.size()); sort(item1.posting.begin(), item1.posting.end()); sort(item2.posting.begin(), item2.posting.end()); merge(item1.posting.begin(), item1.posting.end(), item2.posting.begin(), item2.posting.end(), temp.begin()); indexList[i].posting.assign(temp.begin(), temp.end()); indexList.erase(indexList.begin()+i+j); indexList[i].frequence++; item2 = indexList[i + j]; } j = 1; } */ return 0;} 一开始使用的是普通的 for 循环，但是发现随着元素的删除，循环次数应该改变，因此改成了迭代器加 while 的方式。 迭代器还是个蛮有用的东西，就是一个封装得比较好的指针。 main 测试1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &quot;CIndex.h&quot;#include &lt;string&gt;using namespace std;string fileList[6] ={ &quot;doc1.txt&quot;, &quot;doc2.txt&quot;, &quot;doc3.txt&quot;, &quot;doc4.txt&quot;, &quot;doc5.txt&quot;, &quot;doc6.txt&quot;};int main(){ CIndex in(fileList,6); in.showCollection(); in.indexCollection(); in.mergeIndex(); in.showIndexList(); return 0;}","link":"/posts/simple_inverted_index/"},{"title":"手工归档编程项目","text":"以前写代码建立的工程到处堆放，导致不能很好的找到以前的代码。虽然以前简单地划分了一下文件夹，但并没有投入太多精力去想如何分类。所以打算养成归档编程项目的好习惯，记录一下过程。也给读者们一个参考。 不放图了，文件树结构就用无序列表来显示。 分类整理首先把所有项目文件夹全部放进一个专门的文件夹里面，最好不要中文名，也不要拼音，这是个好习惯，以后的命名也是。我将它起名为DEVELOP。 将它放置在 F 盘（我拿 F 盘当文件盘），并且设置一个快捷方式在桌面，嘿嘿我还给快捷方式选了一个很炫酷的图标让自己开心一下。 然后根据语言将其分为cpp_develop，py_develop，vb_develop，web_develop等（html，css，js 等统一划分到 web_develop 里面，因为我个人觉得它们三个分不开） 在每一个语言文件夹里面再细分(用 cpp 举例) 文件夹名 内容 cpp_archive 用于归档已经完成的项目，方便以后查找 cpp_project 用于存放正在开发的项目 cpp_test 用于测试。这里面我建立了几个空项目用于在别人问我代码问题的时候测试 cpp_example 用于存放从各种渠道得到的源代码，用于研究学习，里面的代码是别人的 cpp_lessonwork 用于存放课设或者课程实验代码，可并入 cpp_project cpp_pratice 用于存放一些不足以称为项目的代码 现在的目录大概是这样的： DEVELOP cpp_develop cpp_archive cpp_project cpp_test cpp_example cpp_lessonwork cpp_pratice py_develop vb_develop web_develop 归档规则项目名称+六位数日期(附加信息) 比如： 词法分析代码高亮 190403(修复了 xx) 日期是为了手动版本控制，利用肉眼就能知道哪些信息。以前做课设的时候就这样弄的（不过队友都不配合我这样搞，我发的版本是多少，改了之后发过来还是多少……） 总之归档时保证下次打开这个项目时能够唤醒当时编写时的记忆即可。","link":"/posts/archive_project/"},{"title":"git恢复误提交的内容","text":"在图书馆敲下最后几行代码，然后就着手机热点把爬虫代码 push 上去之后，突然想起来，我好像忘了把账号密码部分改成手动输入，现在 push 上去的是明文啊！掀桌！早知道就回宿舍上传了，说不准还能想起来。 问题及其解决方案已经上传了，即便我再改回来上传，别人也可以从 git log 里面看到我的账号密码。 那就版本回退，重新更新再上传。但是在我使用GitHub Desktop的Revert this commit的时候它却让我解决一大堆冲突……等会儿，啥时候多出来那么多“changes”？？？刚刚还一个都没有啊，怎么我用了这个选项还没回退就出现一大堆冲突？ 我对 git 其实不熟练，用 GUI 界面也是，解决这些冲突比较麻烦。所以最后的解决方案比较粗暴： 删除本地库以解决那一大堆的冲突文件 从远程库 clone 回来 把库内文件全部打包复制在别的路径 在库里面打开 git bash，使用git reset --hard 版本号回到没出事的版本 将前面备份的文件复制回来 修改之后重新提交，完成 教训 得多准备一条分支，别直接在主分支上边写 一定要注意代码中的隐私信息！","link":"/posts/git_reset_incorrect_commit/"},{"title":"python爬虫学习笔记4模拟登录函数的优化","text":"前面写的代码虽然完成了爬取的功能，但是过于凌乱，于是打算重构一遍。首先从登陆开始 改进前的代码面向过程这是第一次写的登录函数，获取登录信息和登录本身是放在一起的。 1234567891011121314151617181920212223242526272829303132333435363738def login(): &quot;&quot;&quot; 登录并返回已经登录的会话 :return: 已经登录的会话（session） &quot;&quot;&quot; #设置 login_url = 'http://ids.chd.edu.cn/authserver/login?service=http%3A%2F%2Fportal.chd.edu.cn%2F' headers={ 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36', } #新建会话 session=requests.session() #获取登录校验码 html=session.post(login_url,headers=headers).text soup=BeautifulSoup(html,'lxml') lt=soup.find('input',{'name':'lt'})['value'] dllt=soup.find('input',{'name':'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data={ 'username': input(&quot;请输入学号：&quot;), 'password': input(&quot;请输入密码：&quot;), 'btn':'', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } #登录 response=session.post(login_url,headers=headers,data=login_data) if response.url=='http://portal.chd.edu.cn/': print('登录成功！') return session 面向对象第二次是将全部函数封装到类中，这次将获取登录信息从其中分出来。但是两者关系仍然太过于紧密。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class spider: ''' 爬虫类 ''' def __init__(self,headers): self.session=requests.session()#初始化登录session self.is_login=False#登录状态 self.headers=headers#头信息 self.cookiejar=http.cookiejar.LWPCookieJar('cookie.txt') def get_login_data(self,login_url): ''' 获取登录需要的数据 :param login_url: 登录页面url :return: 一个存有登录数据的字典 ''' # 获取登录校验码 html = self.session.post(login_url, headers=self.headers).text soup = BeautifulSoup(html, 'lxml') lt = soup.find('input', {'name': 'lt'})['value'] dllt = soup.find('input', {'name': 'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data = { 'username': input(&quot;请输入学号：&quot;), 'password': input(&quot;请输入密码：&quot;), 'btn': '', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } return login_data def login(self,login_url): &quot;&quot;&quot; 登录并返回已经登录的会话 :return: 已经登录的会话（session） &quot;&quot;&quot; if self.load_cookie(): self.is_login = True else: #获取登录信息 login_data=self.get_login_data(login_url) # 登录 response = self.session.post(login_url, headers=self.headers, data=login_data) if response.url!=login_url: print(&quot;登录成功&quot;) self.is_login=True self.save_cookie() else: print(&quot;登录失败&quot;) return self.session #省略后面的函数 改进这次改进，我打算让login()函数与获取登录信息用的函数关系没有那么紧密，让后者可以被替换或者不用。 所以使用了回调函数，也就是将函数指针作为参数传入，不过 python 变量本身就像指针一样，直接传变量即可。 函数头1def login(self,login_url,login_data_parser=None,target_url=None): 传入了三个参数， login_url : 显而易见，这是登录页面的 url login_data_parser : 这是一个函数，用于解析页面中随机生成的隐藏域代码的函数，可以不传入 target_url : 用于判断是否登录成功，这是登录之后会跳转到的页面 获取登录信息接着判断参数是否为函数（是否可调用），如果可以调用，就调用它获取登录信息。在这里不需要关心函数内部具体如何获取，而只用关心它的接口。 这个函数的返回值是一个装有登录信息的 dict，和一个 cookies。 12345def login(self,login_url,login_data_parser=None,target_url=None): login_data=None #get the login data if(login_data_parser!=None and callable(login_data_parser)): login_data,cookies=login_data_parser(login_url) 登录然后就完成了 1234567891011121314151617181920212223def login(self,login_url,login_data_parser=None,target_url=None): ''' login :param login_url: the url you want to login :param login_data_parser: a callback function to get the login_data you need when you login,return (login_data,response.cookies) :param target_url: Used to determine if you have logged in successfully :return: response of login ''' login_data=None #get the login data if(login_data_parser!=None and callable(login_data_parser)): login_data,cookies=login_data_parser(login_url) #login response=requests.post(login_url,headers=self.headers,data=login_data,cookies=cookies) if(target_url!=None and response.url==target_url): print(&quot;login successfully&quot;) self.cookies=cookies return response 获取登录信息函数这个和前面就是一样的了。只要修改传给 login 函数的函数，就可以获取不同网站的登录信息。login 函数变得更加通用了，不再过于依赖登录信息函数存在。 1234567891011121314151617181920212223242526def chd_login_data_parser(self,url): ''' This parser is for chd :param url: the url you want to login :return (a dict with login data,cookies) ''' response=requests.get(login_url) html=response.text # parse the html soup=BeautifulSoup(html,'lxml') lt=soup.find('input',{'name':'lt'})['value'] dllt=soup.find('input',{'name':'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data={ 'username': input('input account:'), 'password': input('input passwd:'), 'btn':'', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } return login_data,response.cookies","link":"/posts/python_spider_note4optimization_of_the_login_function/"},{"title":"python爬虫学习笔记5爬虫类结构优化","text":"打算全部以 cookie 来登陆，而不依赖于 session（因为听组长说 session 没 cookie 快，而且我想学些新东西而不是翻来覆去地在舒适区鼓捣）。弄了几天终于弄出来个代码不那么混乱的爬虫类了，更新一下博文来总结一下。代码在我 github 的 spider 库里面。 初步思路既然要封装成爬虫类，那么就以面向对象的思维来思考一下结构。 从通用的爬虫开始，先不考虑如何爬取特定的网站。 以下只是刚开始的思路，并不是最终思路。 爬虫的行为步骤并不复杂，分为以下几步： 请求并获取网页（往往需要模拟登录） 解析网页提取内容（还需要先获取需要爬取的 url） 保存内容（保存到数据库） 爬虫类方法（初步设计）： 方法 说明 login 登录 parse 解析 save 保存 crawl 爬取（外部调用者只需调用这个方法即可） 爬虫类属性（初步设计）： 属性 说明 headers 请求的头部信息，用于伪装成浏览器 cookies 保存登录后得到的 cookies db_data 数据库的信息，用于连接数据库 进一步设计我想将这个爬虫类设计得更为通用，也就是只修改解析的部分就能爬取不同的网站。组长说我这是打算写一个爬虫框架，我可没那么厉害，只是觉得把逻辑写死不能通用的类根本不能叫做类罢了。 参考代码我看了一下组长给出的参考代码，大致结构是这样的： 首先一个Parse解析类（为了关注结构，具体内容省略）： 12345678910111213141516171819202122232425262728293031323334353637383940class Parse(): def parse_index(self,text): ''' 用于解析首页 :param text: 抓取到的文本 :return: cpatcha_url, 一个由元组构成的列表(元组由两个元素组成 (代号，学校名称)) ''' pass def parse_captcha(self, content, client): ''' 解析验证码 :return: &lt;int&gt; or &lt;str&gt; a code ''' pass def parse_info(self, text): ''' 解析出基本信息 :param text: :return: ''' pass def parse_current_record(self, text): ''' 解析消费记录 :param text: :return: ''' return self.parse_info(text) def parse_history_record(self, text): ''' 解析历史消费记录 :param text: :return: ''' return self.parse_info(text) 这个思路不错，将解析部分独立形成一个类，不过这样要如何与爬虫类进行逻辑上的关联呢？解析类的对象，是什么？是解析器吗？解析器与爬虫应该是什么关系呢？ 我继续往下看： 12345678910111213141516class Prepare(): def login_data(self,username, password, captcha, schoolcode, signtype): ''' 构造登陆使用的参数 :return:data ''' pass#省略代码，下同 def history_record_data(self, beginTime, endTime): ''' 历史消费记录data :param beginTime: :param endTime: :return: data ''' pass 这是一个Prepare类，准备类？准备登录用的数据。说起来似乎比解析类更难以让我接受。解析器还可以说是装在爬虫身上，但是，但是“准备”这件事情分明是一个动作啊喂！ 好吧，“一类动作”倒能说得过去吧。我看看怎么和爬虫类联系起来： 12class Spider(Parse, Prepare):#??? pass 等会儿等会儿…… 继承关系？ 让我捋捋。 为了让爬虫能解析和能准备还真是不按套路出牌啊…… 子类应该是父类的特化吧不是吗，就像猫类继承动物类，汽车类继承车类一样，猫是动物，汽车也是车。 算了不继续了，毕竟我不是为了故意和我组长作对。只是将其作为一个例子来说明我的思路。 解析器类参考代码虽然不太能让我接受，但是它的结构仍然带给了我一定启发。就是解析函数不一定要作为爬虫的方法。 解析这个步骤如果真的只写在一个函数里面真的非常非常乱，因为解析不只一个函数。比如解析表单的隐藏域，解析页面的 url，解析页面内容等。 单独写一个解析类也可以。至于它和爬虫类的关系，我觉得组合关系更为合适（想象出了一只蜘蛛身上背着一个红外透视仪的样子），spider 的解析器可以更换，这样子我觉着更符合逻辑一些。 关于更换解析器的方式，我打算先写一个通用的解析器类作为基类，而后派生出子解析器类，子解析器根据不同的网站采取不同的解析行为。 然后新建my_parser.py文件，写了一个MyParser类。解析方式是 xpath 和 beautifulsoup。这里面的代码是我把已经用于爬取学校网站的特定代码通用化之后的示例代码，实际上并不会被调用，只是统一接口，用的时候会新写一个类继承它，并覆盖里面的函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class MyParser(object): def login_data_parser(self,login_url): ''' This parser is for chd :param url: the url you want to login :return (a dict with login data,cookies) ''' response=requests.get(login_url) html=response.text # parse the html soup=BeautifulSoup(html,'lxml') #insert parser,following is an example example_data=soup.find('input',{'name': 'example_data'})['value'] login_data={ 'example_data':example_data } return login_data,response.cookies def uni_parser(self,url,xpath,**kwargs): response=requests.post(url,**kwargs) html=response.text tree=etree.HTML(html) result_list=tree.xpath(xpath) return result_list def get_urls(self,catalogue_url,**kwargs): ''' get all urls that needs to crawl. ''' #prepare base_url='http://example.cn/' cata_base_url=catalogue_url.split('?')[0] para = { 'pageIndex': 1 } #get the number of pages xpath='//*[@id=&quot;page_num&quot;]/text()' page_num=int(self.uni_parser(cata_base_url,xpath,params=para,**kwargs)) #repeat get single catalogue's urls xpath='//a/@href'#link tag's xpath url_list=[] for i in range(1,page_num+1): para['pageIndex'] = i #get single catalogue's urls urls=self.uni_parser(cata_base_url,xpath,params=para,**kwargs) for url in urls: url_list.append(base_url+str(url)) return url_list def get_content(self,url,**kwargs): ''' get content from the parameter &quot;url&quot; ''' html=requests.post(url,**kwargs).text soup=BeautifulSoup(html,'lxml') content=soup.find('div',id='content') content=str(content) return content 我把构造登录信息的部分放在了解析器中。并在登录中调用。 登录之后得到的 cookies 就在参数中传递。 数据库类由于只打算存到数据库，所以并没有写一个“存档宝石类“，或许之后会写。 目前我只写了一个保存函数，以及自己封装的一个数据库类。 这个数据库类是my_database.py中的MyDatabase（应该不会撞名吧），目前只封装了 insert 函数，传入的参数有三个：数据库名，表名，装有记录的字典。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import pymysqlclass MyDatabase(object): def __init__(self,*args,**kwargs): self.conn=pymysql.connect(*args,**kwargs) self.cursor=self.conn.cursor() def insert(self,db,table,record_dict): ''' :param db:name of database that you want to use :param table:name of table that you want to use :param record_dict:key for column,value for value ''' #1.use the database sql='use {}'.format(db) self.cursor.execute(sql) self.conn.commit() #2.connect the sql commend sql='insert into {}('.format(table) record_list=list(record_dict.items()) for r in record_list: sql += str(r[0]) if r != record_list[-1]: sql += ',' sql+=') values(' for r in record_list: sql += '&quot;' sql += str(r[1]) sql += '&quot;' if r != record_list[-1]: sql += ',' sql+=')' #3.commit self.cursor.execute(sql) self.conn.commit() def show(self): pass def __del__(self): self.cursor.close() self.conn.close()if __name__ == &quot;__main__&quot;: db_data={ 'host':'127.0.0.1', 'user':'root', 'passwd':'password', 'port':3306, 'charset':'utf8' } test_record={ 'idnew_table':'233' } mydb=MyDatabase(**db_data) mydb.insert('news','new_table',test_record) 封装之后用起来比较方便。 save 函数123456def save(content,**save_params): mydb=MyDatabase(**save_params) record={ 'content':pymysql.escape_string(content) } mydb.insert('dbase','bulletin',record) pymysql.escape_string()函数是用于将内容转义的，因为爬取的是 html 代码（就不解析那么细了，直接把那一块 html 代码全部存下来，打开的时候格式还不会乱），有些内容可能使组合成的 sql 语句无法执行。 爬虫类给构造函数传入特定的解析器和保存函数，然后调用 crawl 方法就可以让 spider 背着特制的 parser 去爬取网站内容啦~ 登录函数和上次不太一样，做了一些修改，不过主要功能仍然是获取登录之后的 cookies 的。 简单说一下修改：我们学校网站登录之后会从登陆页面开始，经过三四次跳转之后才到达首页，期间获取到的 cookies 都需要保留，这样才能利用这些 cookies 来进入新闻公告页面。于是禁止重定向，手动获取下一个 url，得到这一站的 cookies 之后再手动跳转，直到跳转到首页。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import requestsclass MySpider(object): def __init__(self,parser,save,**save_params): self.parser=parser#parser is a object of class self.save=save#save is a function self.save_params=save_params self.cookies=None self.headers={ &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36&quot; } def login(self,login_url,home_page_url): ''' login :param login_url: the url you want to login :param login_data_parser: a callback function to get the login_data you need when you login,return (login_data,response.cookies) :param target_url: Used to determine if you have logged in successfully :return: response of login ''' login_data=None #get the login data login_data,cookies=self.parser.login_data_parser(login_url) #login without redirecting response=requests.post(login_url,headers=self.headers,data=login_data,cookies=cookies,allow_redirects=False) cookies_num=1 while(home_page_url!=None and response.url!=home_page_url):#if spider is not reach the target page print('[spider]: I am at the &quot;{}&quot; now'.format(response.url)) print('[spider]: I have got a cookie!Its content is that \\n&quot;{}&quot;'.format(response.cookies)) #merge the two cookies cookies=dict(cookies,**response.cookies) cookies=requests.utils.cookiejar_from_dict(cookies) cookies_num+=1 print('[spider]: Now I have {} cookies!'.format(cookies_num)) next_station=response.headers['Location'] print('[spider]: Then I will go to the page whose url is &quot;{}&quot;'.format(next_station)) response=requests.post(next_station,headers=self.headers,cookies=cookies,allow_redirects=False) cookies=dict(cookies,**response.cookies) cookies=requests.utils.cookiejar_from_dict(cookies) cookies_num+=1 if(home_page_url!=None and response.url==home_page_url): print(&quot;login successfully&quot;) self.cookies=cookies return response def crawl(self,login_url,home_page_url,catalogue_url): self.login(login_url,home_page_url) url_list=self.parser.get_urls(catalogue_url,cookies=self.cookies,headers=self.headers) for url in url_list: content=self.parser.get_content(url,cookies=self.cookies,headers=self.headers) self.save(content,**self.save_params) def __del__(self): pass 调用为了更好地展示结构，大部分内容都 pass 省略掉。想看具体代码可以去我 github 的spider 库 这个文件内首先创建了一个特定解析类，继承自通用解析类，再写了一个保存函数，准备好参数，最后爬取。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from my_spider import MySpiderfrom my_parser import MyParserfrom my_database import MyDatabasefrom bs4 import BeautifulSoupimport requestsimport pymysqlclass chdParser(MyParser): def login_data_parser(self,login_url): ''' This parser is for chd :param url: the url you want to login :return (a dict with login data,cookies) ''' pass return login_data,response.cookies def get_urls(self,catalogue_url,**kwargs): ''' get all urls that needs to crawl. ''' #prepare pass #get page number pass #repeat get single catalogue's urls pass for i in range(1,page_num+1): para['pageIndex'] = i #get single catalogue's urls pass return url_listdef save(content,**save_params): passif __name__ == '__main__': login_url=&quot;pass&quot;#省略 home_page_url=&quot;pass&quot; catalogue_url=&quot;pass&quot; parser=chdParser() save_params={ 'host':'127.0.0.1', 'user':'root', 'passwd':'password', 'port':3306, 'charset':'utf8' } sp=MySpider(parser,save,**save_params) sp.crawl(login_url,home_page_url,catalogue_url)","link":"/posts/python_spider_note5optimization_of_the_spider_class/"},{"title":"练习利用Scrapy爬取b站排行榜","text":"开始学 python 的 Scrapy 框架了，参考书是崔庆才的《python3 网络爬虫开发实战》 跟着示例敲完之后，又试着按照一样的逻辑去爬取了 B 站排行榜的数据。 通过这个小项目学习使用 Scrapy 框架。 步骤新建项目首先新建一个名为practice的项目 1$scrapy startproject practice 这个项目的目录结构（省略 init 文件）： practice practice items.py middlewares.py pipelines.py settings.py scrapy.cfg 这一个项目里面的代码是整个项目的爬虫通用的。 新建 Spider新建一个爬虫bilibiliRank 12$cd practice$scrapy genspider bilibiliRank 然后与在此目录下出现了一个spider文件夹，用于存放这个新的爬虫 spider bilibiliRank.py bilibiliRank.py中： 123456789import scrapyclass BilibilirankSpider(scrapy.Spider): name = 'bilibiliRank'#爬虫名字 allowed_domains = ['bilibili.com']#允许爬取的域名 start_urls = ['https://www.bilibili.com/ranking/']#初始url def parse(self, response): pass spider文件夹里面是用于爬取不同网站的爬虫，它继承自scrapy.Spider，scrapy 的引擎Engine就是利用你写的爬虫里面的parse()方法来解析页面获取数据，可以在这个方法里面将数据以item的形式返回出去，给ItemPipeline继续处理。 创建 Itemitems.py里面定义了不同的 item，这些 item 都继承自scrapy.Item，文件生成的内容如下（无关注释已删去）： 123456import scrapyclass PracticeItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() pass 在这里你可以照着它的模板新建一个类，也可以直接修改，总之只要符合要求就可以： 12345678import scrapyclass RankItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() num=scrapy.Field() title=scrapy.Field() 在这个 Item 子类当中，我新建了两个域，也可以说是字段。按照注释给出的格式来就可以了。 解析 response适当简化的流程大概是：引擎利用爬虫的start_url发起请求，然后将得到的响应response作为参数传入爬虫的parse()方法中。parse()将解析出的数据装入Item并返回给引擎。 需要解析的 html 页面内容（只展示其中一个项的结构）： 123456789101112131415161718192021222324252627282930313233&lt;ul class=&quot;rank-list&quot;&gt; &lt;li class=&quot;rank-item&quot;&gt; &lt;div class=&quot;num&quot;&gt;1&lt;/div&gt; &lt;div class=&quot;content&quot;&gt; &lt;div class=&quot;img&quot;&gt; &lt;a href=&quot;//www.bilibili.com/video/av56121331/&quot; target=&quot;_blank&quot;&gt; &lt;div class=&quot;lazy-img cover&quot;&gt; &lt;img alt=&quot;视频标题&quot; src=&quot;图片url&quot; /&gt; &lt;/div&gt; &lt;/a&gt; &lt;div class=&quot;watch-later-trigger w-later&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;info&quot;&gt; &lt;a href=&quot;视频url&quot; target=&quot;_blank&quot; class=&quot;title&quot;&gt;视频标题&lt;/a &gt;&lt;!----&gt; &lt;div class=&quot;detail&quot;&gt; &lt;span class=&quot;data-box&quot;&gt; &lt;i class=&quot;b-icon play&quot;&gt;&lt;/i&gt;366.8万&lt;/span&gt; &lt;span class=&quot;data-box&quot;&gt;&lt;i class=&quot;b-icon view&quot;&gt;&lt;/i&gt;3.8万&lt;/span&gt; &lt;a target=&quot;_blank&quot; href=&quot;视频url&quot;&gt; &lt;span class=&quot;data-box&quot;&gt; &lt;i class=&quot;b-icon author&quot;&gt;&lt;/i&gt;作者名&lt;/span &gt;&lt;/a &gt; &lt;/div&gt; &lt;div class=&quot;pts&quot;&gt; &lt;div&gt;3798978&lt;/div&gt; 综合得分 &lt;/div&gt; &lt;/div&gt; &lt;!----&gt; &lt;/div&gt; &lt;/li&gt;&lt;/ul&gt; 爬虫文件： 1234567891011121314151617import scrapyfrom practice.items import RankItem#这是之前自定义的itemclass BilibilirankSpider(scrapy.Spider): name = 'bilibiliRank' allowed_domains = ['bilibili.com'] start_urls = ['https://www.bilibili.com/ranking/'] def parse(self, response): #获取所有的项目 rank_items=response.css('.rank-list .rank-item') #获取每一项中的数据 for rank_item in rank_items: item=RankItem() item['num']=rank_item.css('.num::text').extract_first() item['title']=rank_item.css('.content .info .title::text').extract_first() yield item#每次调用就会返回一个item 遇到的问题： 注意获取的所有项目得是一个节点，不能用extract()读取其中的数据，第一次写时，写成了： 123rank_list=response.css('.rank-item').extract()for rank_item in rank_list: #…… 爬取1$scrapy crawl bilibiliRank -o bilibiliRank.json 利用名为bilibiliRank爬虫进行爬取，并将得到的结果保存在bilibiliRank.json文件中 参考链接 scrapy 官方中文文档","link":"/posts/Scrapy_spider_bilibiliRank/"},{"title":"hexo日记本","text":"打算从纸质日记转到电子日记。 之前是一个月的日记放在一个 markdown 文件里面，每天一个一级标题。昨天突发奇想，为啥不用 Hexo 来搭建日记本呢？它本来就是用来写博客（blog 网络日志）的呀。 于是今天就来搭建 hexo 日记本 前言本文只分享设计思路以及步骤，不提供详细教程，详细教程可以看这个：【持续更新】最全 Hexo 博客搭建+主题优化+插件配置+常用操作+错误分析-遇见西门 优点利用 hexo 搭建日记本有很多优点： 好看，并且可以随时换主题 比我之前的方式更加地将日记格式化，便于以后编写脚本来管理 可以在scaffolds里面设置日记模板 可以设置分类与标签 有的主题甚至能搜索文章 需求 不联网：这个日记本和我部署到 github 上面的博客有些不一样，因为这个是比较隐私的，我不打算放在网上，仅利用移动硬盘备份。并且看日记都在本地，不使用外链图片，以免断网的时候无法查看 功能少：并且不需要评论，阅读计数等功能，起到的只是一个阅读器的作用。 重美观：需要能够方便地切换主题。 无需侧边目录：因为我打算一篇只记录一天的内容，写不了太多，标题层级不会太多。 写日记要便捷 步骤参考链接： hexo 官方中文文档 初始化 hexo刚开始的时候我不是很清楚 hexo 在一台电脑上是否可以搭多个博客，后来发现，hexo 的每个博客其实就是一个“项目”，那些命令得在已经搭建博客的文件夹里面才能使用，而不是我之前想的“全局命令”。 首先初始化： 123hexo init &lt;folder&gt;cd &lt;folder&gt;npm install 然后就可以通过以下命令查看本地内容了： 1hexo server 或简写为 1hexo s 全局设置在博客根目录下的_config.yml内配置 标题相关1234567title: 日记subtitle:description:keywords:author: 憧憬少language: zh-CNtimezone: permalink这个设置会决定你的文件最后渲染之后放在哪里。 利用hexo g来渲染 markdown 文件，它会将渲染好的 html 文件放在public目录下，部署到 github 时，上传的就是这个文件夹里面的内容。 比如最开始的设置： 1permalink: :year/:month/:day/:title/ 则会将最开始的hello-world.md示例文章给生成在public\\2019\\06\\26\\hello-world这个文件夹当中。 我觉得一天的内容单独放一个文件夹有点不太合适，而一年的内容全部放在一个文件夹的话，三百多个文件也不好管理，所以按照一个月的内容放在一个文件夹内的规则，将这个设置改成： 1permalink: :year/:month/:title/ new_post_name新建文章的文件名，因为日记按照时间管理比较方便，因此在文件名中加入日期 1new_post_name: :year-:month-:day-:title.md # File name of new posts 图片问题我之前一直是将图片上传到 github 的一个 repo 上面然后使用链接的，看了文档之后才发现原来还有更简便的方法！ 方法一 外链首先开启仓库的 github page 这个设置。 比如用户名是HaneChiri，创建的仓库名叫blog_images，那么在这个仓库根目录下的图片avatar.jpg的链接就是 1https://hanechiri.github.io/blog_images/avatar.jpg 而不是 1https://github.com/HaneChiri/blog_images/avatar.jpg 后者是浏览编辑这个图片的链接，而不是图片本身。 上传之后无法访问这个链接也不要急，等几分钟就可以了。 日记本不能使用这个，因为我需要在不联网的时候也能看。 方法二 资源文件夹来自资源文件夹-hexo 官方文档 资源（Asset）代表 source 文件夹中除了文章以外的所有文件，例如图片、CSS、JS 文件等。比方说，如果你的 Hexo 项目中只有少量图片，那最简单的方法就是将它们放在 source/images 文件夹中。然后通过类似于 ![](/images/image.jpg) 的方法访问它们。 早知道认真看文档了，插图片就简单多了。 这个是将图片放在source/images中，而我将 Typora 设置成将图片自动保存在同目录下的images中，编辑之后只要将这个文件夹内图片给复制到前者所述文件夹，就可以在编辑以及渲染时都看到图片了。 方法三 下载插件Hexo 文章中插入图片的方法-CSDN 我不需要每个文章的图片分开管理，这样会导致source\\_posts\\内有太多没用的空文件夹，因此我使用方法二，读者可以选择适合自己的方法。 主题为了防止和联网的博客弄混（毕竟一旦将日记上传上去，repo 里面就会留下痕迹，哪怕删掉也看得到，除非删 repo），我打算换个别的主题。 找到了几个心仪的： Gal ：galgame。和我第一次用的夏娜 shana主题是同类型的 Sakura ：樱。贼好看，功能蛮多的样子 One ：单页面。每个文章都可以配图，上面的几个也是 但是考虑到个人的一些因素，还是先用着 Next 吧，反正可以换。 外观Next 主题有四种外观（scheme），在配置文件（themes\\next\\_config.yml）中可以找到并修改： 12345# Schemes#scheme: Muse#scheme: Mist#scheme: Piscesscheme: Gemini 侧边栏社交链接最右边的||后面跟着的是文字边上显示的图标 12345678910111213social: GitHub: https://github.com/HaneChiri || github #E-Mail: mailto:yourname@gmail.com || envelope #Weibo: https://weibo.com/yourname || weibo #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skype Bilibili: https://space.bilibili.com/13290087 头像在对应的位置放上头像图片 123456789101112# Sidebar Avataravatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: /images/avatar.gif # If true, the avatar would be dispalyed in circle. rounded: false # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: false 左右为了防止和博客混淆而误将日记上传，而将侧边栏调整到相反方向 1234sidebar: # Sidebar Position, available values: left | right (only for Pisces | Gemini). #position: left position: right 回到顶部这么好用的小功能当然要开着呀！ 123456back2top: enable: true # Back to top in sidebar. sidebar: true # Scroll percent label in b2t button. scrollpercent: true 菜单首先在解开“分类”(categories)和“标签”(tags)的注释 123456789menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 但是这个还只是在侧边的菜单栏处显示了“分类”和“标签”两项，还没有功能。 需要在根目录下使用指令来生成这两个页面： 12hexo new page categorieshexo new page tags 这下能显示了，但是仍然不够，因为 Next 还没有识别出这两个页面就是分类和标签页面。 打开source\\categories\\index.md，里面是： 12345---title: categoriesdate: 2019-06-26 15:44:09--- 在里面加上一句，变成： 123title: categoriesdate: 2019-06-26 15:44:09type: &quot;categories&quot; 这样就能识别出这是分类页面了，能够使用了。标签页面同理。 本地搜索第一步 修改主题设置找到这个设置： 1234567891011# Local search# Dependencies: https://github.com/theme-next/hexo-generator-searchdblocal_search: enable: true # If auto, trigger search by changing input. # If manual, trigger search by pressing enter key or search button. trigger: auto # Show top n results per article, show all results by setting to -1 top_n_per_article: 1 # Unescape html strings to the readable one. unescape: false 将enable改为 true 之后就会在菜单显示一个”搜索“，但是还无法使用。 照着注释里面那个 github 项目内的说明 第二步 下载插件：1npm install hexo-generator-searchdb --save 第三步 添加全局设置在根目录下的_config.yml加上如下设置： 123456search: path: search.xml field: post format: html limit: 10000 content: true 我把帮助中的注释复制过来就是下面这样： 12345678910111213141516171819# see https://github.com/theme-next/hexo-generator-searchdbsearch: # file path. By default is search.xml . If the file extension is .json, the output format will be JSON. Otherwise XML format file will be exported. path: search.xml # the search scope you want to search, you can chose: # post (Default) - will only covers all the posts of your blog. # page - will only covers all the pages of your blog. # all - will covers all the posts and pages of your blog. field: post # the form of the page contents, works with xml mode, options are: # html (Default) - original html string being minified. # raw - markdown text of each posts or pages. # excerpt - only collect excerpt. # more - act as you think. format: html #define the maximum number of posts being indexed, always prefer the newest. limit: 10000 # whether contains the whole content of each article. If false, the generated results only cover title and other meta info without mainbody. By default is true. content: true 意外地轻松便捷呢。 编写快捷打开的脚本虽然弄好了，但是每次想写还得打开命令行输入命令，再进入文件夹用 Typora 打开文件，太麻烦了。 于是写一下 bat 批处理脚本。 这东西其实就是把在命令行执行的命令放在一个文本文件然后把后缀名改成.bat 而已。 不过我不是很熟命令，弄了很久。 快速打开本地预览首先是快速查看我的日记。目标是双击一下脚本文件就可以在浏览器中看到我的日记。 一般情况下的步骤： 在根目录打开命令行 输入hexo s 打开浏览器 在地址栏输入localhost:4000 我写出来的.bat 文件是这样的： 12set browser=&quot;C:\\Program Files (x86)\\Tencent\\QQBrowser\\QQBrowser.exe&quot;%browser% localhost:4000 &amp;&amp; hexo s 只有两行，第一行是设置用于打开日记本的浏览器所在的位置，当然，如果设置了环境变量，这里可以直接写浏览器的名字。 第二行是利用这个浏览器打开localhost:4000，打开成功才执行hexo s来启动 hexo。 新建日记一般情况下的步骤： 在根目录打开命令行 输入hexo new &lt;title&gt; 打开source\\_posts\\ 找到并打开新建的日记 获取标题1set /p title=请输入标题: /p表示动态输入 创建文件1hexo new &quot;%title%&quot; %变量名%表示引用已经赋值的变量。 打开文件由于我设置的文件名不只是标题，因此还需要获取日期来组成文件名。 12345678set year=%date:~0,4%set month=%date:~5,2%set day=%date:~8,2%rem 在这里设置你的文件名格式set new_post_name=%year%-%month%-%day%-%title%&quot;S:\\Program Files\\Typora\\Typora.exe&quot; source\\_posts\\%new_post_name%.md 其中： %date%是系统变量，用于获取系统时间，返回的值的格式是2019/06/26 周三 %date:~x,y%代表从第 x 个字符开始，获取 y 个字符 刚开始的脚本代码是这样的： 12345678910set /p title=请输入标题:hexo new &quot;%title%&quot;set year=%date:~0,4%set month=%date:~5,2%set day=%date:~8,2%rem 在这里设置你的文件名格式set new_post_name=%year%-%month%-%day%-%title%&quot;S:\\Program Files\\Typora\\Typora.exe&quot; source\\_posts\\%new_post_name%.md 但是我发现在执行完hexo new &quot;%title%&quot;之后，命令行直接退出，加pause都没用。 猜测是因为，hexo 创建文件需要时间，还没创建好就打开，于是出错了。 后来改成： 1hexo new &quot;%title%&quot; &amp;&amp; call z_open_editor.bat 在创建完之后，才会执行后面的内容，后面的代码都放在z_open_editor.bat里面 最终代码： 1234rem z_new_diary.bat@echo offset /p title=请输入标题:hexo new &quot;%title%&quot; &amp;&amp; call z_open_editor.bat 1234567891011121314151617rem z_open_editor.batrem 本文件只支持打开默认布局的文件@echo offset year=%date:~0,4%set month=%date:~5,2%set day=%date:~8,2%dir source\\_postsif not defined title set /p title=请输入标题:rem 在这里设置你的文件名格式set new_post_name=%year%-%month%-%day%-%title%echo source\\_posts\\%new_post_name%.md&quot;S:\\Program Files\\Typora\\Typora.exe&quot; source\\_posts\\%new_post_name%.md","link":"/posts/hexo_diary/"},{"title":"调整博客分类","text":"目前个人博客内的分类不太合理，于是重新调整分类 调整前分类 c++ java python 工具 日志 流程 算法 标签 awt c++ git hexo java mysql notepad++ python scrapy stl 信息检索 小游戏 日志 爬虫 算法 项目 题目 分析c++、java、python 等大类很明显和标签重叠了。 我目前对二者的理解： 分类表明一个事物是什么； 标签表明一个事物有什么。 按照文章区别于其他类型文章的特征来分类。 新建一个标签前，要考虑这个标签的可重用性，比如 c++、java 这类标签肯定会经常用到，但是 notepad++这类基本只用一次了，所以将它归到 IDE 这个标签内。stl 和 awt 这类标签不常用，可以删去。 调整后分类 分类 内容 工具使用 工具的获取（下载安装）、使用，类似教程 编程语言 记录遇到的一些语法问题 项目总结 主要记录过程及遇到的问题与方案，包括一些感想和体会 算法模型 记录一些算法相关的题目以及概念 过程记录 记录解决方案和过程，记录经验总结，简化版的项目总结，侧重过程 调整之后，分类比之前清晰多了，我写新的博文，就知道应该归类到哪里，找的时候也知道应该到哪里去找了。 标签减少了一些标签 IDE ：分得比较宽泛，连 notepad++都算进去 c++ git hexo java mysql python scrapy 框架 爬虫","link":"/posts/adjust_categories/"},{"title":"python相对路径是相对于哪里","text":"在学习 scrapy 时，保存数据到文件的时候，发现一直出现“找不到这样的文件或文件夹”的错误，最后发现是因为 python 的相对路径。 问题描述学习 scrapy 时，编写 pipeline 来将数据保存到文件当中，代码如下： 123456class NovelPipeline(): def process_item(self, item, spider): with open('Novel/'+str(item['title'][0])+'.txt','w') as f: for p in item['content']: f.write(p+'\\n') return item 看着爬取时调试信息飞快闪过（爬取的东西有点多），却没有发现我准备好的 Novel 文件夹里面多出文件，连忙把爬虫停下来。发现出现了“找不到这样的文件或文件夹”的错误。 分析过程查看日志信息，发现文件名是对的，但是为什么不行呢？ 于是我在pipelines.py里面写了测试代码： 12with open('Novel/'+'文件名'+'.txt','w') as f: print(1) 发现同样的错误。 我把前面的文件夹去掉，也就是： 12with open('文件名'+'.txt','w') as f: print(1) 发现文件生成在了我的工作目录下！ 这个时候我才注意到相对路径的问题。 当前目录是这样的（略去无关文件）： learn_scrapy 文件名.txt practice practice pipeline.py 我本来以为这个相对路径会使得文件生成在pipelines.py的同级目录下，但是却生成在了我的 VScode 的工作文件夹？ 我回忆起 java 课时老师写错相对路径导致无法显示图片的问题。那时也是需要相对当前项目的根目录来写相对路径的。我认为这是 eclipse 的特性。 会不会这个也是 vscode 的特性？ 于是我搜索“python 相对路径”，找到了和我遇到类似问题的朋友：vscode 中使用 python 相对路径问题?-知乎 我的工作目录是/Work 我在工作目录中创建了文件/Work/Program/main.py 并且运行 main.py 生成了 file.txt 文件 12with open('file.txt','w') as f: f.write('HelloWorld') 我以为 file.txt 在/Work/Program 路径下，和创建它的 main.py 在一个路径中 结果 file.txt 这个文件却在/Work 路径下面（/Work/file.txt），而不是我所期望的/Python/Program 路径下面 所以应该怎么配置，或者安装什么插件，能让 py 创建的文件在自己的相对路径下，而不是直接跑到了工作路径那里？ 这个问题怎么解决啊，困扰了我好久，而我又比较喜欢 vscode 的界面不想放弃它。求解答！ 看了回答之后我继续搜索，终于解决了困惑。 解决方案参考链接： Python 里使用相对路径的坑-简书 Python 里写这种相对路径, 是相对于终端的当前目录的. 解决办法是, 获取脚本所在目录, 构造绝对路径","link":"/posts/python_relative_path/"},{"title":"一个好用的图床管理工具PicGo","text":"先前给 hexo 博客插图片都是把图片 commit 到 github 上再手动构造链接，比较麻烦，又不想把图片直接放在博客所在的库。 这次找到了一个好东西：PicGo 测试一下图片： 很方便的一个工具，简单地截图然后上传剪切板图片，它就自动帮我上传到 github 上我准备好的库里面，然后把 markdown 格式的图片引用复制到我的剪切板里面。 具体如何下载安装和使用，它的官方文档肯定比我写的详细，不赘述。 我使用的是 github 图床（当然，它还支持别的图床），提一下与它相关的一个比较重要的插件。 PicGo 插件：github-plus它的 github 库链接 它的作用是，让本地的 PicGo 相册和 github 库的内容同步。 PicGo 本体只负责上传，不负责删除。我在发现上传错图片，在 PicGo 相册中删除了图片之后，发现 github 上面并没有删除这些图片。这是个比较严重的问题。而手动删除的时候很麻烦，要 clone 到本地，删除之后再提交。 好在找到了这个插件。 这个插件的功能： 将删除操作同步到 github 从 github 上把图片同步到本地相册，从而可以复制链接","link":"/posts/PicGo_imgur/"},{"title":"WIN10共享文件夹","text":"这是我以前写的第一篇博客的补档，由于图片太多于是就发在了 CSDN，现在不愁图片的问题了，于是就在整理电脑文件时把这篇博客在个人博客这边发一下。 这是在 CSDN 的第一篇博客，也是我第一篇正式的博客。 我们的 linux 老师上课时用到了共享文件夹，于是我就百度学习了一下。 来写一下刚刚学到的共享文件夹的方法。 共享方法 首先右键你想要共享的文件夹，【共享】-&gt;【特定用户】 2.在选择框里面选择 Everyone，接着点击旁边的【添加】 3.调整权限后，点击【共享】即可 4.共享完成 别人进入共享文件夹的方法1.你可以复制系统给你的链接给局域网内（我只试过局域网）的别人，让他复制到文件资源管理器地址栏 2.或者找到资源管理器最左下角的【网络】，让他点进去就是了。 点进去之后的效果是这样： 然后你就可以用这个文件夹和局域网里的各位来分享文件了。","link":"/posts/win10_share_folder/"},{"title":"excel实现周总结签到积分制","text":"我在自己一个学习群里设定了一个周总结制度，这篇博客记录一下如何使用 excel 函数来实现计算打卡相册的积分。这里其实我用的是 wps 表格，但是函数一样，所以我就分类在 excel 里面。 简介每周日，每个人在群聊天发一个周总结，内容是自己这周学习了什么，没有限制，只是给大家一个自我反省的机会。 如果没有可以写的东西，那么也在群里面报备，方式为在群聊天中说：“本周无总结”或者别的能表明这一事实的话。别有压力，只是回复一句话的功夫。 如果没有报备也没有在截止之前发周总结，将会被艾特提醒。可以在下一周总结之前补。 为了方便描述，下文把发送周总结称为“签到” 积分规则 如果本周签到了，积分=原本积分+正调整参数 如果未签到，积分=原本积分+负调整参数 如果补签到，积分=原本积分 签到登记表样例 成员 ID 昵称 正常签到次数 周总结积分 week1 week2 week3 week4 week5 week6 1 憧憬少 1 1 1 2 听星缘 1 1 1 3 简白 1 1 1 4 HUST 1 1 1 5 咸鱼米 1 1 1 1 表示已签到，-1 表示未签到，补签改为 0 编写公式正常签到次数即计算 1 出现的次数（补签不算），如果用之前的SUMIF函数就是： 1=SUMIF(对应成员的签到区域,1) 但是我又查到一个更适合的函数：COUNTIF 参数和SUMIF差不多含义，写成公式也是一样 1=COUNTIF(对应成员的签到区域,1) 但是前者只能计算 1 出现的次数，如果计算-1 出现的次数就不行了。 周总结积分比较简单，不赘述了。 1=COUNTIF(E2:ZZ2,1)*积分规则!$C$3+COUNTIF(E2:ZZ2,-1)*积分规则!$D$3*(-1)","link":"/posts/excel_weekly_sign/"},{"title":"excel实现打卡相册积分制","text":"我在自己一个学习群里设定了一个打卡相册制度，这篇博客记录一下如何使用 sumif 函数来实现计算打卡相册的积分。这里其实我用的是 wps 表格，但是函数一样，所以我就分类在 excel 里面。 规则说明群员可以申请建立打卡相册，需要自己下载群文件中的登记表填写相关信息，然后就可以创建群相册，在群相册描述里面写上打卡内容。 相册状态 相册状态：正在进行、放弃、失败、归档 如果连续三天未打卡，管理员就删除相册，并在登记表内将相册状态设置为“失败”。 对于有期限的相册，比如打卡目标是“两周读完《xxx》”，那么在结束日期时，可以将其状态设置为“归档”。相册资源回收（删除或改作他用），避免资源闲置。若持续时间大于等于一百天，则可以选择保留相册。（可以给其他群员作榜样） 对于没有期限的相册，比如“每天背单词”，那么在创建时间满三十天后就可以选择“归档”（三十天应该够养成一个小习惯了） 相册删除后，相册记录还会保留在登记表里面 积分计算 创建相册不需要积分，但是“放弃”或“失败”每个会扣除 5 积分 一个成员的打卡相册总积分=他所有相册的积分之和 单个相册的积分： 若相册状态是“正在进行”，则积分=持续天数1*正调整参数=正调整参数*（当前日期-创建日期） 若相册状态是“归档”，则积分=正调整参数*持续天数2=正调整参数*（结束日期-创建日期）,目前参数为 0.5 若相册状态是“放弃”或“失败”，则积分=负调整参数，也就是扣除积分，目前参数为-5，即扣除 5 积分 相册字段 字段 描述 相册 ID 这个手动赋值为：最大的相册 ID+1 申请人昵称 可以写真名或者自己的群名片昵称，只要大家能通过这个知道是谁即可 相册名称 无特别要求，不过最好写明昵称和目的，例如：憧憬少的英语流利说 APP 打卡 相册目标描述 描述你要通过这个打卡相册达到的目标，例如：每天读口语 10 分钟 如何判断目标完成 上传到打卡相册的图片应当满足怎样的要求，例如：每天在相册内上传一张可以表明读了 10 分钟的截图 相册状态 目前用到的状态：正在进行，放弃，失败，归档（仅留表中记录，相册本身删除，若打卡满 100 天可选择保留） 创建日期 用于计算持续天数的字段 结束日期 归档日期，或有期相册结束日期。 持续天数 除了正在进行状态，其他状态都停止增加持续天数 相册类型 目前的类型：无期（未规定期限，满 30 天可以选择归档），有期（规定了完成期限，若期限内完成则归档，未完成则为失败） 打卡相册积分 利用表格的自动填充功能复制上一个相册的公式 编写公式计算相册持续天数相册持续天数有两种情况，一种是“正在进行”，一种是其他状态，只有“正在进行”的打卡相册会继续计算天数。 也就是说： “正在进行”的相册的持续天数=今天日期-创建日期 其他状态相册的持续天数=结束日期-创建日期 因此需要一个 IF 判断。 IF 函数的语法是： 1IF(条件，条件为真时的返回值，条件为假时的返回值) 公式如下（中文处替换为对应的单元格） 1=IF(相册状态=&quot;正在进行&quot;,TODAY()-创建日期,结束日期-创建日期) 计算打卡相册积分根据上述规则，我们需要用 IF 函数判断一下相册状态。 这里还用到了一个函数OR excel 里面的与或非不是用逻辑运算符的，而是用函数。 公式如下： 1=IF(相册状态=&quot;正在进行&quot;,1,0)*(积分规则!$C$2)*持续天数+IF(相册状态=&quot;归档&quot;,1,0)*(积分规则!$C$2)*持续天数+IF(OR(相册状态=&quot;失败&quot;,相册状态=&quot;放弃&quot;),1,0)*(积分规则!$D$2)*(-1) 其中，积分规则!$C$2代表的是我在另一个名为“积分规则”的表中的 C2 格中设置的一个正调整参数。积分规则!$D$2同理。 计算个人总积分一个成员可以有多个相册，因此需要将他所有的相册的积分相加。 相加可以使用SUM函数，来将已知区域求和。 例如现在的情况是这样的： 申请人昵称 相册名称 打卡相册积分 憧憬少 憧憬少的英语流利说打卡 18 简白 简白的英语打卡 12 咸鱼米 米米的啃书打卡 12 咸鱼米 米米的每日练习 5 H.U.S.T. H.U.S.T.的小说练笔 3 米米有两个相册，她的积分就是 12+5=17，相加的格子不确定，要如何用公式计算她的积分呢？ 我查到了SUMIF这个函数，也就是“条件相加”，格式如下： 1SUMIF(条件区域,求和条件,[实际求和区域]) 它的官方文档链接 条件区域：也就是要按条件计算的单元格区域。不太好理解，我的理解是，这个函数对于“条件区域”内符合条件的单元格进行求和。 求和条件：定义进行求和的单元格需要满足的条件。例如：32、”&gt;32”、B5、”32”、”苹果” 或 TODAY ()。任何文本条件或任何含有逻辑或数学符号的条件都必须使用双引号 (“) 括起来。 如果条件为数字，则无需使用双引号。 实际求和区域：如果省略，则将条件区域当作实际求和区域。 在这里，条件区域是“申请人昵称”，实际求和区域是“打卡相册积分”，求和条件是要计算积分的成员昵称。这样我们就可以将某个成员的所有相册数据所在的那几行给筛选出来，再将这几行的打卡相册积分相加，得到这个成员的总积分了。 某成员打卡相册总积分计算公式： 1=SUMIF(打卡相册登记表!B:B,某成员昵称,打卡相册登记表!K:K) 这里的B:B和K:K就分别对应了“申请人昵称”和“打卡相册积分”这两列。","link":"/posts/excel_clock_in_album/"},{"title":"python读取ini文件失败的原因","text":"尝试使用 python 的configparser来读取ini配置文件，但是遇到了No Section的错误。 最终发现其实是路径出了问题。 问题描述初始代码简化之后是： 1234567from configparser import ConfigParserif __name__ == '__main__': config=ConfigParser()#创建配置对象 config.read('test.ini')#读取配置文件 result=config.get(section='test',option='name')#读取test下的name print(result) 同目录的test.ini的内容如下： 12[test]name = tom 但是运行出现了configparser.NoSectionError: No section: 'test'的错误 原因探索经过单步调试后发现并没有读取到文件的内容，猜测可能是没有找到文件。 以前在 import 自定义模块的时候遇到过类似的问题，当时的解决方法是把当前工作路径设置为正在执行的文件所在的路径。 解决方案 使用绝对路径 将当前工作路径改为当前文件路径，再使用相对路径 第二种方法的代码如下： 12345678910from configparser import ConfigParserimport osif __name__ == '__main__': curpath=os.path.dirname(os.path.realpath(__file__)) filename=os.path.join(curpath,&quot;test.ini&quot;) config=ConfigParser()#创建配置对象 config.read(filename)#读取配置文件 result=config.get(section='test',option='name')#读取test下的name print(result)","link":"/posts/python_read_ini_No_section/"},{"title":"学校信息门户模拟登录之密码加密","text":"以前写的爬虫无法登录到学校的信息门户上去了，因为门户的新 JS 代码将表单的密码先加密了一次，再将其与别的表单数据 POST 过去。使用的是 AES 加密的 CBC 模式。 本文前半部分是我的 python 组长雁横给组员们讲解的信息门户的密码加密思路，然后由我总结成文，后半部分是我自己写的加密代码实现，使用 python 的PyCryptodome库来进行加密。 参考链接 浏览器开发者工具基本使用教程-博客园 Python 运行 js 代码 python 加密与解密（大致介绍了加密解密算法）-博客园 常见加密方式与 python 实现-简书 PyCryptodome 库的官方文档 python encode 方法-菜鸟教程 本文代码的 github 链接 问题描述登录之后查看原本提交表单的部分可以发现，密码由明文传输改成密文传输了。于是原本只需要 POST 账号和密码的明文就行，现在需要多经过一步——加密。 起码咱们学校还是有考虑安全问题嘛！OVO 分析加密过程因为登录到主页的时候已经是加密好的密码，所以加密工作应该是在登录页面就进行的。 所以回到登录页面刷新一下，筛选 javascript 文件（因为 js 文件是用于动作的） 在这几个 js 文件中找找有没有线索，然后在其中一个 js 文件中找到了一个密码加密函数。 encryptPassword()传入密码，返回加密后的密码。 12345678function encryptPassword(pwd0) { try { var pwd1 = encryptAES(pwd0, pwdDefaultEncryptSalt); $(&quot;#casLoginForm&quot;).find(&quot;#passwordEncrypt&quot;).val(pwd1); } catch (e) { $(&quot;#casLoginForm&quot;).find(&quot;#passwordEncrypt&quot;).val(pwd0); }} 核心逻辑就一句。 1var pwd1 = encryptAES(pwd0, pwdDefaultEncryptSalt); encryptPassword()调用了一个名为encryptAES()的函数，参数pwd0可能是未加密的密码，pwdDefaultEncryptSalt可能是加密用的密钥。try-catch 不用说了，就是错误处理。 encrypt 是加密的意思，而 AES 是一种加密的方式。 而刚刚的 js 文件里面有一个文件就带着 encrypt 这个单词，点进去看，找到了下一个函数： encryptAES()传入密码明文和 AES 密钥，返回密文。 123456789101112function encryptAES(data, aesKey) { //加密 if (!aesKey) { return data; } var encrypted = getAesString( randomString(64) + data, aesKey, randomString(16) ); //密文 return encrypted;} 代码逻辑： 如果没有给出密钥，那么就不加密直接返回明文； 如果给出了密钥，那么就调用getAesString()函数来获取密文 返回密文 其中randomString()函数代码如下： 123456789var $aes_chars = &quot;ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678&quot;;var aes_chars_len = $aes_chars.length;function randomString(len) { var retStr = &quot;&quot;; for (i = 0; i &lt; len; i++) { retStr += $aes_chars.charAt(Math.floor(Math.random() * aes_chars_len)); } return retStr;} 从上图可以看到，getAesString()就在这个函数上方。 getAesString()传入明文、密钥、偏移量，返回密文。 12345678910111213//AES-128-CBC加密模式，key需要为16位，key和iv可以一样function getAesString(data, key0, iv0) { //加密 key0 = key0.replace(/(^\\s+)|(\\s+$)/g, &quot;&quot;); //去除开头和结尾的空白 var key = CryptoJS.enc.Utf8.parse(key0); var iv = CryptoJS.enc.Utf8.parse(iv0); var encrypted = CryptoJS.AES.encrypt(data, key, { iv: iv, mode: CryptoJS.mode.CBC, padding: CryptoJS.pad.Pkcs7, }); return encrypted.toString(); //返回的是base64格式的密文} 在这个函数中调用了 aes 加密算法的函数来加密 密钥还差密钥pwdDefaultEncryptSalt，去 js 文件里面搜索： 图中可以看到，密钥的来源是pwdEncryptArr[1]变量，但是在 js 文件里面却找不到这个从哪里来的了。 不过去搜索登录页面源代码的时候发现它就写在页面里面。 得到了密钥： 1var pwdDefaultEncryptSalt = &quot;QgkxfHXdbwRHcvDI&quot;; 后来发现，这个密钥同样每次都会变化，可以在获取表单变化的隐藏域值的时候顺便获取了。 总结信息门户加密算法是：AES-128-CBC 加密模式，key 需要为 16 位，key 和 iv 可以一样（从注释里面得到的） 密文 data 是长度为 64 的随机字符串与登录密码连接。 密钥 key 就放在登录页面源码内，每次都会变化，需要动态获取。 偏移量 iv 是长度为 16 的随机字符串。 现在知道了它的加密算法以及密钥，我们在模拟登录的时候把我们的密码用同样的方式加密，向以前那样发送就可以登录了。 有两种解决方案： 直接在 python 里面运行复制来的 js 代码。参考：Python 运行 js 代码 使用 python 进行加密 加密 python 代码实现AES 简介AES（Advanced Encryption Standard）（高级加密标准），用于代替原本的 DES（Data Encryption Standard） 2006 年，高级加密标准已然成为对称密钥加密中最流行的算法之一。——搜狗百科 AES 算法将明文分为长度相等的若干组，每次加密一组数据。 分组长度固定为 128 位（16 字节），密钥长度则可以是 128，192 或 256 比特（16、24 和 32 字节）。 我遇到的加密问题需要的是 128 位的密钥。 PyCryptodome 库这个库是 PyCrypto 库（已经停止更新）的延续。 PyCryptodome 库的官方文档 安装方式（windows）： 1pip install pycryptodomex 导入方式： 1import Cryptodome 获取密钥在页面源码里面密钥的格式是： 1var pwdDefaultEncryptSalt = &quot;QgkxfHXdbwRHcvDI&quot;; 使用正则表达式来解析： 12345678910def get_encrypt_salt(login_url): ''' 获取密钥 :param login_url:登录页面的url :return: (密钥,密钥对应的cookies) ''' response=requests.get(login_url) pattern = re.compile('var\\s*?pwdDefaultEncryptSalt\\s*?=\\s*?&quot;(.*?)&quot;') pwdDefaultEncryptSalt = pattern.findall(response.text)[0] return (pwdDefaultEncryptSalt,response.cookies) 获取初始化向量iv 是初始化向量，也称作偏移量。 在上面的分析中，传给加密函数的 iv 是一个随机字符串： 1var encrypted = getAesString(randomString(64) + data, aesKey, randomString(16)); //密文 现在用 python 来实现这个randomString() randomString()的 python 实现12345678910def random_string(length): ''' 获取随机字符串 :param length:随机字符串长度 ''' ret_string='' aes_chars = 'ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678' for i in range(length): ret_string+=random.choice(aes_chars) return ret_string 那一串用于随机的字符串是我从 js 文件的注释里面复制下来的，这个串并没有覆盖全部的字母和数字，为了防止意外，直接使用它的。 getAesString()的 python 实现12345678910111213141516171819202122232425from Cryptodome.Cipher import AESfrom Cryptodome.Util.Padding import pad#用于对齐import base64def get_aes_string(data,key,iv): ''' 用AES-CBC方式加密字符串 :param data: 需要加密的字符串 :param key: 密钥 :param iv: 偏移量 :return: base64格式的加密字符串 ''' #预处理字符串 data=str.encode(data) data=pad(data, AES.block_size)#将明文对齐 #预处理密钥和偏移量 key=str.encode(key) iv=str.encode(iv) cipher = AES.new(key, AES.MODE_CBC, iv)#初始化加密器 cipher_text=cipher.encrypt(data)#加密 #返回的是base64格式的密文 cipher_b64=str(base64.b64encode(cipher_text), encoding='utf-8') return cipher_b64 对齐首先，先将明文对齐，因为 AES 加密是分组加密，所以明文的长度需要是组长度的倍数。 有两种方式 Cryptodome.Util.Padding中的 pad 函数就可以实现对齐，就是我采用的办法。 组长雁横的代码是这样实现对齐的： 1234def add_to_16(value): while len(value) % 16 != 0: value += '\\0' return str.encode(value) # 返回bytes 预处理js 代码里面在加密之前，对数据做了编码处理： 12var key = CryptoJS.enc.Utf8.parse(key0);var iv = CryptoJS.enc.Utf8.parse(iv0); 因此也顺便处理一下。 python encode 方法 描述Python encode() 方法以 encoding 指定的编码格式编码字符串。errors 参数可以指定不同的错误处理方案。 语法encode()方法语法： 1str.encode(encoding='UTF-8',errors='strict') encryptAES()的 python 实现1234567891011121314def encrypt_aes(data,key=None): ''' 进行AES加密 :param data: 需要加密的字符串 :param key: 密钥 :return: 如果key存在，则返回密文，否则返回明文 ''' if(not key): return data else: data=random_string(64)+data iv=random_string(16)#偏移量 encrypted =get_aes_string(data,key,iv) return encrypted encryptPassword()的 python 实现1234567891011def encrypt_password(password,login_url): ''' 加密密码 :param password: 需要加密的密码 :param login_url:登录页面的url :return: (加密后的密码,对应的cookies) ''' key,cookies=get_encrypt_salt(login_url) password.strip()#去除头尾空格 encrypted=encrypt_aes(password,key) return (encrypted,cookies) 这就完成了 测试代码123456if __name__ == '__main__': login_url='http://ids.chd.edu.cn/authserver/login?service=http%3A%2F%2Fportal.chd.edu.cn%2F' password=input('password:') password,cookies=encrypt_password(password,login_url) print('encrypted password:',password) 有效性检验可以使用浏览器开发者工具的控制台，调用 js 函数，传入同样的参数，看是否得到相同的结果。 测试结果如图：","link":"/posts/3903089268/"},{"title":"学校信息门户模拟登录","text":"将登陆学校信息门户的部分专门封装成一个模块，需要的时候导入。 相关链接本文代码的 github 链接 获取登录所需表单数据 从图中看到的，和在登录页面源代码中查找的，需要的表单数据如下： username：用户名，也就是信息门户账号 password：是经过加密之后的密码 lt：是一个每次请求都会变化的表单隐藏域值 dllt：固定表单隐藏域值 execution：固定表单隐藏域值 _eventId：固定表单隐藏域值 rmShown：固定表单隐藏域值 除了需要表单数据之外，还需要在登录页面源代码中获取密钥，详情见：学校信息门户模拟登录之密码加密 使用BeautifulSoup来获取这些数据。 123456789101112131415161718192021222324252627282930313233343536373839404142from portal_login.encrypt import *import requestsfrom bs4 import BeautifulSoupdef get_login_data(login_url,headers): ''' 长安大学登录表单数据解析 :param login_url: 登录页面的url :return (登录信息字典,获取时得到的cookies) ''' username=input('input username:') password=input('input password:') username.strip() password.strip()#去除头尾空格 #获取登录所需表单数据 response=requests.get(login_url,headers=headers) html=response.text soup=BeautifulSoup(html,'lxml') #获取密钥来加密密码 pattern = re.compile('var\\s*?pwdDefaultEncryptSalt\\s*?=\\s*?&quot;(.*?)&quot;') key = pattern.findall(html)[0] password=encrypt_aes(password,key) lt=soup.find('input',{'name':'lt'})['value'] dllt=soup.find('input',{'name':'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data={ 'username': username, 'password': password, 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } return (login_data,response.cookies) 要注意的是，获取完数据之后，需要将 response 的 cookies 留下来，因为不同 cookies 对应的登录数据也不一样（比如说每次打开页面都不一样的密钥和 lt） 登录登录过程分析在登录页面输入账号密码，F12 打开开发者工具，Network勾选Preserve log，点击登录，然后就会出现下图场景： 找到从登陆页面出去的第一个响应，可以发现这个响应的状态码是 302，代表“重定向”。在Response Headers里面可以找到Location这个键，它指示的是重定向的地址。 这个响应的含义大概是“服务器告诉浏览器带着给它的 cookies 去访问Location指示的 url” 在刷出来的一大堆响应中继续寻找，找到下一个地址： 从图中可以看到，目的地址已经是门户的主页 url 了，继续跳转： 随便打开一个登陆才能查看的页面，查看它的 cookie，发现浏览器带着这几个 cookies 来访问这个页面，也就是说，我们需要获取到这几个 cookies，才能登录成功： 处理跳转默认情况下，requests 的post()方法是得到跳转后最终页面的响应，也就是说，登录成功就返回门户主页的响应，登录失败就返回跳转之后回到的登录页面的响应。 需要设置一个参数，来阻止它进行跳转： 1response=requests.post(login_url,headers=headers,data=data,cookies=cookies,allow_redirects=False) 也就是： 1allow_redirects=False 不允许跳转，第一次请求得到什么响应就返回什么响应。 每一次跳转，我们需要做的工作如下： 将现有的 cookies 与新获取的 cookies 合并 找到下一个重定向地址，带上 cookies，再一次请求 实现代码如下： 123456789response=requests.post(login_url,headers=headers,data=data,cookies=cookies,allow_redirects=False)while response.status_code == 302:#如果响应状态是“重定向” #合并新获取到的cookies cookies=join_cookies(cookies,response.cookies) #获取下一个需要跳转的url next_station=response.headers['Location'] response=requests.post(next_station,headers=headers,cookies=cookies,allow_redirects=False)cookies=join_cookies(cookies,response.cookies) 其中join_cookies()的实现如下： 1234567def join_cookies(cookies1,cookies2): ''' 将cookies1和cookies2合并 ''' cookies=dict(cookies1,**cookies2) cookies=requests.utils.cookiejar_from_dict(cookies) return cookies 登录函数总览123456789101112131415161718192021222324252627def login(login_url,headers,check_url=None): ''' 登录到CHD信息门户 :param login_url: 登录页面的url :param headers: 使用的headers :param check_url: 用于检查的url，尝试请求此页面并核对是否能请求到 :return: 已登录的cookies ''' data,cookies=get_login_data(login_url,headers)#获取登录数据 response=requests.post(login_url,headers=headers,data=data,cookies=cookies,allow_redirects=False) while response.status_code == 302:#如果响应状态是“重定向” #合并新获取到的cookies cookies=join_cookies(cookies,response.cookies) #获取下一个需要跳转的url next_station=response.headers['Location'] response=requests.post(next_station,headers=headers,cookies=cookies,allow_redirects=False) cookies=join_cookies(cookies,response.cookies) #登录检查 if check_url != None: response = requests.get(check_url,headers=headers,cookies=cookies) if response.url==check_url: print(&quot;登录成功&quot;) else: print(&quot;登录失败&quot;) return cookies","link":"/posts/portal_login/"},{"title":"简易密码生成器","text":"为了管理自己平时各种各样的账号密码，我使用了一个加密了的 xlsx 文件来记录，同时使用了密码生成规则。为了方便生成密码，使用 python 写了一个小工具。 由于代码比较简单，因此不做过多说明，仅做记录。 密码生成规则对于一些比较重要的账号，比如 QQ，密码采用随机字符串，再记住，这样的字符串是没有规律的。 对于一些不太重要的账号，就使用对应的网站变量进行偏移。 代码导入模块12import randomimport clipboard 生成随机密码1234567891011def generate_random(length, alphabeta=None): ''' 生成指定长度的随机密码 ''' length = int(length) if alphabeta == None: alphabeta = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' # 字母表 password = '' for i in range(0, length): password += random.choice(alphabeta) return password 生成偏移密码12345678910111213def generate_offset(raw_password, offset, alphabeta=None): ''' 将原始密码进行偏移 ''' offset = int(offset) if alphabeta == None: alphabeta = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' # 字母表 password = '' for character in raw_password: index = alphabeta.index(character) # 获取原本的索引 new_index = (index+offset) % len(alphabeta) # 获取偏移后的索引 password += alphabeta[new_index] return password 主函数1234567891011121314151617181920212223242526if __name__ == '__main__': print('q退出') print('random 生成随机密码') print('offset 生成偏移密码') cmd = input('&gt;') while cmd != 'q' and cmd != 'Q': password = '' if cmd == 'random': length = input('请输入密码长度：') password = generate_random(length) clipboard.copy(password) print('密码已复制到剪切板:\\n',password) elif cmd == 'offset': raw_password = input('请输入原始密码：') offset = input('请输入偏移量：') password = generate_offset(raw_password, offset) clipboard.copy(password) print('密码已复制到剪切板:\\n',password) else: print('请输入正确的指令') print('q退出') print('random 生成随机密码') print('offset 生成偏移密码') cmd = input('&gt;')","link":"/posts/simple_password_generater/"},{"title":"爬取微信公众号文章1获取文章链接","text":"爬取微信公众号的文章，之前一直觉得应该很难，我搞不定，但是尝试了一下发现，其实这和之前爬取的网站没有太大的区别。 本文记录了 2019 年 8 月 7 日爬取某一特定微信公众号的所有文章链接的方式，读者请注意时效性。 前言 需要一个可登录的微信公众号。本文采用的方法是使用微信公众号内部的搜索来搜索文章。 由于登录部分很复杂，我还没搞懂，本文直接手动获取 cookies 来登录。 参考链接记一次微信公众号爬虫的经历-CSDN 如何手动获取在登录后的微信公众平台的【素材管理】页面，点击【新建图文素材】，在新出现的编辑页面内，找到用于插入别的文章引用的，【超链接】图标。接着就会出现下图的窗口，输入需要获取的公众号查找即可。 分析打开 F12 开发者工具，搜索到公众号之后，查看 Ajax 请求 换页的时候会再次发出 Ajax 请求，多换几页，查看它们的参数的规律。 通过观察，知道了接口是： 1https://mp.weixin.qq.com/cgi-bin/appmsg 在访问这个接口时，需要在后面带上参数： 12345678910111213data = { 'token':'271444813', #在同一次登录不变，在首页源代码里面可以获取 'lang':'zh_CN', # 不变 'f':'json',# 不变 'ajax':'1',# 不变 'random': str(random.random()),# 随机数 'action':'list_ex',# 不变 'begin':'0',# 代表页数，每翻一页就会+5，但是每一页的文章数不一定为5篇 'count':'5', # 应该是每一次获取的文章篇数 'query':'',# 不变 'fakeid':'MzAwNjA3Nzg0MA==',# 文章所在的公众号的id 'type':'9',# 不变} 获取步骤 登录微信公众平台 手动在开发者工具中获取 cookies 字符串 带好参数访问 Ajax 接口，获取到所需要的 json 数据 示例代码12345678910111213141516171819202122232425262728293031323334353637383940414243import requestsimport randomdef cookiejar_from_str(cookies_str): ''' 将cookies字符串转换为cookiejar ''' cookies=dict([item.split('=',1) for item in cookies_str.split(';')]) print(cookies) cookies=requests.utils.cookiejar_from_dict(cookies) return cookiesif __name__ == '__main__': # cookies字符串 cookies_str='''openid2ticket_okSCe0vbk_v5067L-AuViT1wrkEg=ARU37unMfUwam3yNHXFcw5CMFvTHMvmBnjjS8A8= '''.strip() # 这里我手动截去了大部分cookies字符串，明白意思即可 # headers headers={ 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.25 Safari/537.36 Core/1.70.3722.400 QQBrowser/10.5.3738.400' } cookies = cookiejar_from_str(cookies_str) data = { 'token':'271444813', #在同一次登录不变，在首页源代码里面可以获取 'lang':'zh_CN', # 不变 'f':'json',# 不变 'ajax':'1',# 不变 'random': str(random.random()),# 随机数 'action':'list_ex',# 不变 'begin':'0',# 代表页数，每翻一页就会+5，但是每一页的文章数不一定为5篇 'count':'5', # 应该是每一次获取的文章篇数 'query':'',# 不变 'fakeid':'MzAwNjA3Nzg0MA==',# 文章所在的公众号的id 'type':'9',# 不变 } url='https://mp.weixin.qq.com/cgi-bin/appmsg' response_json = requests.get(url, cookies=cookies,headers=headers, params=data).json() for item in response_json[&quot;app_msg_list&quot;]: # 获取url print(item['link'])","link":"/posts/wechat_offical_account_spider_1_get_article_urls/"},{"title":"2019年年中总结","text":"要一个人在家一周，有些孤独，有些茫然，想起来写总结。 不太清楚总结怎么写，就和以前一样，把过去的东西列出来看看吧，帮助自己回顾一番。 这是 2019 上半年的总结，也是大二第二学期的学期总结。 过去做了什么事情翻了一下 qq 空间动态以及别的一些痕迹，大概了解了一下我自己在 2019 年上半年干了些什么事情。 输出平台上半年我主要在三个平台上输出一些东西： 个人博客 bilibili github 个人博客2019 年 2 月 6 日，我在 github 上部署了我的个人博客，并记录下了过程（不算教程啦，更像是日记） 到今天（2019 年 8 月 10 日）为止，已经有 29 篇博文了。标签中占的比例比较大的是“python”和“spider”，2 月份之后除了 5 月没有 python 文之外，其他月份都有至少 2 篇的博文关于 python，因为觉得 python 写起来很舒服，比起 c++和 java 的严格语法，python 更容易写出东西来。自从 2 月份的寒假开始学习 python 爬虫之后，就时不时地更新相关的博文。 有了个人博客之后，我就彻底抛弃了原本的微信公众号。 在个人博客里面写东西有一种更加快乐的感觉。一步一步了解 Hexo 博客搭建的原理，一步一步改进博客功能，添加右下角的 live2D 人物，安装图片插件，添加基于 leancloud 的评论和阅读次数统计……这些让我有种掌控感。 Hexo 日记本搭建了 Hexo 个人博客之后，又新建了一个博客作为日记本，把以前写的电子版日记存在里面，不部署到服务器，只留存在我电脑上，主要是想利用它好看的渲染效果和各种插件来丰富日记本。 github下图是我目前的 github 资料页： 从 contributions 日历可以看到，2018 年还只是零星的几个 commits，2019 年的 commits 就增加了好多。 主要有两个原因。 第一个原因，是我部署了个人博客之后，写博客以及频繁调试博客提供了 commits 数。不过这只是次要原因。 第二个原因，是我真正开始把 git 当成生产工具了，这才是主要原因。 我大概是在 2018 年 4 月 15 日创建了 github 账号，2018 年下半年的时间并没有去管 github 账号，因为那时候还不知道怎么用 github，觉得得把 git 命令行给用熟了才能去玩这个网站。但是这就形成了一个不算太高但是我不想跨的门槛，而且我觉得平时我也用不到这么高级的东西，于是就没去学了。 一次偶然的机会，我看到了社团里面一个大佬——封掣是如何使用 github-desktop（github 官方的 GUI 桌面软件）来管理自己的代码，终于明白，管它那么多高大上的命令干什么，一个工具，能够解决人的问题就行。于是我开始用起有 GUI 的 git 软件了（现在用的就是 github-desktop），把它当成存档软件，写课设的时候，写完一个功能就存一个档，写错了就回档。 bilibili从创作中心的日历来看，今天是我成为 up 主的 464 天。2018 年 5 月 4 日，我投稿了第一个视频。 到今天，已经陆陆续续投稿了 26 个视频。主要的主题是分享代码思路。 然而总是有人只要代码不要思路，这让我很是苦恼，详情可以看这个 现在前往代码分享群的通道基本已经关闭，只有少数几个视频下面的群号我没有删除，避免伸手党直接进来。一到期末，需要课程设计的时候，我的视频播放量就会增加，我算是明白怎么回事了。 想要解决“代码分享和代码抄袭的矛盾”，我有一个初步的想法，就是在视频里面先介绍思路，声明视频主要分享思路，不提供源代码，如果是伸手党，估计就直接走了找别的代码，同时也能够让真正想学的人学到思路。 不过还有一个问题，我做的视频的主题注定我每个视频的观众很少有重叠。我并不像教程 up 主一样，针对某个固定主题来出视频，而是更加注重于巩固自己学到的知识，分享只是顺带的。这也不是太大的问题。 组织团队网络安全协会虽然加了这个社团，但是感觉自己很难进入网络安全这个领域。 易班工作站大概 2019 年 3 月的时候，偶然看到易班工作站的群里面发了一个通知，说是辅导员有个技术讲座。当时我只是一个普普通通的社团成员，想去就去，那时候正好没什么事情，就去了。没想到会对我影响这么大。 我当时只是过去凑个热闹，没想到这是工作站的技术组的又一次纳新。 以前的技术组纳新我也有去，那时候是大一，啥也不懂，连 html 都不会，然后就让我们自学来制作一个留言板。 自学诶！ 刚开始自学 html 的时候，感觉这个难度我能 hold 住，没问题，可以进去！ 但是学到后面我连需要用什么东西，需要学什么都不知道，很长一段时间没有进展，想放弃了。可能是因为很多同学也是如此，辅导员无奈之下，给大家简单演示了一下怎么用 easyPHP 来写，然后又放着我们去自学。 其实有问题确实可以问他，但是我对和辅导员打交道这件事情有些畏惧。一个自闭的人。 然后越学越自闭，最后放弃。 和我一起参加纳新的老朱则坚持了下来，加入了技术组。挺羡慕的，也明白自己不够强大，不够努力。 这次我是大二，在课堂上和课外学了更多的东西，以前没写成功的留言板也写了一下，以及一个注册登录系统，录了个视频发 b 站（传送门）。 成功完成写一个爬虫的挑战，也因此入了 python 的坑。 打卡学习群2019 年 4 月 26 日，一时心血来潮，建了一个学习群。 我给这个群制定了一些规则，比如：每月最多邀请一人进群，每周做个周总结，可以申请群相册来打卡等。 现在过去差不多四个月了，从刚开始的三个人到现在的五个人。还是有按照我的预期来发展的。 我认为能顺利发展的主要因素是邀请制进群，人多了就不好管了，人少就容易遵守规则。 运动在 2018 年 6 月 30 日，也就是大一的暑假快要开始的时候，我在 QQ 空间建了一个打卡相册，名字叫做《到 6 月 30 日要有 300 张》，一年 365 天，运动 300 天。 到 2019 年 6 月 30 日结算时，共有 218 张截图打卡，虽然没有达成目标，但是进度也差不多三分之二，比较满意。 开学之后打算开始新的打卡。 现状兴趣爱好小说在我建的打卡学习群里，有人建了一个写小说的打卡相册，这让我又开始想要写小说了。 我曾经写过网络小说，在起点中文网上面发过，但是写的很烂，挤出二十几章就没了。 不过他把我的兴趣又勾起来了。不要像以前那样，一打算写就把全部的精力都耗费在上面，而是合理分配时间精力 板绘2019 年 7 月 29 日，我网购的数位板到了。这是我第一块数位板。 上一次想要买数位板时，我对自己说，得把手绘的习惯稳定下来之后才准买，不能买了不用。 我以前有一定的手绘基础，一般是临摹，偶尔会画几幅原创的画（比较丑啦）。很久没画，没时间，也没有那份兴趣。 打卡群里面唯一的妹子会板绘，有一次在上课之前我坐她旁边看到她在用数位板画画，是个大触。她在群里也新建了一个打卡相册，是一个画画相册。 这一次是快要过 20 岁生日了，我想买一个自己真正喜欢的生日礼物。犹豫了很久，终于下定决心买了。在知乎上查推荐品牌型号，在 b 站上看推荐视频，买到了一块两百多的数位板。 买完之后我还是很担心自己会不会把它扔在一边吃灰，安慰自己说老弟的高达和假面骑士模型比我这个贵多了，我买个这个来玩没啥的。 没想到板绘真的挺好玩的，到货当天我就临摹了一个 menhera 酱表情图，录了一个视频发在 b 站，挺有成就感的。 今天（2019 年 8 月 11 日）晚上还打算试试直播临摹，昨天探过绘画直播间了，也是有人看这种的。 人际交往这个暑假在驾校学科目二，多了很多和别人交流的机会，和陌生人聊天也没有那么困难了。 健康状况健康状况不容乐观。 现在喝任何一种饮料都和喝咖啡一样兴奋，抵抗力越来越差，肚子也越来越胖了，成为了一个肥宅。 所适应的刺激水平越来越高，控制不住自己玩手机，玩电脑（主要是看 b 站）。","link":"/posts/2019_semi-annual_summary/"},{"title":"爬取微信公众号文章2获取页面失败","text":"虽然获取到了微信公众号文章的链接，但没法获取到包含文章内容的 html。 花了一个小时来研究怎么获取页面，最后还是失败了。 requests首先按照一般思路，使用 requests 库来获取页面，但是获取到的却是不含有文章内容的一堆 js 代码和 css 代码，以及少量的没有内容的 html。 去查看 Ajax 请求，有 4 个请求，其中三个都是没有文章内容的 json，而第一个请求也是最可疑的一个，无法预览。 第一个请求的接口： 1https://mp.weixin.qq.com/mp/appmsgreport?action=page_time&amp;__biz=MzAwNjA3Nzg0MA==&amp;uin=&amp;key=&amp;pass_ticket=&amp;wxtoken=777&amp;devicetype=&amp;clientversion=&amp;appmsg_token=&amp;x5=0&amp;f=json 这是以 POST 方式访问的接口，下面一大堆的 Form data，这其中甚至还有文章的标题！ 也就是说在访问这个接口之前，就已经得知了文章的内容了吗？ selenium我觉得模拟请求太过于复杂，于是尝试使用 selenium 来获取。 但是得到的内容和上文说的一样，并没有什么不同。非常奇怪。加了 60 秒的延时让它充分渲染也没用，问题不在这里。 教训后来输出到文件才发现，内容并没有少，确确实实地获取到了文章内容，但是由于 print 出来的字符数有限制，无法在控制台显示完，才导致我以为获取失败。当个教训吧。","link":"/posts/wechat_offical_account_spider_2_fail_to_get_html/"},{"title":"一封邀请函","text":"如果你是从外部链接来到这个页面，那么你也许是获得了进入一个自我管理群的邀请函。 你可以阅读下面的介绍，以确定要不要加入这个群。 建议在电脑上查看，有侧边栏目录方便跳转。 无论是否选择加入此群，都请不要将此链接随意传播。 群简介这是一个 QQ 群，于 2019 年 4 月 26 日创建。 是为了营造一个良好的学习氛围，提供一个外在监督环境建立的。 在建立之初，我并没有想好这是一个什么样的群，只是想聚集一些小伙伴一起学习。后来，这个群慢慢地发展起来，变成了一个有着打卡系统和反思系统的群。 打卡系统：本群的打卡系统利用了 QQ 群的群相册。如果你有想要打卡的项目，可以在登记了信息之后创建群相册用于打卡，由管理员以及全体群成员监督，超过一定天数未打卡，就会删除对应的相册，并扣除一定的积分。而达到一定天数可以将相册归档，获得与持续天数正相关的积分。 反思系统：作为本群成员，需要每周周日总结一下本周的收获，并以文字的形式发到群内。如果没有收获，也需要在群里说明（例如说：“本周无总结”）。没有声明本周没有总结且未总结的，扣除一定的积分，在下一周周日结算之前补回，则取消扣分。正常总结会获得一定量的积分。 积分系统：进群之后初始积分为 0，若积分为负数且在下一周周日结算之前仍然为负数，则会强制离开群聊。 邀请系统：本群采用邀请制，每个月最多邀请一个愿意遵守群规则的人入群。如果没有这样的人选，这个月就不邀请，宁缺毋滥。 文件系统：为了方便学习交流，如果需要上传文件，请将文件上传到对应的文件夹，并使得看文件名就知道这个文件的作用，多版本文件请用 6 位数日期+修改次数的后缀 群活动：群内会不定期地进行一些活动，自愿参与。 简单来说，想要留在这个群里面，最简单的方式是只需要在每周日发一条“本周无总结”，维持积分不为负。 而在这个基础上，你可以选择群里面提供的规则来进行自我提升、自我管理，也可以向管理员提出自己的规则提案、活动提案。 本群提供的是一种氛围，一种监督环境，至于能否从中获得提升，还需要看你自己。 详细内容见下： 打卡系统由一个.xlsx 文件（即电子表格文件）来实现。下图为示意图，点击可放大。 创建打卡相册创建打卡相册需要以下步骤： 在群文件内下载“打卡相册登记表 xxxxxx-x.xlsx”文件 在其中根据工作表“打卡相册字段描述”内的说明，在工作表“打卡相册登记表”内填写好对应的信息 将文件名修改为“打卡相册登记表+6 位数日期+任意分隔符+这一天第几次修改”，如：“打卡相册登记表 190617_1“代表 2019 年 6 月 17 日的第一次修改。并将文件上传 在群相册创建自己的打卡相册，开始打卡 打卡相册规则下面只列出比较重要的几个规则，具体的积分计算规则见这里 相册状态：正在进行、放弃、失败、归档 如果连续三天未打卡，管理员就删除相册，并在登记表内将相册状态设置为“失败”。 不创建打卡不扣分，创建打卡而未坚持下来会扣分。没有请假制度，创建打卡前请考虑好 对于有期限的相册，比如打卡目标是“两周读完《xxx》”，那么在结束日期时，可以将其状态设置为“归档”。相册资源回收（删除或改作他用），避免资源闲置。若持续时间大于等于一百天，则可以选择保留相册。（可以给其他群员作榜样） 对于没有期限的相册，比如“每天背单词”，那么在创建时间满三十天后就可以选择“归档”（三十天应该够养成一个小习惯了），删除规则同上一条。 相册删除后，相册记录还会保留在登记表里面，是公开的哦。 反思系统其登记表与打卡相册登记表使用同一个工作簿。 作用 在群文件内复习自己学习内容 看到别人学习了自己却没有而产生激励效果。 保持群内一定的活跃度，去除不活跃成员 作为群内一个基本的群活动，强化学习氛围 规则 每周日，每个人在群聊天发一个周总结，内容是自己这周学习了什么，没有限制，只是给大家一个自我反省的机会。 如果没有可以写的东西，那么也在群里面报备，方式为在群聊天中说：“本周无总结”或者别的能表明这一事实的话。别有压力，只是回复一句话的功夫。 无论总结多少，只要总结了，都会获得一定量的积分。 如果周日那一天状态不好或者很忙，可以在群里@管理员，告知推迟时间（不可超过下周周日），只要在报备的时间之前补了总结，也可以获得总结积分。 如果没有报备也没有在截止之前发周总结，可以在下一周总结之前补。如果没有补，则会扣除一定的积分。 每周所有成员的周总结将会被管理员整理到一个文件中，发到群内，即周总结是公开的，方便你随时查看自己的周总结以及自己下周的目标。 尽量使用 markdown 语法，方便管理员整理。如果你不了解什么是 markdown，那么就只需要在你的总结前面加上一行“## 你的昵称”即可。如果你想要学习 markdown，可以参考我在 b 站发的这个视频。本篇文章就是使用 markdown 语法来书写的。 总结示例内容没有限制，想写什么都可以，不限字数，但是最起码的格式是，在总结前面加上“## 你的昵称” 以下内容仅供参考，可以根据自己的喜好来增加或删除模块。 简易总结示例123## 憧憬少本周没做什么事情 详细总结示例摘自“周总结 week5”，使用了 markdown 语法，可以在群文件的“周报”文件夹中找到它，看一下 markdown 的渲染效果。 123456789101112131415161718192021222324252627282930## 憧憬少### 本周做了什么- 驾校练完了右侧倒车入库，开始学习左侧- （周一）完成信息门户密码加密模块并上传 github 和[编写博客](https://yxchangingself.xyz/posts/portal_login_encrypt/#more)- （周三）完成信息门户模拟登录模块并上传[github](https://github.com/HaneChiri/CHD_portal_login)和[编写博客](https://yxchangingself.xyz/posts/portal_login/#more)- 驾校排队练车的时候无聊，开始使用墨者写作 APP 来重新开始以前放弃的小说并在群里连载- （周六）写了一个 python 脚本用于自动启动明日方舟的代理指挥，学习了`pyautogui`库。- （周日）发布上述脚本的[介绍视频](https://www.bilibili.com/video/av60038926/)以及上传脚本和打包的 exe 到[github](https://github.com/HaneChiri/arknights_assist)### 本周的目标有没有达到【目标链编号，每完成一个目标，生成下一个目标，编号增加，未完成则归零】- [x] 【1】一周四次运动- [x] 【0】一周三次，每天写代码半小时### 下周的目标- [ ] 【2】一周四次运动，包括不限于跑步，散步等- [ ] 【1】一周三次，每天写代码半小时- [ ] 【0】每天利用 time meter 记录时间开销### 概括这一周分数：85%- 在驾校遇到了同一个高中的同学（虽然不是一个班不认识）- 做了挺多事情 群活动可以在群内向管理员提出群活动的建议。 目前已经举行过的群活动： #1 学期总结【活动】学期总结【编号】#1（也就是第一次活动）【时间】2019-6-21~2019-7-10【内容】本学期已经告一段落，学科的内容是否考完试就忘得差不多了呢？为了避免这一学期白学，各位学研都市居民可以在活动时间内在群文件的群活动作品提交文件夹内提交自己的学期总结。形式不限，可以是手写总结拍照，可以是知识框架思维导图，可以是笔记文件，可以是录音讲解等。【存档】活动结束之后，会将群文件中提交的总结统一打包，保存到群活动文件夹中，群活动提交文件夹会被清空。【排名】活动结束之后，会进行作品投票，票数最多的参与者可以获得奖励【奖励】目前我能想到的奖励就只有 30 天自定义专属头衔了","link":"/posts/invitation/"},{"title":"2019年暑假总结","text":"这个暑假大致是 7 月 7 日（到家时间）至 8 月 24 日，已经过了 6 周左右。 如果是以前的假期，肯定是不记得自己做过什么了，但是这次每周做了一次周总结，因此可以对照着周总结来进行假期总结。应该是头一次有参考地记录下自己的整个假期了。 做了什么事情科目二最主要做的事情是考驾照的科目二，每天都去练一个上午或者一个下午。 认识了几个同一个高中的同学，并且和陌生人打交道没有那么困难了。 bilibili代码分享群里面有个人问我要不要参与 b 站的暑假爆肝活动，在 7 月 28 日之前投稿 4 个视频。我想要奖励里面的一个月大会员，于是就参加了。 7 月 13 日投了一个:“如何像项目一样整理和管理你的个人电脑文件”，分享了一下我自己不久前开始使用的整理电脑文件的方式，而且特地利用“网易见外”这个网站来试着加上字幕。比起分享代码思路，这种视频受众更加广一些。 通过自动上字幕，我发现自己讲解的时候语气词和停顿还蛮多的，需要多锻炼表达能力。 学习 python，利用 python 写了一个脚本，用来自动帮我的明日方舟的关卡点“开始游戏”按钮，灵感来自一个用机械装置做“物理外挂”的视频。录制了一个演示视频：“明日方舟代理指挥“代理指挥”的代理指挥” 后来没什么想做的视频主题，就没有继续做了。 到了八月，买了一个板绘用的数位板，开始学习板绘作为平时的兴趣。八月录制了三个临摹过程的视频，感觉不错。 个人博客 &amp; githubpython 爬虫使我开始更加积极地更新博客的事件是，我终于在 7 月 15 日解决了信息门户的登录密码加密问题。 将以前存放在有道云笔记里面的分析过程重新整理了一下写成博文：“学校信息门户模拟登录之密码加密” 再利用这个加密模块，很快写出了模拟登录信息门户的 python 自定义包：“学校信息门户模拟登录” 没想到这个自定义包竟然获得了封掣大佬的 pull request（也就是他参与了这个项目，贡献了一部分代码）！这可是我第一次获得 pull request！兴奋之情可想而知，我当时就想继续写点什么出来。 不过这个项目发展空间并没有太多，最多输出 cookies 文件给别的程序或者脚本用。在写好了文档，增加了成绩查询，学习了如何将其打包成 exe 文件，又学习了如何 release 一个版本之后，就没有什么可以扩展的地方了。 在这个过程中，除了上面说到的那些，我还开始使用 github 的 issue 来记录待办事项和 bug，等到有空的时候去修复。 在 github 上面终于有了一个像样的项目了，这让我很高兴。 我又开始把之前写的信息门户爬虫给整理了一下，整理到了一个 github 仓库当中：“chd_spider” 在这个成绩的激励下，我开始尝试做之前领取的任务：爬取微信公众号，确实有成功的部分，不过目前卡关了 博客主题优化给博客增加了几个功能： RSS 简易信息聚合 valine 评论 hexo 的 Next 主题挺方便的，将所有东西都准备好了，增加这些功能挺容易的。 RSS 简易信息聚合在设计自我管理系统中的信息输入子系统时，了解到RSS这个概念。 RSS(Really Simple Syndication)是一种描述和同步网站内容的格式，是使用最广泛的 XML 应用。RSS 搭建了信息迅速传播的一个技术平台，使得每个人都成为潜在的信息提供者。发布一个 RSS 文件后，这个 RSS Feed 中包含的信息就能直接被其他站点调用，而且由于这些数据都是标准的 XML 格式，所以也能在其他的终端和服务中使用，是一种描述和同步网站内容的格式。 就本质而言，RSS 和 Atom 是一种信息聚合的技术，都是为了提供一种更为方便、高效的互联网信息的发布和共享，用更少的时间分享更多的信息。同时 RSS 和 Atom 又是实现信息聚合的两种不同规范 （来自百度百科） 以我的理解，RSS 的 Feed 其实就是一个将网站的内容格式化的 XML 文件，也就是一个“地图”，按照一定的标准标注了特定内容，RSS 阅读器其实就是一个爬虫软件。将 RSS Feed 给 RSS 阅读器之后，阅读器爬虫按照这份“地图”，解析出需要爬取的链接，然后获取文章内容，再展现给用户。 弄懂了原理之后，我帮我的博客也加了一个 RSS 插件，在部署博客的同时生成 RSS Feed（我博客的 RSS Feed），这样别人使用 RSS 阅读器就可以“订阅”我的博客，在我的博客更新的时候可以第一时间看到。 在电脑上我下了一个 RSS 阅读器irreader，订阅了几个朋友的博客。除此之外，这个阅读器还能订阅没有 Feed 的链接，我猜原理是根据你选择的几个链接来自动生成一个 Feed 来进行订阅，甚至能订阅 B 站 up 的视频以及贴吧的帖子，还是挺好用的。 valine 评论和阅读量计数用了同一个 leancloud 应用，效果挺不错： 但遗憾的是，leancloud 在经过上个月的域名封禁事件之后，又是实名注册又是绑定备案域名的，十月一号之后就得找别的办法来弄评论和点击数了。 半途而废的事情 暑假开始的运动目标没有完成，意志力随着身体素质的变差越来越弱 跟着廖雪峰 python 教程写代码的目标没有完成 利用 time meter 记录时间 每天在 anki 录入 30 个单词 晚上十一点睡","link":"/posts/2019_summer_holidays_summary/"},{"title":"python爬虫解析库BeautifulSoup速查","text":"为了方便使用，将 BeautifulSoup 库常用的接口进行总结。 总结内容来源：《python3 网络爬虫开发实战》崔庆才 导入与解析12from bs4 import Beatsoup = BeautifulSoup(response.text,'lxml') 节点选择器提取属性获取到的是第一个标签 soup.title.string:获取 title 标签的文本内容 soup.title.name:获取节点名称“title” soup.p.attrs:获取节点属性字典 soup.p.attrs['class']或者soup.p['class']:获取节点属性 关联选择子孙 soup.p.contents:获取直接子节点列表 soup.p.children：获取直接子节点生成器 soup.p.descendants：获取所有子孙节点生成器 祖先 soup.p.parent：获取直接父节点 soup.p.parents：获取所有祖先节点生成器 兄弟 soup.a.next_sibling：获取下一个兄弟节点 soup.a.previous_sibling：获取上一个兄弟节点 soup.a.next_siblings：获取后面所有兄弟节点列表 soup.a.previous_siblings：获取前面所有兄弟节点列表 方法选择器find_all()1find_all(self, name=None, attrs={}, recursive=True, text=None,limit=None, **kwargs) 用法： soup.find_all(name='ul')：获取所有 ul 节点组成的列表 soup.find_all(attrs={'id':'list'})：获取 id 为 list 的节点 常用参数如 id 和 class 可以直接传入，如：soup.find_all(id = 'list')或soup.find_all(class_='element') soup.find_all(text=re.compile('link'))可以匹配文本，也可以用正则表达式对象 find()返回第一个匹配的元素，和 find_all 用法差不多 其他 find_parents(),find_parent() find_next_siblings(),find_next_sibling() find_previous_siblings(),find_previous_sibling() find_all_next(),find_next()返回节点后符合条件的节点 find_all_previous(),find_previous() CSS 选择器soup.select('CSS选择器')：返回列表","link":"/posts/python_spider_parser_beautifulsoup/"},{"title":"MFC用对话框获取输入","text":"在 MFC 调用对话框读入数据，并在客户区输出。 这是《计算机图形学基础教程》的一个习题： 使用 MFC 设计一个长方形类 CRectangle，调用对话框读入长方形的长度和宽度，在客户区输出长方形的周长和面积。 这个书上并没有教怎么用对话框读取输入，我在这之前也完全没接触过 MFC 的对话框。弄了两小时，终于把这道题做出来了。以此文记录一下 参考链接 MFC 调用输入对话框并返回输入信息 MFC 对话框和常用教程 设计对话框找了一下，MFC 似乎没有像 python 那样的input()或者像是 VB 里面的inputBox()之类的函数，所以得自己先设计对话框。 首先打开Resource View，在Dialog处右键菜单插入新的对话框。 接着就是放控件以及给控件命名了。这个比较简单，就不详细说了。 我设计的对话框有两个Edit控件，一个是IDC_LENGTH，用于输入长方形的长，一个是IDC_WIDTH，用于输入长方形的宽。 新建对话框类在设计好的对话框上右键菜单打开类向导，也就是classWizard，会弹出一个对话框如下图： 大致意思是：检测到有个新建的对话框资源，你可能想要为它创建一个类，要创建吗？ 点确定创建一个对应的类。 如果没有弹出这个对话框，你也可以在类向导右上角的Add Class按钮来创建一个 MFC 里面的类，把基类调整成CDialog，Dialog ID设置成你刚刚设计的对话框 ID 就可以了。 （其实命名最好在后面加个Dlg后缀以表示这是对话框，但是我懒得改了） 添加关联变量在类向导里面选择第二个选项卡，也就是Member Bariables成员变量选项卡。 这里面列出了对话框上控件的 ID，这些 ID 可以在设计对话框的时候指定。 选中用于输入数据的控件，然后点击Add Variable添加对话框类的成员变量。改变量名字，其他选项默认即可。 这个操作与你直接在类代码中添加的区别是，这个操作会建立起控件和这个成员变量的关联关系。这个关联关系体现在自定义对话框类的DoDataExchange()这个成员函数内： 12345678void CInputRectangle::DoDataExchange(CDataExchange* pDX){ CDialog::DoDataExchange(pDX); //{{AFX_DATA_MAP(CInputRectangle) DDX_Text(pDX, IDC_LENGTH, m_edLength);//添加关联变量之前，这里是没有这两行的 DDX_Text(pDX, IDC_WIDTH, m_edWidth); //}}AFX_DATA_MAP} 调用对话框如图，我打算使用菜单来调用对话框输入矩形长和宽。 添加菜单的过程不详细说。 直接跳到菜单的响应函数： 1234567891011void CComputerGraphicsExerciseView::OnHomework2_2(){ // TODO: Add your command handler code here CInputRectangleDlg inputDlg; int nResponse = inputDlg.DoModal(); if(nResponse==IDOK) { //这里获取输入并在客户区输出 }} 在文件开头 include 对话框类的头文件，声明对象，并调用对话框对象的DoModal()方法。 这个方法在对话框关闭之后，才会返回一个值，对应关闭对话框的动作，这里我用nResponse这个 int 变量接收返回值。 接着判断返回值，如果是点击确定按钮关闭对话框，那么获取对话框的输入，并且在客户区输出。 获取输入绑定对话框上两个编辑框的变量分别为：m_edWidth和m_edLength。默认情况下，它们是 CString 类型的，因此需要进行类型转换。 12int width=atoi(inputDlg.m_edWidth.GetBuffer(0));int height=atoi(inputDlg.m_edLength.GetBuffer(0)); 对上面两行代码的说明： 两个关联变量是public的，因此可以直接访问。 CString 的GetBuffer()成员函数返回对应的字符数组类型的字符串 atoi（ASCII to integer）把字符串转换成整型数 进行输出获取设备上下文，并调整坐标系： 1234567891011CDC *pDC=GetDC();//获取设备上下文CRect rect;GetClientRect(&amp;rect);pDC-&gt;SetMapMode(MM_ANISOTROPIC);pDC-&gt;SetWindowExt(rect.Width(),rect.Height());pDC-&gt;SetViewportExt(rect.Width(),-rect.Height());pDC-&gt;SetViewportOrg(rect.Width()/2,rect.Height()/2);rect.OffsetRect(-rect.Width()/2,-rect.Height()/2);pDC-&gt;Rectangle(rect);//清空屏幕 输出数据，并释放设备上下文： 12345678910CRectangle crect(width,height);CString perimeter_text,area_text;perimeter_text.Format(&quot;长方形的周长为：%.2f&quot;,crect.perimeter());area_text.Format(&quot;长方形的面积为：%.2f&quot;,crect.area());pDC-&gt;TextOut(0,0,perimeter_text);pDC-&gt;TextOut(0,20,area_text);ReleaseDC(pDC);//释放设备上下文 这样就完成了 菜单代码概览1234567891011121314151617181920212223242526272829303132333435363738void CComputerGraphicsExerciseView::OnHomework2_2(){ // TODO: Add your command handler code here CInputRectangleDlg inputDlg; int nResponse = inputDlg.DoModal(); if(nResponse==IDOK) { CDC *pDC=GetDC(); CRect rect; GetClientRect(&amp;rect); pDC-&gt;SetMapMode(MM_ANISOTROPIC); pDC-&gt;SetWindowExt(rect.Width(),rect.Height()); pDC-&gt;SetViewportExt(rect.Width(),-rect.Height()); pDC-&gt;SetViewportOrg(rect.Width()/2,rect.Height()/2); rect.OffsetRect(-rect.Width()/2,-rect.Height()/2); pDC-&gt;Rectangle(rect);//清空屏幕 int width=atoi(inputDlg.m_edWidth.GetBuffer(0)); int height=atoi(inputDlg.m_edLength.GetBuffer(0)); CRectangle crect(width,height); CString perimeter_text,area_text; perimeter_text.Format(&quot;长方形的周长为：%.2f&quot;,crect.perimeter()); area_text.Format(&quot;长方形的面积为：%.2f&quot;,crect.area()); pDC-&gt;TextOut(0,0,perimeter_text); pDC-&gt;TextOut(0,20,area_text); ReleaseDC(pDC); }} 错误思路一开始我以为需要编写对话框的ok按钮的响应事件，写成了下面这样，试了一下不行，不知道为什么： 123456789101112131415161718192021222324252627282930313233343536void CInputRectangleDlg::OnOK(){ // TODO: Add extra validation here CDialog::OnOK(); UpdateData();//用于将数据从对话框同步到成员变量中 int width=atoi( m_edWidth.GetBuffer(0)); int height=atoi( m_edLength.GetBuffer(0)); CRectangle crect(width,height); CDC *pDC=GetDC(); CRect rect; GetClientRect(&amp;rect); pDC-&gt;SetMapMode(MM_ANISOTROPIC); pDC-&gt;SetWindowExt(rect.Width(),rect.Height()); pDC-&gt;SetViewportExt(rect.Width(),-rect.Height()); pDC-&gt;SetViewportOrg(rect.Width()/2,rect.Height()/2); rect.OffsetRect(-rect.Width()/2,-rect.Height()/2); pDC-&gt;Rectangle(rect);//清空屏幕 CString perimeter_text,area_text; perimeter_text.Format(&quot;长方形的周长为：%.2f&quot;,crect.perimeter()); area_text.Format(&quot;长方形的面积为：%.2f&quot;,crect.area()); pDC-&gt;TextOut(100,100,perimeter_text); pDC-&gt;TextOut(100,300,area_text); ReleaseDC(pDC);}","link":"/posts/MFC_get_input_by_Dialog/"},{"title":"MFC习题|RGB颜色模型演示程序","text":"习题来源：《计算机图形学基础教程》孔令德（第二版） 用 mfc 基于对话框的编程，实现下图的 RGB 颜色模型演示程序。点击颜色按钮能将“颜色及代码”这个组框中的静态文本框变成对应的颜色，调色板按钮可以调出自带的颜色选择对话框。滚动条和旁边的编辑框都可以调整颜色。 设计对话框过程不详述，直接开始代码和思路介绍。参考链接见文末。 改变演示块颜色我在这里将用于演示颜色的静态文本框称为演示块，对应的 ID 为IDC_COLOR_BOX。 查找了很久关于“如何修改控件颜色”的资料。 改变控件颜色需要在对话框类的OnCltColor()成员函数里面写对应代码。要生成这个方法，需要添加WM_CTLCOLOR这个消息的响应函数，在Class View的对话框类上右键可以找到Add Windows Message Handler，在这里添加就可以了。 生成的代码如下： 123456789HBRUSH CComputerGraphcisExercise2Dlg::OnCtlColor(CDC* pDC, CWnd* pWnd, UINT nCtlColor){ HBRUSH hbr = CDialog::OnCtlColor(pDC, pWnd, nCtlColor); // TODO: Change any attributes of the DC here // TODO: Return a different brush if the default is not desired return hbr;} 这个函数会在每个控件被重绘时调用，所以将改变控件颜色的代码放在这里就行了。 参数pWnd可以用来识别现在是哪个控件正在被重绘。 它的返回值是用于填充控件的画刷。 可以先判断是哪个控件正在被重绘，当演示块被重绘时，将它的颜色调整为自己设置的颜色。 12345678910111213HBRUSH CComputerGraphcisExercise2Dlg::OnCtlColor(CDC* pDC, CWnd* pWnd, UINT nCtlColor){ HBRUSH hbr = CDialog::OnCtlColor(pDC, pWnd, nCtlColor); // TODO: Change any attributes of the DC here if(pWnd-&gt;GetDlgCtrlID() == IDC_COLOR_BOX)//判断控件 { hbr=CreateSolidBrush(m_color);//调整颜色 } // TODO: Return a different brush if the default is not desired return hbr;} 上面代码的m_color是一个对话框类的protected变量，我把它和自动生成的m_hIcon放在了一起。 注意：如果这个变量被设置为public，就会在运行时产生错误，原因未知。 此变量在对话框类的初始化函数OnInitDialog()内初始化。 有了以上代码之后，想要改变演示块的颜色，只需要改变m_color的值并刷新对话框（例如使用Invalidate()）就可以了。 显示颜色代码在演示块下面有一个静态文本框用于显示当前颜色的十六进制代码，例如“#ffffff”。 由于颜色每次都是在对话框刷新的时候被改变的，可以将这个功能写在OnPaint()内。获取方式也不难，看代码基本能看懂，不赘述。 12345678910void CComputerGraphcisExercise2Dlg::OnPaint(){ //其他代码 //获取颜色代码 CStatic *color_code = (CStatic*)GetDlgItem(IDC_COLOR_CODE); CString color; color.Format(&quot;#%02x%02x%02x&quot;,GetRValue(m_color),GetGValue(m_color),GetBValue(m_color)); color_code -&gt;SetWindowText(color);} 实现颜色按钮双击每个颜色按钮，添加它们的响应事件，例如： 123456void CComputerGraphcisExercise2Dlg::OnButtonRed(){ // TODO: Add your control notification handler code here m_color = RGB(255,0,0); Invalidate();} 调整它们的颜色，并进行刷新重绘。 至于调色板按钮，需要使用 mfc 内置的颜色对话框CColorDlg: 123456789101112void CComputerGraphcisExercise2Dlg::OnButtonPalette(){ // TODO: Add your control notification handler code here CColorDialog palette; int nResponse = palette.DoModal(); if(nResponse == IDOK) { m_color = palette.GetColor();//获取调色板的颜色 } Invalidate();} 实现滚动条初始化滚动条首先需要在对话框的OnInitDialog()方法内，新增初始化滚动条范围值的代码。 123456789101112131415161718BOOL CComputerGraphcisExercise2Dlg::OnInitDialog(){ //其它代码 //... CScrollBar *scroll=(CScrollBar*)GetDlgItem(IDC_SCROLLBAR_R); scroll-&gt;SetScrollRange(0,255); scroll = (CScrollBar*)GetDlgItem(IDC_SCROLLBAR_G); scroll-&gt;SetScrollRange(0,255); scroll = (CScrollBar*)GetDlgItem(IDC_SCROLLBAR_B); scroll-&gt;SetScrollRange(0,255); return TRUE; // return TRUE unless you set the focus to a control} 这段代码初始化了三个滚动条控件，首先用GetDlgItem()来获取 ID 对应的控件对象的指针，然后调用SetScrollRange()来设定其范围为 0~255。 响应滚动条事件滚动条的响应事件不像按钮一样是每个按钮分开的，而是分为水平滚动条事件响应函数，和垂直滚动条响应函数。 在Class View里对对话框类右键，在右键菜单中找到Add Windows Message Handler，添加WM_HSCROLL消息的响应函数（如果是垂直滚动条，应该是WM_VSCROLL消息）。 生成的响应函数是这样的： 12345void CComputerGraphcisExercise2Dlg::OnHScroll(UINT nSBCode, UINT nPos, CScrollBar* pScrollBar){ // TODO: Add your message handler code here and/or call default CDialog::OnHScroll(nSBCode, nPos, pScrollBar);} 没看文档，不过参数大概意思可能是： nSBCode：滚动条响应的消息类型 nPos：滚动条改变状态之后的值 pScrollBar：指向被改变状态的滚动条控件的指针 滚动条拖动的代码需要自己写，在实现功能之前，你即使用鼠标拖动滑块，滑块也会回到原来的位置。 在这个响应函数里面，我只让滚动条改变对应的编辑框对应的数值。 1234567891011121314151617181920212223242526272829303132void CComputerGraphcisExercise2Dlg::OnHScroll(UINT nSBCode, UINT nPos, CScrollBar* pScrollBar){ // TODO: Add your message handler code here and/or call default CDialog::OnHScroll(nSBCode, nPos, pScrollBar); int pos = pScrollBar-&gt;GetScrollPos();//获取当前位置 switch(nSBCode) { case SB_THUMBPOSITION://被拖动 pos = nPos; break; //其实这里还可以写别的事件响应，丰富功能 } pScrollBar-&gt;SetScrollPos(pos); //设置与滚动条对应的编辑框的数值 switch(pScrollBar-&gt;GetDlgCtrlID()) { case IDC_SCROLLBAR_R: SetDlgItemInt(IDC_EDIT_R,pos); break; case IDC_SCROLLBAR_G: SetDlgItemInt(IDC_EDIT_G,pos); break; case IDC_SCROLLBAR_B: SetDlgItemInt(IDC_EDIT_B,pos); break; }} 响应编辑框变化事件现在已经可以滑动滚动条来修改编辑框内的值了，但演示块的颜色还不会改变，我把这个功能写在编辑框里面了，这样，可以顺便实现“在编辑框内修改值来修改颜色”的功能。 这是其中一个编辑框的响应函数代码，其他两个类似，要说的内容都写在注释里面了。 12345678910111213141516171819202122232425void CComputerGraphcisExercise2Dlg::OnChangeEditR(){ // TODO: If this is a RICHEDIT control, the control will not // send this notification unless you override the CDialog::OnInitDialog() // function and call CRichEditCtrl().SetEventMask() // with the ENM_CHANGE flag ORed into the mask. // TODO: Add your control notification handler code here UpdateData();//更新数据，将数据从控件上同步到绑定的变量 int pos = atoi(m_R_value.GetBuffer(0)); ((CScrollBar*)GetDlgItem(IDC_SCROLLBAR_R))-&gt;SetScrollPos(pos); //根据滚动条位置设置当前颜色值 int R=0,G=0,B=0; R=((CScrollBar*)GetDlgItem(IDC_SCROLLBAR_R))-&gt;GetScrollPos(); G=((CScrollBar*)GetDlgItem(IDC_SCROLLBAR_G))-&gt;GetScrollPos(); B=((CScrollBar*)GetDlgItem(IDC_SCROLLBAR_B))-&gt;GetScrollPos(); m_color = RGB(R,G,B); //为了防止整个对话框闪烁，只刷新演示块 CRect rect; ((CStatic*)GetDlgItem(IDC_COLOR_BOX))-&gt;GetWindowRect(&amp;rect); ScreenToClient(&amp;rect);//转换为对话框上的客户坐标 InvalidateRect(rect);//只刷新控件位置} 完成这一步之后，已经能够实现使用滚动条或者编辑框来改变颜色了，但是当你在点击颜色按钮时，虽然颜色改变了，但是滚动条的位置和编辑框的值不会随之改变。 因此还需要一步： 滚动条随颜色而变化位置这个对话框内只有颜色按钮能够改变颜色，所以简单地在所有颜色按钮的代码内添加改变位置的代码即可。 而改变滚动条的位置只需要改变对应的编辑框的数值就可以了。 于是颜色按钮代码变成了这样 12345678910111213141516void CComputerGraphcisExercise2Dlg::OnButtonRed(){ // TODO: Add your control notification handler code here m_color = RGB(255,0,0); //调整滚动条位置 int R=0,G=0,B=0; R=GetRValue(m_color); G=GetGValue(m_color); B=GetBValue(m_color); SetDlgItemInt(IDC_EDIT_R,R); SetDlgItemInt(IDC_EDIT_G,G); SetDlgItemInt(IDC_EDIT_B,B); Invalidate();} 部分用到的 MFC 函数或宏的简介详情见百度 GetRValue()，GetGValue()，GetBValue()，分别用于获取颜色值的 RGB 三个通道的值 SetDlgItemInt()，可以将值送入 ID 对应的控件 GetDlgItem()，通过 ID 来获取指向控件的指针，记得转换指针类型 Invalidate()，使客户区无效化，引起重绘 参考链接 VS2010/MFC 编程入门之二十六（常用控件：滚动条控件 Scroll Bar）-鸡啄米","link":"/posts/MFC_RGB_demonstration/"},{"title":"文章分类说明","text":"为了对文章进行更好的管理，需要提前确定好文章的分类。将本博客内的文章分为以下七类： 过程复盘 知识整理 解决方案 算法理解 工具使用 目录索引 日志随笔 分类定好了基本就不变了： 分类 内容 过程复盘 记录学习实践一个事物的过程，侧重记录与反思 知识整理 针对某一部分知识进行集中整理方便查阅，例如 API、语法、命令等 解决方案 针对遇到的某个具体问题寻找解决方案 算法理解 针对某个具体算法的理解掌握 工具使用 对于框架、软件、网站等工具的使用方法与心得经验，或是简单推荐 目录索引 定期将本博客的文章索引起来，或者整理一些有用的参考链接 日志随笔 随便写点啥心情，或者年终总结之类的","link":"/posts/categories_description/"},{"title":"Hello World","text":"大家好，我是憧憬少。 这是用 hexo 搭建的第二个博客，由于想改一个名字，又担心会影响到很多东西，于是就新搭建了一个，原本的博客仍然保留，链接在此：羽尘的个人博客-尘世未解 其实和以前的几乎是一样的，只是改了用户名，以及域名。这可能是中二病带来的对帅气名字的执着吧！ 现在是 2019 年 12 月 30 日，大三第一学期末，现在的我，比之前会了更多的东西，也认识到了文字输出对于学习的重要性，所以我会花更多时间在写博客总结上（也许吧）。 测试代码块 test.py12print(&quot;hello world&quot;);","link":"/posts/hello_world/"},{"title":"更改git仓库已经commit的用户名和邮箱信息","text":"换了一个 github 账号，想把以前的仓库 push 到新的账号上，但是 commit 的用户名和邮箱信息还是以前的，想修改成新的用户信息。 参考链接 图文详解如何修改 git 已提交记录的邮箱？ ：关于如何使用git rebase -i来修改 commit 的信息 github 修改 commit 的用户名和邮箱 ： 这里面讲得很全面，所有方法都讲到了 git 更改作者信息 ：git 官方教程，使用脚本 最终采纳的方法使用git rebase成功修改了一条，但是一条条改比较麻烦。 最终使用了官方提供的脚本（怪不得那么多教程的脚本代码都长一样，原来是官方的），修改前面三个变量即可，详情见上面的官方教程的参考链接 12345678910111213141516171819#!/bin/shgit filter-branch --env-filter 'OLD_EMAIL=&quot;your-old-email@example.com&quot;CORRECT_NAME=&quot;Your Correct Name&quot;CORRECT_EMAIL=&quot;your-correct-email@example.com&quot;if [ &quot;$GIT_COMMITTER_EMAIL&quot; = &quot;$OLD_EMAIL&quot; ]then export GIT_COMMITTER_NAME=&quot;$CORRECT_NAME&quot; export GIT_COMMITTER_EMAIL=&quot;$CORRECT_EMAIL&quot;fiif [ &quot;$GIT_AUTHOR_EMAIL&quot; = &quot;$OLD_EMAIL&quot; ]then export GIT_AUTHOR_NAME=&quot;$CORRECT_NAME&quot; export GIT_AUTHOR_EMAIL=&quot;$CORRECT_EMAIL&quot;fi' --tag-name-filter cat -- --branches --tags","link":"/posts/git_amend_commited_info/"},{"title":"【编程练习】明日非舟抽卡模拟器（1）按照概率抽取干员星级","text":"好友封掣写了一个明日方舟模拟寻访，于是也想做一个来作为 java 的练手，这学期写课设的时候就体现出我平时写代码写太少了。 当然，经过这学期末的编码轰炸，我现在可不敢像以前一样没有计划地直接开始，先想好它的架构，随后再开始编写，并留下系列博文记录，供以后参考。 本项目连载 github 库地址 目前已经构思的架构 主包 视图包 view 模型包 model 简历类 Resume：用于存储干员的信息，比如名字，星级，立绘路径等 人事资源类 HumanResourse：用于存储合成玉以及其他抽卡资源数目 属性 合成玉数目 卡池 方法 单抽 十连 卡池类 Pool 属性 星级出率：一维数组，下标对应星级，值为对应出率 简历池：二维数组，一维下标对应星级，二维下标动态，值为干员引用 方法 载入简历 loadResume(String fileName)从文件中读取出简历，并加入简历池 抽出下一份简历 recruit()先抽取星级，再从对应的星级池中抽取简历 抽取星级 randomStar()生成 1~100 的随机整数，根据星级出率确定每个星级的区间，判断随机数落在哪个区间，从而确定星级 抽取对应星级的简历 randomResume(int star)从简历池中随机抽取下标，并返回下标对应的干员引用 算法根据卡池的出率抽取星级。 干员的星级分为一星到六星，每个星级的概率不一定相同。 这个目标的要点在于，如何给予六个星级不同的抽取概率。 方法一是创建一个 100 个元素的数组，根据不同星级各自的概率分配不同的元素数量。比如，三星有 45%概率被抽出，那么就将 45 个元素赋值为“3”，六星有 2%的概率，那么就将 2 个元素赋值为“6”。最后抽取下标来获取星级。 不过我没有采取这种方式，这种方式有点暴力。这个例子里面还好，是 100 个整数，假如是 100 个开销比较大的对象，或者概率精确到了很多位小数，那么就不太合适了。 方法二是对每个星级划分一个区间，概率决定了区间的长度，在总区间内随机一个数，然后判断落在哪个星级区间。我用的是这个方法。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 卡池类 * 负责存储卡池概率信息 */package africanights.model;import java.util.Random;public class Pool { protected double[] m_starProbability = new double[] { 0.00,0.00,0.00,//1,2星 0.40,0.50,//3,4星 0.08,0.02//5,6星 };//星级出率，下标1~6对应星级，0暂时闲置 /** * 根据星级概率抽取出一个星级，取值为1~6 * @return 干员星级 */ public int randomStar() { Random random = new Random(); int star = 0;//返回值 int randomInt = random.nextInt(100) + 1;//产生[1,100]之间的随机数 //判断星级区间 /** * 每一个星级根据概率大小占据[1,100]区间不同长度的区间， * 判断随机数落在哪个区间，就是抽取到了哪个星级 * */ int lowerInt=1;//边界整数，用于给星级区域定界 int upperInt=1; for(int i=1;i&lt;m_starProbability.length;i++) { lowerInt = upperInt;//上一个星级的上界变为这个星级的下界 int areaLength = (int)Math.round(m_starProbability[i] * 100); upperInt += areaLength; if(lowerInt &lt;= randomInt &amp;&amp; randomInt &lt; upperInt) { //如果随机数落在[lowerInt,upperInt)区间 star = i; break; } } //单独处理抽到100的情况 //抽到100则为最高星级 if(randomInt == 100) return m_starProbability.length-1; return star; } public static void main(String[] args) { //测试randomStar() Pool pool = new Pool(); int[] counter=new int[7]; for(int i=0;i&lt;100;i++) { int star = pool.randomStar();//测试randomStar() System.out.format(&quot;%d\\n&quot;,star); counter[star]++; } for(int i=0;i&lt;7;i++) { System.out.format(&quot;抽到%d星%d个\\n&quot;,i,counter[i]); } //测试randomStar()*/ }}","link":"/posts/Africanights_simu_hr_1/"},{"title":"建新hexo博客后继续更新旧hexo博客的方法","text":"我创建了一个新的 github 账号 ChangingSelf（憧憬少）来搭建新的博客，旧的博客搭建在旧账号 HaneChiri（羽尘）上，原本的博客已经有一些人知道了，所以我用这个方式来将以前的访客带到我的新博客来。 问题在于，为了部署新博客，我将原本的 ssh 密钥对文件删掉了，重新生成了新的 ssh，现在想要部署旧博客就会出现类似下面的错误： 123ERROR: Permission to HaneChiri/HaneChiri.github.io.git denied to ChangingSelf.fatal: Could not read from remote repository.Please make sure you have the correct access rights ` 大意是我没有权限，也就是 ssh 没有配好。 参考链接 github 支持多个账号 SSH-keygen 用法 git 配置多个 SSH-key git 配置多个 SSH-key-多图易理解版 配置多个 ssh 密钥对并且永久多 ssh 管理 是否必须每次添加 ssh-add ssh 百度百科 解决方案目前状况操作系统是 win10（找到的资料很多 linux 的，不过没关系，有 git-bash） github 上有两个账号，一个旧账号（HaneChiri），一个新账号（ChangingSelf）。本地有两个 hexo 博客源代码文件夹，分别对应两个账号上搭建的博客。 本地C:\\Users\\Administrator\\.ssh文件夹内有： id_rsa.pub：公钥文件，已添加到 ChangingSelf 账号的 ssh-key id_rsa：私钥文件 known_hosts 现在在 ChangingSelf 博客文件夹内使用hexo d部署博客，可以部署到对应账号的仓库，而在 HaneChiri 博客文件夹内部署博客，则权限不足。 （现在回想起来也许直接将现在新的公钥添加到旧账号中就搞定了呀，搞那么麻烦 QAQ，等写完这篇文再试试这个方法） 过程复盘生成新密钥对先来看看百度百科关于 SSH（安全外壳协议）的介绍： 从客户端来看，SSH 提供两种级别的安全验证。 第一种级别（基于口令的安全验证） 只要你知道自己帐号和口令，就可以登录到远程主机。所有传输的数据都会被加密，但是不能保证你正在连接的服务器就是你想连接的服务器。可能会有别的服务器在冒充真正的服务器，也就是受到“中间人”这种方式的攻击。 第二种级别（基于密匙的安全验证） 需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到 SSH 服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。 用这种方式，你必须知道自己密匙的口令。但是，与第一种级别相比，第二种级别不需要在网络上传送口令。 第二种级别不仅加密所有传送的数据，而且“中间人”这种攻击方式也是不可能的（因为他没有你的私人密匙）。但是整个登录的过程可能需要 10 秒 [2] 。 我们现在弄的就是第二种，基于密钥的安全验证。本地创建一个密钥对，将公钥放在 github 服务器上，本地保留私钥。 首先，打开 git-bash，生成新的 ssh 密钥对： 1$ssh-keygen -t rsa -C &quot;youremail@xxx.com&quot; -f keyfileName 参数 说明 -t 生成的密钥类型，默认 rsa -C 注释文字，应该不会影响密钥内容，这里设置成邮箱 -f 指定密钥文件名，默认为 id_rsa 由于.ssh 目录下已经存在默认文件名的密钥，所以换一个名字。我想要生成旧账号 HaneChiri 的密钥，所以文件名就起名为id_rsa_hanechiri，当然，这个并无影响。 最后会生成两个文件，.pub 后缀的是公钥，另一个是私钥。 添加公钥到 github 账号在网页右上角账号设置中找到 SSH key，添加公钥文件的内容即可，添加过程很简单，不详细叙述。 添加完毕后再次部署 HaneChiri 的博客，发现仍然是这个错误： 123ERROR: Permission to HaneChiri/HaneChiri.github.io.git denied to ChangingSelf.fatal: Could not read from remote repository.Please make sure you have the correct access rights 也对，现在有两个密钥对，可能是配对错误了。 仔细看错误内容，HaneChiri 库拒绝了用户 ChangingSelf 的访问，也就是说，用的是 HaneChiri 的公钥，与新账号 ChangingSelf 的私钥，难怪无法配对了。因此我们需要改变私钥的选择。 改变使用的私钥我查到的参考博客里面基本上都说要使用ssh-add命令来将私钥添加管理，不过我后来发现，这个添加并不是永久保存，而是添加到 ssh-agent 的高速缓存中，我打开另一个 git-bash 的时候就不行了（参考：是否必须每次添加 ssh-add） 临时性保存打开 ssh-agent 服务，即输入命令： 1$ssh-agent bash 然后添加私钥： 1$ssh-add C:/Users/Administrator/.ssh/id_rsa_hanechiri 这里的地址是需要使用的私钥文件的绝对地址。 可以通过-l 选项查看所有已经添加的私钥： 1$ssh-add -l 使用-D 选项清空私钥列表： 1$ssh-add -D 接着在这个 git-bash 里面来操作就行了（如果退出就得再弄一次），此时用hexo d命令部署，就部署成功了。 永久性保存需要永久保存私钥的选择，则需要一个配置文件 config，这个文件长这样： 12345Host github.com HostName github.com IdentityFile C:/Users/Administrator/.ssh/id_rsa_hanechiri PreferredAuthentications publickey User HaneChiri 字段 说明 Host 网站别名，最好和 HostName 一致 HostName 网站域名 IdentityFile 私钥文件的绝对路径 PreferredAuthentications 验证方式，填 publickey 就是公钥验证 User 用户名 可以配置多个网站，每个网站都有上面这些字段。在你使用 ssh 访问这个文件内存在的某个网站时，ssh 就会拿这个文件里面指定的私钥来进行验证。 在.ssh 目录下找，如果存在这个名为config的文件，就打开来编辑，没有的话就新建一个。 配置好文件之后，打开 git-bash 再使用hexo d就搞定部署了。 由于我只是需要临时将博客地址转移的公告发上旧博客，使用临时的方法就好了。（不过我是先用了 config 文件的方法，写本文时才尝试临时性的方法，成功了） 最后做个试验最后再来试试我写本文时，对 ssh 更加了解之后，才想到的简便方法：直接把新账号 ChangingSelf 的公钥添加到旧账号的 ssh-key 中。 结果给我显示： 1Key is already in use 果然没这么简单。找解决方法，也就是上文我写的那些。","link":"/posts/update_old_hexo_blog_after_build_new_hexo_blog/"},{"title":"【编程练习】明日非舟抽卡模拟器（2）xml文件解析","text":"为了修改与添加方便，将干员的信息放在简历类 Resume 中，简历信息使用 xml 文件存储，在启动时加载进来。 本项目连载 github 库地址 参考链接 细说 java 解析 XML 文档的常用方法（含实例）-知乎 Java 千百问_02 基本使用（010）_java、javax、sun、org 包有什么区别 Java DOM 简介-w3cSchool 解析 xml 文件需要 import 进来的内容如下，jdk1.8 全部自带，不需要额外下载。 123456import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import org.w3c.dom.Document;import org.w3c.dom.Node;import org.w3c.dom.NodeList; 获取文档对象解析方式如下： 首先获取一个工厂类（DocumentBuilderFactory）实例，使用了单例模式所以得用newInstance()来获取全局对象 再用获得的工厂对象来创建文档解析器（DocumentBuilder） 最后才能够利用文档解析器来解析文档（Document） 12345String path = &quot;Melantha.xml&quot;;//解析xml文件DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();DocumentBuilder db = dbf.newDocumentBuilder();Document doc = db.parse(path); 这里DocumentBuilder对象的parse()方法可以直接传入 String 类型的字符串文件路径，也可以传入文件对象，例如： 1234567import java.io.File;String path = &quot;Melantha.xml&quot;;File f=new File(path);//解析xml文件DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();DocumentBuilder db = dbf.newDocumentBuilder();Document doc = db.parse(f); DOM 方式获取文档数据此处引用自：Java DOM 简介-w3cSchool 例如，我们有以下 xml 结构: 1&lt;yourTag&gt;This is an &lt;bold&gt;important&lt;/bold&gt; test.&lt;/yourTag&gt; DOM 节点的层级如下，其中每行代表一个节点: 12345ELEMENT: yourTag + TEXT: This is an + ELEMENT: bold + TEXT: important + TEXT: test. yourTag元素包含文本，后跟一个子元素，后跟另外的文本。 节点类型为了支持混合内容，DOM 节点非常简单。标签元素的“内容”标识它是的节点的类型。 例如， 节点内容是元素yourTag的名称。 DOM 节点 API 定义nodeValue()，nodeType()和nodeName()方法。 对于元素节点&lt; yourTag&gt;nodeName()返回 yourTag，而 nodeValue()返回 null。 对于文本节点+ TEXT:这是一个nodeName()返回#text，nodeValue()返回“This is an”。 虽然这里写的用nodeValue()，但现在用的是getValue()这样子的方法。 载入单份 xml 文件示例代码需要解析的 xml 文件的内容： 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;resume&gt; &lt;name&gt;玫兰莎&lt;/name&gt; &lt;star&gt;3&lt;/star&gt; &lt;chat&gt;......玫兰莎。从现在起，我的利刃将为您所用。&lt;/chat&gt; &lt;portrayal&gt;image/Melantha.jpg&lt;/portrayal&gt;&lt;/resume&gt; 代码部分： 12345678910111213141516171819202122232425262728/** * 载入简历对象 * @param path 简历文件路径 * @return 简历对象 */ public Resume loadResume(String path) { Resume resume = null; try{ //解析xml文件 DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance(); DocumentBuilder db = dbf.newDocumentBuilder(); Document doc = db.parse(path); String nameString= doc.getElementsByTagName(&quot;name&quot;).item(0).getFirstChild().getNodeValue(); String starString= doc.getElementsByTagName(&quot;star&quot;).item(0).getFirstChild().getNodeValue(); int starInt = Integer.valueOf(starString); String chatString= doc.getElementsByTagName(&quot;chat&quot;).item(0).getFirstChild().getNodeValue(); String portrayalString= doc.getElementsByTagName(&quot;portrayal&quot;).item(0).getFirstChild().getNodeValue(); resume = new Resume(nameString, starInt, chatString, portrayalString); resume.show(); }catch(Exception e){ e.printStackTrace(); } return resume; }","link":"/posts/Africanights_simu_hr_2/"},{"title":"Scrapy爬虫框架（1）一个简单的可用的爬虫","text":"很久没写爬虫了，又重新开始使用 scrapy，之前学习的内容基本上都忘了，重新复习一遍，发现对它的理解又加深了一些。 本文将初级知识点简单梳理，实现了一个 HelloWorld 级别的 Scrapy 爬虫。 本文适用于 Scrapy 1.6.0，结合了自己的理解，可能理解有错误，欢迎在下面评论区指出。 不包含安装教程。 参考链接 Scrapy-百度百科 Python 爬虫-scrapy 介绍及使用 Scrapy 中文网 Scrapy 中文网的爬虫实验室 xpath 教程： 学爬虫利器 XPath,看这一篇就够了：这个是结合代码来讲解的 Python 神技能：六张表 搞定 Xpath 语法：这个是列出语法表的 VScode Python no module 的解决方法 Python 中获得当前目录和上级目录 Scrapy 是啥先看看Scrapy-百度百科的解释： Scrapy 是一个为爬取网站数据、提取结构性数据而设计的应用程序框架，它可以应用在广泛领域：Scrapy 常应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。通常我们可以很简单的通过 Scrapy 框架实现一个爬虫，抓取指定网站的内容或图片。 它是一个框架，帮你解决写爬虫的过程中遇到的一些问题，简化你写爬虫的过程。对于一些简单的爬虫，你不需要自己来写重复的代码，它将重复的代码都隐藏起来，你只需要写一些与你需要爬取的网站相关的东西就可以了。 例如，爬虫需要发送请求和获取响应，scrapy 有个专门的调度器来帮你解决这个问题，你不需要自己来调度，你只需要使用它的下载器传给你的响应对象 Response 来进行解析即可，解析好的数据你也可以打包成它的一个名为 Item 的类的对象中，更方便地进行处理。方便很多。 Scrapy 的组成下面这个图片来自于Python 爬虫-scrapy 介绍及使用 调度器（Scheduler）选择合适的时机发送 Request（请求）给下载器； 下载器（Downloader）处理 Request（响应），即发送请求并获取响应 Response，将 Response 传给爬虫； 爬虫（Spider）主要做两类事情： 提取当前 Response 中的数据，打包成 Item（或者是 dict），将它们发送给管道 获取 Response 中下一个 Request 的 url（比如你第一个 Response 爬取的是目录页，那么就是获取目录项对应的 url）从而构造下一个 Request，再将这个 Request 发送给调度器 管道（Item Pipeline）处理 Item 中的数据 中间件（Middleware）分为下载中间件和爬虫中间件，用来在传送 Request 和 Response 过程中做一些额外的处理 引擎（Engine）用于将以上模块都连接起来，其他模块都直接与引擎交互，数据等由引擎进行转发 一般我们需要编写的，就是爬虫和管道，也就是解析数据和处理数据。 过程创建项目首先在命令行创建项目 1$scrapy startproject 项目名称 会生成一个以你项目名称命名的文件夹，里面就是你的项目文件 创建爬虫1$scrapy genspider 爬虫名 爬取的域名 它的作用是在 spider 目录下按照模板创建一个以你爬虫为名的 py 文件，当然你也可以手动创建，只要你的文件符合 scrapy 的要求就行，最好用命令。 记得先切换到你项目目录。 编写爬虫我要练习爬取的是Scrapy 中文网提供的爬虫实验室 爬虫命名为 lab，创建好的初始爬虫文件lab.py是这样的 1234567891011# -*- coding: utf-8 -*-import scrapyclass LabSpider(scrapy.Spider): name = 'lab' allowed_domains = ['lab.scrapyd.cn'] start_urls = ['http://lab.scrapyd.cn'] def parse(self, response): pass name：爬虫名 allowed_domains：允许访问的域名，注意是域名，而不是要爬取的 url，别写成http://lab.scrapyd.cn之类的 start_urls：初始 url parse(self,response)：解析函数，传入的参数就是 Response 响应，你可以用这个引用来获取网页内容，从而进行处理 运行过程理解按照我的理解，当启动这个爬虫时： scrapy 会将 start_urls 这个列表里面的 url 都生成对应的 Request 发给调度器 然后调度器将 Request 通过引擎转发给下载器 下载器再将下载好的 Response 发给引擎，引擎调用该爬虫的 parse 方法，将这个 Response 传入作为参数 引擎获取 parse 的返回值 如果是 Request（即新的请求），就发送给调度器 如果是 item 或者 dict，就发送给管道 当调度器中没有新的 Request 了，scrapy 停止。 调试解析1$scrapy shell 你要爬取的url 此处，我要爬取的就是http://lab.scrapyd.cn。 这个命令可以打开交互式调试命令行，如下： 12345678910111213141516$scrapy shell http://lab.scrapyd.cn#……省略一大堆日志信息[s] Available Scrapy objects:[s] scrapy scrapy module (contains scrapy.Request, scrapy.Selector, etc)[s] crawler &lt;scrapy.crawler.Crawler object at 0x0000017F01C9A748&gt;[s] item {}[s] request &lt;GET http://lab.scrapyd.cn&gt;[s] response &lt;200 http://lab.scrapyd.cn&gt;[s] settings &lt;scrapy.settings.Settings object at 0x0000017F031BCBE0&gt;[s] spider &lt;LabSpider 'lab' at 0x17f034c2da0&gt;[s] Useful shortcuts:[s] fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)[s] fetch(req) Fetch a scrapy.Request and update local objects[s] shelp() Shell help (print this help)[s] view(response) View response in a browserIn [1]: scrapy 这时已经将 response 给你了，你可以使用这些命令来进行调试。 没错，就是给 parse 函数传的那个 response 参数。 你可以使用： 1In[1]:response.text 来获取得到的 html 字符串，以确定是否成功获取到自己想要的网页。 先去那个网站按 f12 查看一下它的元素： 12345678910111213141516171819202122232425262728293031323334353637&lt;div class=&quot;col-mb-12 col-8&quot; id=&quot;main&quot; role=&quot;main&quot;&gt; &lt;div class=&quot;quote post&quot;&gt; &lt;span class=&quot;text&quot; &gt;看官，此页面只为爬虫练习使用，都是残卷，若喜欢可以去找点高清版！&lt;/span &gt; &lt;span &gt;作者：&lt;small class=&quot;author&quot;&gt;中国传世名画&lt;/small&gt; &lt;a href=&quot;http://lab.scrapyd.cn/archives/57.html&quot;&gt;【详情】&lt;/a&gt; &lt;/span&gt; &lt;p&gt;&lt;/p&gt; &lt;div class=&quot;tags&quot;&gt; 标签： &lt;a class=&quot;tag&quot; href=&quot;http://lab.scrapyd.cn/tag/%E8%89%BA%E6%9C%AF/&quot; &gt;艺术&lt;/a &gt;，&lt;a class=&quot;tag&quot; href=&quot;http://lab.scrapyd.cn/tag/%E5%90%8D%E7%94%BB/&quot; &gt;名画&lt;/a &gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;quote post&quot;&gt; &lt;span class=&quot;text&quot;&gt;下面每一幅都是上亿？你造几？&lt;/span&gt; &lt;span &gt;作者：&lt;small class=&quot;author&quot;&gt;天价世界名画&lt;/small&gt; &lt;a href=&quot;http://lab.scrapyd.cn/archives/55.html&quot;&gt;【详情】&lt;/a&gt; &lt;/span&gt; &lt;p&gt;&lt;/p&gt; &lt;div class=&quot;tags&quot;&gt; 标签： &lt;a class=&quot;tag&quot; href=&quot;http://lab.scrapyd.cn/tag/%E8%89%BA%E6%9C%AF/&quot; &gt;艺术&lt;/a &gt;，&lt;a class=&quot;tag&quot; href=&quot;http://lab.scrapyd.cn/tag/%E5%90%8D%E7%94%BB/&quot; &gt;名画&lt;/a &gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 我们需要获取到的，是以下内容： 12[{'text': '看官，此页面只为爬虫练习使用，都是残卷，若喜欢可以去找点高清版！', 'tag': ['艺术', '名画']}, {'text': '下面每一幅都是上亿？你造几？', 'tag': ['艺术', '名画']}, ] 这个 response 拥有几种解析方法，你可以使用 xpath，也可以用 css。 xpath 教程： 学爬虫利器 XPath,看这一篇就够了：这个是结合代码来讲解的 Python 神技能：六张表 搞定 Xpath 语法：这个是列出语法表的 比如使用 xpath： 1234567In [2]: response.xpath('//div[contains(@class,&quot;quote&quot;)]')Out[2]:[&lt;Selector xpath='//div[contains(@class,&quot;quote&quot;)]' data='&lt;div class=&quot;quote post&quot;&gt;\\n\\t &lt;span '&gt;, &lt;Selector xpath='//div[contains(@class,&quot;quote&quot;)]' data='&lt;div class=&quot;quote post&quot;&gt;\\n\\t &lt;span '&gt;, &lt;Selector xpath='//div[contains(@class,&quot;quote&quot;)]' data='&lt;div class=&quot;quote post&quot;&gt;\\n\\t &lt;span '&gt;, &lt;Selector xpath='//div[contains(@class,&quot;quote&quot;)]' data='&lt;div class=&quot;quote post&quot;&gt;\\n\\t &lt;span '&gt;, &lt;Selector xpath='//div[contains(@class,&quot;quote&quot;)]' data='&lt;div class=&quot;quote post&quot;&gt;\\n\\t &lt;span '&gt;] 返回的将是 Selector 的列表，Selector 的具体用法也不在本文范围内。 其实response.xpath()只是方便使用，它调用了response.selector.xpath()，也就是说 xpath 和 css 实际上是 Selector 的方法。说这个的原因在于告诉你，对于这个列表里面每一个 Selector，你都可以使用同样的方法来进行解析。 接着你就可以利用这个调试 shell 来调整你的 xpath 字符串或者 css 字符串了。 编写 Item 域items.py 里面有着你可以用的 item 类，根据你确定需要获取的字段（Field）来给它添加： 12345678910111213141516# -*- coding: utf-8 -*-# Define here the models for your scraped items## See documentation in:# https://doc.scrapy.org/en/latest/topics/items.htmlimport scrapyclass TutorialItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() text = scrapy.Field() tag = scrapy.Field() pass 解析代码我用的是 css 选择器。 123456789101112131415161718# -*- coding: utf-8 -*-import scrapyclass LabSpider(scrapy.Spider): name = 'lab' allowed_domains = ['lab.scrapyd.cn'] start_urls = ['http://lab.scrapyd.cn'] def parse(self, response): quotes= response.css('div.quote') for quote in quotes: item = items.TutorialItem() text = quote.css('.text::text') tag = quote.css('.tag::text') item['text'] = text.get() item['tag'] = tag.getall() yield item 开始爬取1$scrapy crawl 需要启动的爬虫名 -o 输出文件名（比如test.json） scrapy 会自动将得到的 item 保存到输出文件 解决导入 items 模块的问题1234567import sysimport ospath = os.path.dirname(__file__)parent_path = os.path.dirname(path)sys.path.append(parent_path)import items","link":"/posts/Scrapy_spider_1/"},{"title":"【编程练习】java简易学生管理系统","text":"上周一个数据库作业，用文件读写的方式来实现学生信息的读写，从而与数据库编程的方式进行对比。 在这个练习中，我主要是打算熟悉一下 java 的文件操作，因为我发现我学了 java 之后基本没有写过文件读写。 本文主要总结一下本练习用到的一些知识点，方便下次使用。 本文对应的 github 库 参考链接 java 输入和输出函数 java 文件和文件夹的创建 Java I/O 包 读写文件：有关各种文件流、Reader 和 Writer 之间关系的解释 java 基础知识之 FileInputStream 流 JAVA 中字符流详解 Java 实现文件随机读写-RandomAccessFile 流-文件操作（1）-Java 高级知识（4）：讲了流的原理和分类 Java 语言的输入与输出与文件处理：常用文件处理类的 API 列表 如何检查 Java 字符串并不是所有空白？ 题目 1.建两个文本文件 2.插入学生信息 3.查询学生对应的奖励 4.增删改信息 文件 1 学生基本信息 学号 姓名 性别 年龄 专业 位置 长度 2017901006 杨啸 男 21 软件工程 0 30 …… …… …… …… …… …… …… 位置：奖励文件内对应的位置 长度：奖励文件内对应的奖励字段的长度 文件 2 奖励记录学生获得的奖励 奖励 2011 校奖学金，2012 国家奖学金 2012 校优秀学生 结构 model 包 Gender 枚举类：枚举值为“男”和“女” StudentInfo 类：作为学生信息结点，存储学生信息的六个字段。后来写着写着觉得这个类名太长了，不该加 Info 后缀的，写起来怪怪的。 StudentInfoSystem 类：用于实现整个系统的逻辑功能，包括录入信息，查找信息，保存数据，读取数据等。 view 包 ConsoleMenu 类：控制台菜单类，作为与用户交互的界面。 知识点总结Gender 枚举类在录入学生性别的时候，会涉及到输入什么的问题，输入 0 或 1？输入“男”或“女”？如果用整数或者字符串都可能会产生非法数据，导致一些问题，这些问题在很久以前我拿 C++写的时候就遇到过一些。 最好的方式不是用布尔类型这种二值类型，而是使用枚举类型，因为有可能用到别的值，比如 UNSET（未设置）。 在这次练习之前，我会的 java 枚举大概是下面这样： 12345public enum Gender { MALE, FAMALE} 如同 C++枚举一样列出枚举值，然后当成常量一样使用。 后面变成了这样： 12345678910111213141516171819202122232425262728293031323334353637//Gender.javapackage model;public enum Gender { MALE(&quot;男&quot;), FAMALE(&quot;女&quot;); private String m_genderString; private Gender(String gender) { m_genderString = gender; } public String getGenderString() { return m_genderString; } /** * 根据字符串的值返回对应的枚举值 * TODO：应该可以优化成不用手动写switch的 * @param genderString * @return 返回字符串对应的枚举值，找不到则返回null */ public static Gender newGender(String genderString) { switch (genderString) { case &quot;男&quot;: return Gender.MALE; case &quot;女&quot;: return Gender.FAMALE; default: break; } return null; }} 百度了几篇博客之后（当时没收藏，找不到了），知道了枚举类一点点原理。 拿上面这个代码举例：写MALE(&quot;男&quot;)其实像是为 Gender 类的构造方法传入一个值为“男”的字符串，而默认的构造方法是没有参数的，所以你需要写一个以字符串为参数的构造方法。 为了保留下这个传入的字符串，需要定义一个字符串类型的属性；为了获取它，再定义一个 getter。 这样做的目的是，在输出学生性别时，可以调用性别属性的getGenderString()方法获取对应的字符串。 最下面那个newGender()方法则是在录入学生性别时使用。 File 类java 中的 File 类是对文件的抽象，它可以是文件，也可以是目录。 12File dir = new File(pathName);if(!dir.isDirectory()) return -1;//如果传入的不是目录字符串，则返回 它拥有的方法主要是用于检测文件的信息的，比如它是文件还是目录，是否存在，绝对路径是什么等等，它不能直接读写文件（创建倒是可以）。 读写文件得需要其他类，这一部分的类太多了，我找了挺久才找到合适的类。 FileOutputStream 类首先是保存数据到文件中。用到了这个类，它是文件输出流，以字节流的形式输出到文件。意思就是给他传入的参数是字节数组而不是字符串。不过字符串转字节数组非常简单，用字符串的getBytes()就好。 打开文件输出流： 12345678File dir = new File(pathName);if(!dir.isDirectory()) return -1;//如果传入的不是目录字符串，则返回File infoFile = new File(pathName + &quot;/StudentInfoList.csv&quot;);//学生信息文件if(!infoFile.exists()) infoFile.createNewFile();FileOutputStream infoFOS = new FileOutputStream(infoFile); 随后拼接好学生信息的字符串，转换为字节数组，传入即可： 12byte[] infoBuf = studentInfoString.getBytes();infoFOS.write(infoBuf);//写入文件 最后记得 close 1infoFOS.close(); FileReader 类和 BufferedReader 类一行一个学生信息，所以读取时打算直接 readline，需要BufferedReader类，进而需要FileReader类。 12345BufferedReader bufReader = new BufferedReader(new FileReader(infoFile));//打开缓冲字符流String tmpString = null;while((tmpString = bufReader.readLine()) != null) {} 因为基本信息文件中保存的是奖励在奖励文件中的位置与长度，所以在读取时需要设置文件指针。 这个需要用到RandomAccessFile类。 1RandomAccessFile randomAccessFile = new RandomAccessFile(rewardFile, &quot;r&quot;);//打开随机读写 设置文件指针到指定位置，读取对应长度的字节。 12345//从Reward文件中读取奖励信息randomAccessFile.seek(position);byte[] tmpBytes = new byte[1024];randomAccessFile.read(tmpBytes,0, rewardLen);//读取指定长度的奖励信息String rewardString = new String(tmpBytes); 写到这里我还遇到了一个问题，就是读取到字符串后，无法判断字符串是否为空，如果用rewardString.equals(&quot;&quot;)或者``rewardString.isEmpty()`，发现字符串的长度是和我设置的缓冲区大小有关的。虽然全部是空白，但是并不为空字符串。用长度判断也不行。 后来找到了一个方法： 1String rewardString = new String(tmpBytes).trim();//转换为字符串 trim()可以去掉首尾空白，那么 1024 长度的空字符串就会变成 0 长度的普通的空字符串，就可以用刚刚的方式来判断学生是否有奖励了。 录入学生信息java 的控制台输入我也是没弄过，这次就来试试。 会了之后发现蛮简单的。创建一个Scanner对象，传入源输入流，要从控制台输入，所以输入流设置为System.in。 1Scanner scanner = new Scanner(System.in); 需要读取一行数据，可以使用next()或者nextLine()方法，区别详情见百度 录入普通字符串搞定： 12345System.out.println(&quot;请输入学生的学号&quot;);String studentId = scanner.nextLine();System.out.println(&quot;请输入学生的姓名&quot;);String name = scanner.nextLine(); 录入性别则需要判断合法性（其实上面的学号，姓名也需要判断合法性，不过不是本次练习的核心，就没弄了） 1234567String genderString = &quot;&quot;;Gender gender = null;do { System.out.println(&quot;请输入学生的性别,输入\\&quot;男\\&quot; 或者\\&quot;女\\&quot;&quot;); genderString = scanner.nextLine(); gender = Gender.newGender(genderString);}while(gender == null); 这里用了一个 do-while 循环，如果输入的不是枚举类里面有的值，就要求再次输入。 接着是年龄，年龄是一个正整数，需要nextInt()来获取整数，如果输入的不是整数，就会抛出异常。处理完这个异常之后继续要求输入，直到输入正确的年龄为止。 12345678910111213141516System.out.println(&quot;请输入学生的年龄&quot;);int age = 0;while (true) { try { age = scanner.nextInt(); if(age&lt;=0) { System.out.println(&quot;年龄必须是正数&quot;); } else { break; } } catch (Exception e) { System.out.println(&quot;年龄必须是整数&quot;); scanner.next();//清空错误数据 }} 在输入完整数类型的年龄后，需要输入字符串类型的专业了，这里会遇到和 C++输入一样的情况，那就是你还没输入就当你输入了，最后得到的是空字符串。这是因为在输入整数后按下回车键确定时，这个换行符还留存在输入缓冲区，下一个nextLine()将其当成了结束标志，从而结束字符串的输入。所以需要清空一下缓冲区，清空方式就是读取一个值并丢弃： 1234scanner.nextLine();//清除缓冲区空行System.out.println(&quot;请输入学生的专业&quot;);String major = scanner.nextLine(); 最后是录入学生的奖励，这个部分加深了我对“String 的相等比较不能用==而要用equals()”的知识点的印象。 12345678910System.out.println(&quot;请输入学生的专业&quot;);String major = scanner.nextLine();System.out.println(&quot;请输入学生的奖励，每输入完一项换行，输入\\&quot;done\\&quot;结束输入&quot;);String rewardString = &quot;&quot;;Vector&lt;String&gt; reward = new Vector&lt;String&gt;();do { rewardString = scanner.nextLine(); if(!rewardString.equalsIgnoreCase(&quot;done&quot;)) reward.add(rewardString);} while (!rewardString.equalsIgnoreCase(&quot;done&quot;)); 核心代码保存数据到文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * 保存到文件中 * @param pathName 数据文件所在的路径字符串 * @return 保存的记录数，如果出错返回-1 */public int saveData(String pathName) { try { File dir = new File(pathName); if(!dir.isDirectory()) return -1;//如果传入的不是目录字符串，则返回 File infoFile = new File(pathName + &quot;/StudentInfoList.csv&quot;);//学生信息文件 File rewardFile = new File(pathName + &quot;/Rewards.csv&quot;);//学生奖励文件 if(!infoFile.exists()) infoFile.createNewFile(); if(!rewardFile.exists()) rewardFile.createNewFile(); FileOutputStream infoFOS = new FileOutputStream(infoFile); FileOutputStream rewardFOS = new FileOutputStream(rewardFile); int curPosition = 0;//“奖励”文件指针当前位置 for(StudentInfo studentInfo:m_studentInfoList) { String studentInfoString = String.format(&quot;%s,%s,%s,%d,%s,&quot;, studentInfo.getStudentId(), studentInfo.getName(), studentInfo.getGender().getGenderString(), studentInfo.getAge(), studentInfo.getMajor() ); String rewardString = String.join(&quot;,&quot;, studentInfo.getReward());//拼接奖励字符串 if(!rewardString.isEmpty()) { //奖励字符串不为空，则添加换行符 rewardString += &quot;\\n&quot;; } byte[] rewardBuf = rewardString.getBytes();//转换为字节数组 studentInfoString += String.format(&quot;%s,%s\\n&quot;, curPosition,rewardBuf.length); curPosition += rewardBuf.length;//计算下一个位置 byte[] infoBuf = studentInfoString.getBytes(); //写入文件 infoFOS.write(infoBuf); rewardFOS.write(rewardBuf); } System.out.printf(&quot;成功保存%d条记录到以下文件中：\\n[%s]\\n[%s]\\n&quot;, m_studentInfoList.size(), infoFile.getCanonicalPath(), rewardFile.getCanonicalPath() ); rewardFOS.close(); infoFOS.close(); return m_studentInfoList.size(); } catch (IOException e) { e.printStackTrace(); } return 0;} 从文件中加载数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * 从文件中加载 * @param pathName 数据文件所在的路径字符串 * @param clearFlag 是否清空内存中原有数据 * @return 读取的记录数，如果出错返回-1 */ public int loadData(String pathName,boolean clearFlag) { try { if(clearFlag) m_studentInfoList.clear(); File dir = new File(pathName); if(!dir.isDirectory()) return -1;//如果传入的不是目录字符串，则返回 File infoFile = new File(pathName + &quot;/StudentInfoList.csv&quot;);//学生信息文件 File rewardFile = new File(pathName + &quot;/Rewards.csv&quot;);//学生奖励文件 BufferedReader bufReader = new BufferedReader(new FileReader(infoFile));//打开缓冲字符流 RandomAccessFile randomAccessFile = new RandomAccessFile(rewardFile, &quot;r&quot;);//打开随机读写 String tmpString = null; int counter = 0; while((tmpString = bufReader.readLine()) != null) { //按行读取 String[] infoStrings = tmpString.split(&quot;,&quot;);//按照分隔符分割 if(infoStrings.length != 7) { return -1;//如果字段数对不上，说明文件格式有问题 } //从StudentInfo文件中读取学生信息 String studentId = infoStrings[0]; String name = infoStrings[1]; Gender gender = Gender.newGender(infoStrings[2]); if(gender == null) return -1; int age = Integer.parseInt(infoStrings[3]); String major = infoStrings[4]; long position = Long.parseLong(infoStrings[5]); int rewardLen = Integer.parseInt(infoStrings[6]); //从Reward文件中读取奖励信息 randomAccessFile.seek(position); byte[] tmpBytes = new byte[1024]; randomAccessFile.read(tmpBytes,0, rewardLen);//读取指定长度的奖励信息 String rewardString = new String(tmpBytes).trim();//转换为字符串 Vector&lt;String&gt; rewardList = null; if(!rewardString.isEmpty()) { //如果奖励不为空则添加 rewardList = new Vector&lt;String&gt;(); String[] rewardArr = rewardString.split(&quot;,&quot;); for(String reward : rewardArr) { rewardList.add(reward); } } StudentInfo newStudentInfo = new StudentInfo(studentId, name, gender, age, major, rewardList); m_studentInfoList.add(newStudentInfo); counter++; } bufReader.close(); randomAccessFile.close(); return counter; } catch (Exception e) { e.printStackTrace(); return -1; } }","link":"/posts/java_simple_studentInfoSystem/"},{"title":"记第二次重装系统","text":"折腾了三个多小时终于把 win10 重装好了，这是我第二次自己装系统。 本文记录了我这次重装系统的过程，以及一些从中学到的新知识，供参考。 参考链接 【装机教程】超详细 WIN10 系统安装教程，官方 ISO 直装与 PE 两种方法 定制 chocolatey 安装路径 起因第一次重装用的是一键装机的软件做的 U 盘，捆绑了一大堆东西，而且装完还是什么都不明白，啥也没学到，装的还是阉割版的企业版（不确定是不是，因为我现在装好专业版后发现功能似乎比原来多） 这一次重装的起因是：我弟将家里的台式机从 win7 升级到 win10。他在 b 站找到了一个讲得非常详细的装系统教程，并且成功自己装好了系统。 我也看了一下那个教程，光是看完视频我就觉得收获颇多，比第一次自己动手装系统学到的还多。学到了 pe 是什么，以及装系统的一些原理。 当时我就给自己以前买的 16gU 盘里面装了一个 pe，并尝试从 U 盘启动以打开 pe。不同于第一次，这一次我对里面的东西都有了一些了解，不是完全抓瞎，开始研究里面每个东西是干啥的。非常有成就感。 玩了一下 pe 之后就退了回到 win10，虽然也有安装包，不过我还是不敢轻易装，还是怕自己吧电脑折腾坏了，等到下次做好准备再说。 这周五我觉得就是合适的时机了，晚上九点钟将系统先用 dism++备份好，在幕布（可以在网页端登录）列好需要重新安装的软件，准备开始了。 开始操作在操作开始之前，我先总结一下有关的概念 什么是 PE 系统下面来自百度百科： Windows Preinstallation Environment（Windows PE），Windows 预安装环境，是带有有限服务的最小 Win32 子系统，基于以保护模式运行的 Windows XP Professional 及以上内核。它包括运行 Windows 安装程序及脚本、连接网络共享、自动化基本过程以及执行硬件验证所需的最小功能。 简单来说，PE 就是一个小型的 windows 系统，去掉了一切不必要的功能，将体积缩小到能够装进 U 盘里面运行（当然并不是在 U 盘里面直接运行）。 电脑可以选择从哪个磁盘来启动，如果你插上了 U 盘，也可以选择从 U 盘启动，从而启动 U 盘中存放的 PE 系统。 两种安装方式如同参考视频里面说的，你可以用官方镜像来安装，也可以用 PE 系统来辅助安装。 第一种方法就是到微软官网去，用官网的启动 U 盘制作器把你的 U 盘制作成启动 U 盘，这样你从 U 盘启动电脑之后，就会自动进入安装程序。 第二种方法是下载系统的 ISO 镜像文件（其实就是一个比较特别的压缩包），并在 U 盘里面安装 PE 系统，把 ISO 文件放进 U 盘。从 U 盘启动时，首先进入 PE 系统，在这里可以对现有的磁盘进行操作，你可以用 PE 里面自带的分区工具来提前分区，然后装载放在 U 盘的 ISO 文件，进行安装。 详细的内容看参考视频，UP 主讲得非常非常好！ 安装系统开始安装之后把系统盘清了准备安装结果出现错误，我开始慌了。 退出安装回到 pe 桌面，在家里找出以前买的移动硬盘，把文件啥的给拷进去（之前认为装系统只清系统盘就够了，但现在的情况似乎要全部清掉，不管怎样先备份），同时使用 pe 里面的 dism++来尝试恢复之前的备份。 使用 PE 系统安装的好处就体现出来了，如果我用的是第一种方法，那么一旦主系统被删了，那么我就没办法补救了，连进去拷贝数据都做不到。 也许是我使用方式不对，系统并没有恢复，拔掉 U 盘后无法进入系统。那就只好继续装了。 由于我以及备份好了数据，所以将分区全部清掉，重新分区。 我现在有一块 1T 的机械硬盘和自己加装的 256g 的固态硬盘。 固态硬盘两个区： 系统 C 盘 加速区 S 盘 机械硬盘四个区 虚拟机 Z 盘（未装 SSD 前的 C 盘，后来被我用来放 virtualbox 的虚拟磁盘） 文件 F 盘 软件 D 盘 娱乐 E 盘。 分区确实挺多的，足足六个分区，而其中还有功能重复的盘。根据我现在的使用情况，我分成了三个分区：系统 C 盘，软件 D 盘，文件 F 盘。 F 盘是我之前最常用的盘，正因为之前把所有资料都放在这里，备份起来非常方便。 之后就很顺利的照着视频完成了安装。 chocolatey 重装软件重装软件我使用的是 chocolatey，这个是我最近找到的一个工具，它是一个 windows 包管理工具，类似于 Linux 上面的 apt，不用关心它从哪里下载，安装到哪里，有哪些依赖，一个命令搞定安装。 如果你不想让它默认安装在 C 盘，那么你得先在环境变量里面添加一个变量ChocolateyInstall，值为你指定的它的安装路径。 如果你不想让它将下载的软件放在 C 盘，那么你也得添加一个环境变量ChocolateyToolsLocation，值为你指定的工具安装路径。 然后去它的官网下载它。（如果先安装再修改环境变量会出现一系列问题，别问我怎么知道的） 下载它的方式是：复制官网给出的下载命令，以管理员身份打开 powershell，运行这条安装命令，它就会自动安装到你之前指定的位置。 在 cmd 或者 powershell 输入以下命令以确认安装成功： 1$choco -? 常用指令： 列出/查询软件包 12$choco list 软件包名$choco search 软件包名 查询本地已安装的软件包（-lo 就是 local 的缩写） 1$choco list -lo 安装某个软件包 1$choco install 软件包名 卸载某个软件包 1$choco uninstall 软件包名 升级某个软件 1$choco upgrade 软件包名 更多的命令可以去官网的文档查看，具体有哪些包可以去这里查看 我用 chocolatey 安装的软件比如我要安装 chrome，可以用这个命令： 1$choco install googlechrome 下面列出我下载的软件： chrome：谷歌浏览器 git choco install git.install cmder：很好用的终端，可以代替系统自带的 cmd 和 powershell 来用 choco install cmder potplayer：很好用的视频播放器 choco install potplayer wechat：微信 choco install wechat github-desktop choco install github-desktop vscode choco install vscode eclipse choco install eclipse jdk8 choco install jdk8 python choco install python steam wps-office-free 英文版的 由于无法使用之前的账号登录就换成中国版了 winrar putty anki obs","link":"/posts/Reinstall_win10/"},{"title":"【自我管理系统】归档文件","text":"记录 2020 年第 12 周的文件归档 起因3 月 13 日也就是上周五晚上，我重装了一次系统，将电脑上存的各种乱七八糟的资料备份到移动硬盘后清空所有磁盘，借此机会整理一下混乱的电脑。 在这次之前，我没有系统性地整理过整个电脑的文件，偶尔整理也只是对部分文件进行分类，并没有制定出文件产生和保存的合适规则（规则还是有的，就是比较混乱） 步骤首先，我无法抽出一整天的时间专门用于整理电脑文件，从以前的经验来看这样效果也不好，不能一次性将所有事情都想到，于是我将整理时间设置为一周。 我现在的磁盘分区状况：系统 C 盘，软件 D 盘，文件 F 盘。C、D 盘都在固态硬盘上以加快速度，F 盘在 1T 的机械硬盘上面。 按照我以前的做法，首先 F 盘作为我的资料盘，所有的个人资料都放在这个盘中，包括“视频”、“文档”等用户文件夹，这在上周五装系统手动备份文件时带来了很多好处，我只需要将 F 盘中的东西全部带走就好，不需要理会其他盘。这次也是这么做。 准备由于整理工作需要持续几天，所以我在 F 盘下面建了一个文件夹叫做“Inbox”，用于存放所有我需要整理的文件，第一天的状况大致如下： F： Inbox 我所有的文件夹，由于我也不记得，就不列出来了 整理 Archive 文件夹首先需要整理我的 Archive（归档）文件夹，这个文件夹在重装之前是用于存放我所有以及完成的项目文件的，大致分为学业相关以及编程相关两大类，下面细分为很多小类，很多重叠，举例如下： Archive college_archive 各种比赛 专业课 xx 课 xx 课课设 190627.zip xx 课实验 190514.zip xy 课 成就 杂项 develop_archive cpp java python asm web vb 按照以前的规则，其中每个项目的相关文件都被打包成压缩文件，并起名为“科目+名称+归档日期”，这为我进一步进行整理归类提供了便利。 由于存储这些项目文件就是为了以后在想找的时候方便查找，我打算不再按照内容进行细分，而是主要按照时间顺序来进行分类。 划分到月太细，于是按照年份来划分。首先建立一个文件夹名为“0000”，充当一个“Inbox”的作用，将所有文件抽出来放进去。随后建立“2017”、“2018”、“2019”、“2020”四个文件夹，按照文件名中的归档日期归类。 有一些项目文件是同一个科目的，比如 java 面向对象实验和 java 面向对象课设，那么就在年份文件夹中建立一个新的科目文件夹存放同类文件。一个科目只有一个文件那种就放在年份文件夹根目录下不用动。 这样分类好了之后，和以前一样，用坚果云将 Archive 设置为同步文件夹，由于只是移动文件的位置，没有消耗上传流量。 需要查找某个文件时，使用 Listary 进行查找即可，或者手动进入文件夹查找，由于是按照时间分类，不用担心按照内容分类时找不到具体分类，节约了归档时间。 删除 Develop 文件夹重装之前，我在 F 盘下设立了一个名为”Develop”的文件夹，用于存放所有编程项目，按照编程语言来分类，在彻底不更新编程项目后，将其打包并放入 Archive 文件夹。 当时分类也很细，大致是这样的： Develop cpp_develop cpp_test：临时文件夹，里面的文件都可以删 cpp_example:用于学习某个知识点的，别人的项目 cpp_exercise:用于练习的项目 cpp_project：课设、实验啥的都放在这里 cpp_archive.lnk：指向 Archive 文件夹对应文件夹的快捷方式（建立后基本没用过） java_develop asm_develop web_develop vb_develop python_develop test 其他的文件夹里面都是类似的情况，大量冗余的文件夹，很少用到。 我这样做了很久之后，发现这种做法会导致 Develop 文件夹中的项目文件夹不断累积（当时懒得归档后面忘记归档），而且要找到自己正在写的项目非常麻烦。一个治标不治本的方法是，建立一个 Buffer 文件夹，用于存放正在写的项目的文件夹的快捷方式。 这次干脆取消这个 Develop 文件夹，将正在写的项目都放在 Buffer 文件夹中，以及不再写的项目写完即打包归档，如果累积着不归档，Buffer 将会越来越满，使得我不会忘记归档。而且不按照编程语言分类，免得出现大量冗余文件夹，不便于管理。 整理 Resource 文件夹Resource 文件夹是我的资源文件夹，里面放的都是囤积的各种学习资料，比如 c#电子书、日语视频、软件安装包等（基本没看过，但是好歹是以前得到的资源，删了浪费啊） 按照用途分为几类： 软件安装包 便携安装包：可以装在 U 盘里面的免安装轻便实用小工具，比如 everthing 其他安装包 图标包 囤积的学习资源：其他所有的资源，懒得分类了，分了也没用，反正只是囤着 整理 bilibili 文件夹作为一名 UP 主，自然有一个存放自己成品视频的文件夹。 有了 Archive 文件夹的经验，也是取消了按照内容分类，改为按照年份来分类。 整理视频的时候挺感慨的，居然已经录了那么多视频了，还是在已经丢失了很多视频原文件的情况下。 由于视频一般都是几百 M 几百 M 的，自然全部需要压缩。我用到的是小丸工具箱，这东西太好用了，压缩率贼高，1G 的东西能给你压成几十 M，而且画质没啥影响。 压缩后仍然很大，不能放进 Archive 文件夹用坚果云来同步，坚果云每个月的上传流量是 1G。这个时候就可以用到百度云盘了。 百度云盘同步功能要会员了，所以就把 2018 年和 2019 年的文件夹直接上传上去，反正也不会往里面加文件了。 整理私人文件还有一些私人文件，比如日记、视频、照片、自己中二时期写的小说等，具有一定的隐私性。上一次整理的时候我一直没有好好地分类，只是丢在一个名为”私人文件夹”的文件夹内，一直保存在本地。 我一直不敢将这些隐私的东西放到云端，甚至买了一个移动硬盘专门备份。 这次重装后，意识到这些东西必须备份到云端，否则不安全。并且对于坚果云还是比较信任的，所有将私人文件夹同步到坚果云。 当然，不是直接备份。而是重新开始使用 VNote（当初开始用 Typora 之后就因为颜值问题换了它，但是后来发现还是 VNote 好用）来管理我的日记。并将文件同步到坚果云。绝佳配合。 不过视频、照片等还没处理好，不太信任百度云。 总结现在我的磁盘结构大致如下：C 盘系统盘，D 盘软件盘，F 盘为我的资料盘和工作盘。 F 盘里面有如下几个文件夹： Archive：按照年份分类的已经完成的项目的归档文件。最为重要，因为都是我努力的成果。坚果云同步。 Inbox：收集箱，用 DropIt 快速收集文件到 Inbox 中，有空的时候再将其处理分类，目前通过腾讯桌面管家独立版将其从 F 盘根目录映射到桌面，以便快速收集以及处理。最不重要，应当保持本文件夹经常为空。 Buffer：存放正在进行的项目的相关文件，完成后立即进行打包归档，或者放入 Inbox 稍后处理。中等重要。 Blog：存放 hexo 博客源代码，放在 F 盘根目录方便快速查找。不太重要，且丢失后可找回，在 github 私有库托管 MyNotebook：VNote 笔记本文件夹。重要，里面有日记，可以删除但是不能给别人看到。 UserFolder：用户文件夹，例如：视频、音乐、下载、图片、文档等系统用户文件夹被我移动到 F 盘下。Bilibili 文件夹放在视频文件夹中 Resource：资源文件夹，我囤积的资源。不太重要，因为不咋用。 System backup：系统备份","link":"/posts/self-management-archive/"},{"title":"【作业总结】python写的DES替代算法的gui小工具","text":"信息安全的上机作业：实现 DES 替代算法，不限语言，可以调库 github 库传送门 参考链接 python3 bytes 与 hex 字符串互转 对于 Python 中的字节串 bytes 和字符串以及转义字符的新的认识 python 常用的十进制、16 进制、字符串、字节串之间的转换 Python GUI 之 tkinter 窗口视窗教程大集合（看这篇就够了） pyDes 库使用 python 来写最简单，安装一个 pyDes 库即可。 1$pip install pyDes 我采用的是默认的 ECB（Electronic CodeBook 电码本模式）。下面介绍的 API 也都是用最简单的版本。 首先传入密钥创建一个 des 对象： 1234import pyDeskey = 'Ts%uN#w4' # 密钥需要8个字符，即64bitdes = pyDes.des(key) 加密1234# 两种填充方式des.encrypt(plain_text,pad=' ',padmode=pyDes.PAD_NORMAL) # 如果用默认模式，需要设置pad参数des.encrypt(plain_text,padmode=pyDes.PAD_PKCS5) # plain_text是明文,padmode是填充模式 如果只传入明文，就需要注意明文的长度问题； 在PAD_NORMAL模式下设置 pad 参数的话，就代表使用 pad 的字符来填充明文不够长度的部分； 在PAD_PKCS5模式下不能设置 pad 参数。一般用这个比较好。 解密1des.decrypt(cipher_text) 设计思路MyDes 类先写一个 MyDes 类将原本的 pyDes.des 类封装一下。这样可以加一些自己的方法，而且不用担心会不小心覆盖掉原来的方法。 一开始写的类方法： 构造方法 加密：传入明文 bytes，返回密文 bytes 解密：传入密文 bytes，返回明文 bytes 随机生成密钥：随机生成 8 个字符的字符串 后来加上的类方法： 将字节串转换为十六进制字符串 将十六进制字符串转换为字节串 MyDesGui 类再写一个 MyDesGui 类，专门用于图形界面显示。不过现在回过头来看，它还负责了本来应该由 MyDes 类负责的逻辑，这是一个需要改进的地方 图形界面相关类方法： 构造方法 初始化控件 显示密文：传入密文 bytes，在控件上显示密文 显示明文：传入明文 bytes，在控件上显示明文 以下类方法本来应该放在 MyDes 类里面实现，在这里面只是简单地调用 MyDes 的类方法的，但是现在是直接在这里面实现对应的算法，需要改进 des 加密 des 解密 二重 des 加密 二重 des 解密 三重两密 des 加密 三重两密 des 解密 三重三密 des 加密 三重三密 des 解密 二重 Des 算法一开始的 DES 加密解密搞定了之后，二重 DES，三重 DES 就比较简单了。 设 C 为密文，P 为明文，E_k 为以 k 为密钥的 DES 加密，D_k 为以 k 为密钥的 DES 解密。 二重 DES 的加密：C = E_k2(E_k1(P)) 二重 DES 的解密：P = D_k1(D_k2(C)) 三重两密 Des 算法加密：C = E_k1(D_k2(E_k1(P))) 解密：P = D_k1(E_k2(D_k1(C))) 三重三密 Des 算法加密：C = E_k3(D_k2(E_k1(P))) 解密：P = D_k1(E_k2(D_k3(C))) 遇到的问题bytes 和字符串之间的转换“损耗”问题描述pyDes 库的加密解密的输入输出都是 bytes 类型的字节串，要如何将其正确地显示在编辑框上，以及从编辑框上读取呢？ 可能你会说，python 将 bytes 转换成 str 不是很简单吗？ str 转换成 bytes： 1text_b = text.encode() # 如果出现问题，encode里面可以加上errors='ignore'参数 bytes 转换成 str： 1text = text_b.decode() # 如果出现问题，decode里面可以加上errors='ignore'参数 没错，确实很简单，但是这种方式有一个问题，转换的过程中可能会有一些“损耗”。 比如下面这段代码，预期结果是输出两个字节串，一个密文字节串，一个明文字节串： 123456789101112131415161718import pyDesplain_text = '你好世界helloworld'key = 'Ts%uN#w4' # 密钥需要8个字符，即64bitdes = pyDes.des(key)# 从编辑框获取明文字符串plain_textplain_text_b = plain_text.encode()cipher_text_b = des.encrypt(plain_text_b,padmode=pyDes.PAD_PKCS5)print(cipher_text_b)# 转换为字符串以显示在编辑框cipher_text = cipher_text_b.decode()# 从编辑框获取密文字符串cipher_text_b = cipher_text.encode()plain_text_b = des.decrypt(cipher_text_b)print(plain_text_b) 但是实际上的输出是： 123456789101112b'\\x80$-\\xd1\\x07\\x1e=k+\\xac\\x00\\xb4\\xbb\\x19\\xa6\\xf6\\xd7\\x8f\\x91\\x86\\xa0\\x9e.\\x05'24---------------------------------------------------------------------------UnicodeDecodeError Traceback (most recent call last)&lt;ipython-input-1-c98230c2df1e&gt; in &lt;module&gt; 11 print(len(cipher_text_b)) 12 # 转换为字符串以显示在编辑框---&gt; 13 cipher_text = cipher_text_b.decode() 14 15 # 从编辑框获取密文字符串UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte 这是因为，加密后的字节串是不符合 utf-8 的编码格式的。我一开始想加个 ignore 选项忽略过去： 1234567891011121314151617181920import pyDesplain_text = '你好世界helloworld'key = 'Ts%uN#w4' # 密钥需要8个字符，即64bitdes = pyDes.des(key)# 从编辑框获取明文字符串plain_textplain_text_b = plain_text.encode()cipher_text_b = des.encrypt(plain_text_b,padmode=pyDes.PAD_PKCS5)print(cipher_text_b)print(len(cipher_text_b))# 转换为字符串以显示在编辑框cipher_text = cipher_text_b.decode(errors='ignore')# 从编辑框获取密文字符串cipher_text_b = cipher_text.encode()plain_text_b = des.decrypt(cipher_text_b)print(plain_text_b)print(plain_text_b.decode()) 输出就会变成下面这样： 123456789101112131415161718192021222324252627b'\\x80$-\\xd1\\x07\\x1e=k+\\xac\\x00\\xb4\\xbb\\x19\\xa6\\xf6\\xd7\\x8f\\x91\\x86\\xa0\\x9e.\\x05'24---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-2-63175c965c0a&gt; in &lt;module&gt; 16 17 cipher_text_b = cipher_text.encode()---&gt; 18 plain_text_b = des.decrypt(cipher_text_b) 19 print(plain_text_b) 20 print(plain_text_b.decode())c:\\python38\\lib\\site-packages\\pyDes.py in decrypt(self, data, pad, padmode) 677 if pad is not None: 678 pad = self._guardAgainstUnicode(pad)--&gt; 679 data = self.crypt(data, des.DECRYPT) 680 return self._unpadData(data, pad, padmode) 681c:\\python38\\lib\\site-packages\\pyDes.py in crypt(self, data, crypt_type) 570 if len(data) % self.block_size != 0: 571 if crypt_type == des.DECRYPT: # Decryption must work on 8 byte blocks--&gt; 572 raise ValueError(&quot;Invalid data length, data must be a multiple of &quot; + str(self.block_size) + &quot; bytes\\n.&quot;) 573 if not self.getPadding(): 574 raise ValueError(&quot;Invalid data length, data must be a multiple of &quot; + str(self.block_size) + &quot; bytes\\n. Try setting the optional padding character&quot;)ValueError: Invalid data length, data must be a multiple of 8 bytes. 转换是成功了，但是解密时失败了，因为在转码时忽略了一些字节，导致长度对不上了。 我在写代码的时候遇到的就是这个问题，当局者迷，想不到是哪里出现了错误，单步调试发现是中间出现了“损耗”。在写本文总结的时候，才发现问题所在。可见总结复盘是多么重要，不写总结的话，这段调试时间就白费了。 解决方案换一种方式将字节串转换为字符串，也就是不让字节串转换为每个字节对应的字符组成的字符串，而是直接将其编码显示出来，比如显示成： 1b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe4\\xb8\\x96\\xe7\\x95\\x8chelloworld' 而不是将其直接显示成对应字符的形式，即 print 函数的显示效果。 不过这种方式仍然不能解决从字符串转换为字节串的问题。 最后在一个博客（传送门）里面找到了比较好用的转换函数，也比较容易看懂： 十六进制字符串转 bytes 12345678910'''hex string to byteseg:'01 23 45 67 89 AB CD EF 01 23 45 67 89 AB CD EF'b'\\x01#Eg\\x89\\xab\\xcd\\xef\\x01#Eg\\x89\\xab\\xcd\\xef''''def hexStringTobytes(str): str = str.replace(&quot; &quot;, &quot;&quot;) return bytes.fromhex(str) # return a2b_hex(str) bytes 转十六进制字符串 123456789101112'''bytes to hex stringeg:b'\\x01#Eg\\x89\\xab\\xcd\\xef\\x01#Eg\\x89\\xab\\xcd\\xef''01 23 45 67 89 AB CD EF 01 23 45 67 89 AB CD EF''''def bytesToHexString(bs): # hex_str = '' # for item in bs: # hex_str += str(hex(item))[2:].zfill(2).upper() + &quot; &quot; # return hex_str return ''.join(['%02X ' % b for b in bs]) 这个博主采用了空格分隔的十六进制字符串，非常好地解决了我的需求，转换时不会损耗，显示在编辑框时也不会乱码。 解密后填充字符仍然存在问题描述12345678910111213141516171819import pyDesplain_text = '你好世界helloworld'print(plain_text)key = 'Ts%uN#w4' # 密钥需要8个字符，即64bitdes = pyDes.des(key)# 从编辑框获取明文字符串plain_textplain_text_b = plain_text.encode()cipher_text_b = des.encrypt(plain_text_b,padmode=pyDes.PAD_PKCS5)# 转换为字符串以显示在编辑框cipher_text = bytesToHexString(cipher_text_b)# 从编辑框获取密文字符串cipher_text_b = hexStringTobytes(cipher_text)plain_text_b = des.decrypt(cipher_text_b)print(plain_text_b.decode()) 输出： 12你好世界helloworld你好世界helloworld\u0002\u0002 在解密后的输出结果中会出现几个乱码，后面这几个乱码是因为加密时进行了填充，而解密时没有去掉。 解决方案我采用的是将填充字符换成空格，然后在显示的时候用 strip 去掉空白。但是刚刚发现还有更好的方法： 12345678910111213141516171819import pyDesplain_text = '你好世界helloworld'print(plain_text)key = 'Ts%uN#w4' # 密钥需要8个字符，即64bitdes = pyDes.des(key)# 从编辑框获取明文字符串plain_textplain_text_b = plain_text.encode()cipher_text_b = des.encrypt(plain_text_b,padmode=pyDes.PAD_PKCS5)# 转换为字符串以显示在编辑框cipher_text = bytesToHexString(cipher_text_b)# 从编辑框获取密文字符串cipher_text_b = hexStringTobytes(cipher_text)plain_text_b = des.decrypt(cipher_text_b,padmode=pyDes.PAD_PKCS5) # 这里也添加填充选项print(plain_text_b.decode()) 直接在解密时也添加相同的填充选项就行了。 其他知识tkinter启动一个窗口： 123import tkinter as tkroot = tk.Tk()root.mainloop() 创建标签框架： 12des_LF = tk.LabelFrame(self.root, text='DES')des_LF.grid(row=0, column=0) 创建标签： 1tk.Label(des_LF, text='明文').grid(row=0, column=0) 创建编辑框并与变量双向绑定： 12plain_text_var = tk.StringVar() # 明文tk.Entry(des_LF,textvariable=self.plain_text_var).grid(row=0,column=1) 创建按钮并与响应函数绑定，其中用到了 lambda 函数： 123tk.Button(des_LF,text='DES加密', command=lambda:self.encrypt(self.key_var.get(),isShow=True) ).grid(row=0,column=2,stick=tk.W+tk.E) 显示对话框： 12import tkinter.messagebox as tkmtkm.showwarning('注意','密钥长度必须为8个字符，即64bit')","link":"/posts/3043391445/"},{"title":"记第二次博客切换主题以及主题优化","text":"2019 年 2 月 28 日的时候第一次换了主题，从从shana（夏娜）换成了NexT，当时换主题的原因是：虽然二次元主题蛮好看的我挺喜欢，但是不实用，功能缺乏，而 NexT 作为一个使用人数非常多的主题，功能非常齐全，所以决定换主题。 2020 年 4 月 5 日，也就是今天，我花了一个上午的时间将个人博客的主题换成闪烁之狐的Matery主题，既美观功能又丰富。 参考链接 Matery 主题 Hexo 博客优化：在 Next 主题中设置进阶版 Live2D 看板娘————拒绝踩坑！！！！ 进阶版 Live2D 的 github 库 换主题切换的方法和其他主题没有什么差别，下载或者 clone 主题到 hexo 文件夹的 theme 目录下，再在根目录的配置文件中切换即可。重点说一下我遇到的问题。 本地搜索用 Next 主题的时候，我添加了搜索插件，可以进行站内搜索，但是切换了主题之后，却不可以用了。虽然这个主题的右上角自带搜索按钮。 README 里面关于这一点是这样说的： 本主题中还使用到了 hexo-generator-search 的 Hexo 插件来做内容搜索，安装命令如下： 1npm install hexo-generator-search --save 在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项： 123search: path: search.xml field: post 需要安装这么一个插件，可是我已经安装了不是吗？切换主题前还可以用的呀！ 我去看了一下主题作者的博客以及也使用这个主题的朋友的博客，他们的站内搜索是可以用的。 后来才发现，next 主题里面安装的插件是hexo-generator-searchdb而不是hexo-generator-search，末尾差了两个字母…… 这两个主题支持的插件不一样，但是名字相似，而且配置部分里面都有上述的内容，所以很容易掉坑里。 把原本的搜索插件删除了就行了。 1$npm uninstall hexo-generator-searchdb 升级 live2d 看板娘原本使用的 live2d 插件是hexo-helper-live2d，模型是koharu 1$npm install --save hexo-helper-live2d 之前就得知有进阶版的 live2D，不过一直没去弄，这次趁着切换主题，顺便将她升级一下。 这方面资料不太多，只搜到这么一篇教程：Hexo 博客优化：在 Next 主题中设置进阶版 Live2D 看板娘————拒绝踩坑！！！！ 这篇教程教的是如何在 Next 主题下设置，改成 Matery 主题的也可以。以下步骤相同的部分直接引用自原教程 第一步 下载大神项目，解压到本地博客目录的 themes/next/source 下，修改 autoload.js 文件，将其中 12const live2d_path = &quot;https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget/&quot;; 改为 1const live2d_path = &quot;/live2d/&quot;; 我这个比较新的版本的autoload.js里面开头就是这两句： 1234// 注意：live2d_path 参数应使用绝对路径const live2d_path = &quot;https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/&quot;;//const live2d_path = &quot;/live2d-widget/&quot;; 可以直接将第二句注释打开，第一句注释上： 123// 注意：live2d_path 参数应使用绝对路径//const live2d_path = &quot;https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/&quot;;const live2d_path = &quot;/live2d-widget/&quot;; 这里第二句赋值的内容需要修改为你放在 source 目录下的文件夹的名字。 比如我从 github 上面 clone 下来名字是live2d-widget-master，如果你不改文件夹名字，将其移动到themes/next/source下后，你需要将themes/next/source/live2d-widget-master/autoload.js这个文件开头声明的那个常量改为： 1const live2d_path = &quot;/live2d-widget-master/&quot;; 即 source 目录下的 live2d 文件夹的名字。 第二步 在/themes/next/layout/_layout.swing 中,标签中新增如下内容，########为你自己的 github 账号： 1&lt;script src=&quot;https://########.github.io/live2d/autoload.js&quot;&gt;&lt;/script&gt; 标签中新增如下内容：一定一定要加上依赖！！！！！ 12345&lt;script src=&quot;https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css&quot;/&gt; 我用的这个主题里面没有layout/_layout.swing这个文件，但是有layout/layout.ejs文件，其实是一样的，都说明了主题的布局 文件里面大致长这样： 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;&lt;%= config.language %&gt;&quot;&gt; &lt;%- partial('_partial/head') %&gt; &lt;body&gt; &lt;!--需要加的三条语句--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css&quot; /&gt; &lt;script src=&quot;https://ChangingSelf.github.io/live2d-widget/autoload.js&quot;&gt;&lt;/script&gt; &lt;!-- 其他的东西省略 --&gt; &lt;/body&gt;&lt;/html&gt; 注意，目前在本地用hexo s预览是看不到的，因为这一句： 1&lt;script src=&quot;https://&lt;你的用户名&gt;.github.io/&lt;你放在source目录下的文件夹名&gt;/autoload.js&quot;&gt;&lt;/script&gt; 需要引用你部署在 github 仓库里面的 js 文件，但是你现在还没有部署上去，你需要先部署到 github 才能在本地预览，或者将这个绝对链接改为相对链接，这个比较复杂，还是用现在这种方法比较好。 第三步 在主题配置文件_config.yml 中,新增如下内容： 12live2d: enable: true 想修改看板娘大小、位置、格式、文本内容等，可查看并修改 waifu-tips.js 、 waifu-tips.json 和 waifu.css。 最终效果如图： 第四步我照着这个作者的教程走就搞定了。 不过还有个问题，那就是看板娘是放在左边的，有点挡正文，右边目录处倒是有一块很适合放看板娘的空白。 这个问题在她的 github 仓库的 issue 里面找到了答案 可以在刚刚的\\themes\\matery\\source\\live2d-widget目录下面的waifu.css设置她的位置： 123456789#waifu { bottom: -1000px; left: 0; /*这个就是设置左右的*/ line-height: 0; position: fixed; transform: translateY(3px); transition: transform 0.3s ease-in-out, bottom 3s ease-in-out; z-index: 1;} 改成下面这样： 12345678910#waifu { bottom: -1000px; /*left: 0;*/ right: 100px; line-height: 0; position: fixed; transform: translateY(3px); transition: transform 0.3s ease-in-out, bottom 3s ease-in-out; z-index: 1;} 就可以了。 关于这个 left 和 right 选项的具体数值设置方式如下（vscode 给我提示的）： Specifies how far an absolutely positioned box’s right margin edge is offset to the left of the right edge of the box’s ‘containing block’. Syntax: | | auto 也就是说可以是长度、百分比、自动，这三种模式，一开始的left:0其实是百分比的形式。后面调整的right:100px表示看板娘距离右边界 100 像素（防止点不到互动按钮） 而要修改将其关掉后让看板娘重新显示的条条的样式，则需要修改下面这个： 12345678910111213141516#waifu-toggle { background-color: #fa0; border-radius: 5px; bottom: 66px; color: #fff; cursor: pointer; font-size: 12px; left: 20px; /*right: 0;*/ margin-left: -100px; padding: 5px 2px 5px 5px; position: fixed; transition: margin-left 1s; width: 60px; writing-mode: vertical-rl;} 我还是继续将它放在左边，不过将它挪出来了一点，免得我点不到。 说实话这个看板娘超可爱！ 换图床这个主题对图片的需求量大了很多，再继续用 github 图床的话担心速度慢显示效果不好。所以选择了其他图床。 最后选择了 SM.MS 图床，它是免费且无需注册就可以上传图片，这种图床缺点就是不太放心，不过这个也算是一个大图床，不用太担心它挂掉。大不了重要的图片再上传到 github 图床。 PicGo 也支持 SMMS 图床，所以图床工具也有了。 最好在 PicGo 的插件商店下载一个叫做smms-user的插件，再注册一个 SMMS 的用户获取 API 口令填进去，这样上传上去的内容自己还能找得到，还可以删除。","link":"/posts/hexo_blog_switch_theme_2/"},{"title":"博客总目录","text":"前言这是本博客站点的文章目录索引，如果你想在本站逛一逛，可以从这里开始。 如果想要搜索特定内容，请结合标签、分类和站内搜索功能。部分博客有对应的 B 站视频，以及 github 库，详见各自文章的开头传送门。 此目录并非包含本站所有文章，比如日志总结之类的不一定会放到目录。 如果觉得本站访问速度慢，可以在【友情链接】中找到托管在 gitee 的本站链接，速度会快很多 这个博客的内容以下是我的博客内容的简单分类，根据我前一次搭建博客的经验所得。 分类 内容 过程复盘 记录学习实践一个事物的过程，侧重记录与反思 知识整理 针对某一部分知识进行集中整理方便查阅，例如 API、语法、命令等 解决方案 针对遇到的某个具体问题寻找解决方案 算法理解 针对某个具体算法的理解掌握 工具使用 对于框架、软件、网站等工具的使用方法与心得经验，或是简单推荐 目录索引 定期将本博客的文章索引起来，或者整理一些有用的参考链接 日志随笔 随便写点啥心情，或者年终总结之类的 这个分类肯定会有交叉，没办法完全将它们分开，也没必要。每个分类虽然有交叉，但是也有自己的侧重。 比如过程复盘和知识整理，前者我会尽量将我探索的过程记录下来，夹杂着一些知识点，而后者会将知识点进行简单罗列便于查询。 解决方案是针对某个具体的问题编写解决步骤，而工具使用则是将使用这个工具的一些常见的问题集中解决。 日志随笔里面可能会对近期写的一些博文进行索引，但是是按照时间顺序线性串联；而目录索引则是专门索引一个系列的文章。 算法理解是针对某个具体的算法进行解析，从而达到学习的目的。 python 爬虫 python 爬虫学习笔记 1 简易爬虫：我的第一篇爬虫博客（2019-02-08），讲了一个爬取小说的简单爬虫 python 爬虫学习笔记 2 模拟登录与数据库 python 爬虫学习笔记 3 封装爬虫类 python 爬虫学习笔记 4 模拟登录函数的优化 python 爬虫学习笔记 5 爬虫类结构优化 练习利用 Scrapy 爬取 b 站排行榜：开始学 python 的 Scrapy 框架了，参考书是崔庆才的《python3 网络爬虫开发实战》。跟着教程敲完之后，又试着按照一样的逻辑去爬取了 B 站排行榜的数据。 学校信息门户模拟登录之密码加密：以前写的爬虫无法登录到学校的信息门户上去了，因为门户的新 JS 代码将表单的密码先加密了一次，再将其与别的表单数据 POST 过去。使用的是 AES 加密的 CBC 模式。当时我对密码学知识还没有太多了解，所以如果有不太对的地方欢迎留言 学校信息门户模拟登录：将登陆我的学校信息门户的部分专门封装成一个模块，需要的时候导入。 爬取微信公众号文章 1 获取文章链接：通过已有的微信公众号个人订阅号来获取某个公众号的所有文章链接。缺点是需要手动登录并将 cookies 复制过来。 爬取微信公众号文章 2 获取页面失败：其实没有获取失败，只是因为用的控制台 print 的字符有数量限制，没显示完全导致误会。 Scrapy 爬虫框架（1）一个简单的可用的爬虫：为了做一个疫情新闻爬虫而复习 Scrapy python 爬虫解析库 BeautifulSoup 速查 课设或上机作业思路分享 简易倒排索引：智能信息检索作业 java 基于 AWT 的对战小游戏：java 课设，主要内容在B 站的视频说明 MFC 习题|RGB 颜色模型演示程序：计算机图形学的某个选做课后习题 【课设总结】基于 LAN 的即时通信软件：python 的 tkinter 程序，计算机网络的课设。 【作业总结】python 写的 DES 替代算法的 gui 小工具：信息安全上机作业 【作业总结】声卡数据采集及处理：计算机网络测控 【编程练习】java 简易学生管理系统：数据库基础上机练习 出于兴趣弄的 【编程练习】明日非舟抽卡模拟器（1）按照概率抽取干员星级 【编程练习】明日非舟抽卡模拟器（2）xml 文件解析 c++学生信息管理系统（一）：不是作业，是几个学期后想要试试看写原本的项目 hexo 日记本：用 hexo 搭建一个本地的日记本（现在并没有在用了，因为新建和预览都比较麻烦） 解决方案 python 相对路径是相对于哪里 python 读取 ini 文件失败的原因 MFC 用对话框获取输入 更改 git 仓库已经 commit 的用户名和邮箱信息 建新 hexo 博客后继续更新旧 hexo 博客的方法 WIN10 共享文件夹 notepad++添加文件关联","link":"/posts/blog-catalogue/"},{"title":"【自我管理系统】电脑文件管理系统v200417","text":"以此文梳理我的电脑文件管理系统，由于是我的文件管理系统，所以很多个性化的设置，读者建立自己的系统时可改为自己的。 目的（系统需求） 当我产生或者获得一个新的文件时，知道存放到哪里 当我想要找到某个我需要的文件时，能够迅速找到 当我的电脑遗失或者重装时，重要的文件不丢失，能够迅速恢复 让我能够舒适地使用电脑 工具 腾讯电脑管家桌面助手独立版：用到它的桌面收纳格、文件夹映射（减少查找层级） 坚果云：用到云同步功能 Listary：快速搜索打开文件夹和软件，可以用 everything 代替 环境配置（数据结构）磁盘分为三个分区： C 盘：系统盘。100G。 D 盘：软件盘。自定义安装时改个盘符即可 F 盘：文件盘。分配最大的空间。用腾讯桌面整理将其映射到桌面 F 盘下建立子文件夹： Archive：存放我的作业等项目文件的存档。使用坚果云同步。 Blog：存放个人博客源文件 Buffer：缓冲区，用于存放正在进行的项目的文件。固定到快速访问，并用腾讯桌面整理将其映射到桌面 MyNotebook：存放 Vnote 笔记本。使用坚果云同步 Resource：存放资源，包括课件、软件以及其他各种学习资源 Software UserFolder：用户文件夹（图片、下载、音乐、文档、视频等）移动到这文件夹，避免占用系统盘空间。 图片文件夹（F:\\UserFolder\\Pictures）下新建以下文件夹（因为暂时没有拍照存相片的习惯，所以没有相册文件夹） Wallpaper：存放壁纸图片。桌面右键菜单【个性化】-&gt;左侧菜单【背景】-&gt;【背景】选项选择“幻灯片放映”，将本文件夹设置为相册。 Temp：临时图片存放处。用于存放暂时保存的图片，默认此处的图片都是可以删除的，哪天想起来了就可以全选删除。 Useful：存放有用的图片，比如证件照片等。 Icon：图标包。图标可在Flaticon这个网站免费下载，用于装饰文件夹。 将下载文件夹（F:\\UserFolder\\download）（作为收集箱文件夹）使用腾讯桌面整理映射到桌面，便于随时打开、观察它是否存在未处理的文件以及将文件拖入。 视频文件夹（F:\\UserFolder\\Videos）新建 Bilibili 文件夹，存放自己做的 B 站视频。 注意事项移动时注意先建立对应文件夹（如新建 download 文件夹），再将其路径指定为此文件夹，避免出现将整个 F 盘指定为用户文件夹的情况。 如果出现上述问题，可通过以下方案解决，它来自此百度知道链接 可以在注册表中修改win+R 输入“regedit”找到\\HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\User Shell Folders找数值为属 F:\\ 的 修改了就行 标准流程（数据操作）收集由于文件大多数来自网络下载，将用户文件夹中的“download”文件夹设置为收集箱。相比于之前单独新建一个收集箱文件夹，省去了从 download 文件夹移动到收集箱的过程。 分类根据文件类型进行分类 自己新建的工程文件：在 Buffer 文件夹中找到对应的项目文件夹（或者新建）放入。 下载的软件 安装版：放入Resource\\Software\\Installer 免安装版：放入Resource\\Software\\Portable 图片 壁纸：放入Pictures\\WallPaper文件夹 临时截图：放入Pictures\\Temp文件夹 有用处的图片：放入Pictures\\Useful文件夹 图标包：放入Pictures\\Icon文件夹 课件与讲义、笔记：放入 Buffer 文件夹中对应的课程文件夹 归档归档还是挺重要的，以前做过的东西可能还要用到。例如近期，软件质量保证与测试这门课程需要使用上上个学期的软件工程导论的第四次上机作业4_软工导论实验四透镜质量检测190618.rar的代码和报告来进行测试，我就很快找到了。 当完成一个项目（比如课设、上机作业、校内校外活动例如某个比赛）后，将用到的资料打包为一个压缩包，只保留能够还原此项目的必要资料，例如编译生成的 exe 之类的都删除。 压缩包命名为[大学学期号_][科目名称]&lt;项目名称&gt;&lt;六位数归档日期&gt;，其中尖括号必选，方括号可选例如：5_计算机图形学隐面算法及光照模型191129.rar代表：大学第五学期（大三第一学期）做的隐面算法及光照模型项目，它在 2019 年 11 月 29 日归档。 这个归档日期并不代表它做完的日期，而是我在将其打包成压缩包并放入 Archive 文件夹的日期，或者是我根据文件的最后更新时间推测出的项目完成时间。因为我在形成这个归档系统之前，并没有记录完成时间的意识。 打包好之后，将其放入 Archive 文件夹对应的年份文件夹中。若是有多个类似的项目文件（比如同一个课程的课设和上机），就新建一个文件夹将它们放在一起，但是内部不再新建新的层级的文件夹。 此时，Archive 文件夹中的一个示意结构如下： Archive 0000：用于存放未整理好的归档文件，这是我之前重构 Archive 文件夹时留下的，我觉得没有必要删除，就留着了。 2017：存放 2017 年的项目文件 vb：2017 年写的 vb 项目的文件夹 是英雄就下一百层171125.rar：其实完成时间还要更早，但是最后更新日期是这个所以就用了它 …… 1_第八届创业先锋挑战赛171011.rar …… 2018： …… 2019： 5_计算机辅助设计：同一科目的项目文件开一个文件夹存放 5_CAD复习笔记191210.rar 5_CAD三类自由曲线191129.rar 5_CAD旋转的三角形191129.rar 5_CAD折线路径191129.rar 明日方舟代理指挥190721.rar：不是学校作业的就不需要学期号了 …… Archive 文件夹使用云同步，重装系统后它是最快恢复的部分，这让我真正意识到建立一个完善的系统是多么重要。 查找 双击 ctrl 使用 Listary 或者使用 everything 查找项目名称 或者进入对应功能的文件夹手动查找，按照上面的方式设置，查找层级一般不会超过三层（因为还有桌面映射） 备份与恢复根据 F 盘中文件夹中数据的重要程度来执行不同的策略。 本系统中最为重要的文件是Archive中的文件，因为这里面都是我自己积累下来的自己完成的代码以及各种资料，它们是不可恢复的。 其次是存放着日记的MyNotebook文件夹，虽然不可恢复但是对我来说只要不泄露就行，删日记这种事情我以前没少干。 它们都使用了坚果云同步，以及定期移动硬盘备份。 接着是Blog文件夹，它存放着我个人博客的 hexo 源代码。我使用 git 来对它进行管理，注意这个 git 库和它用于部署的 git 库不一样，这个是用于管理源代码而不是发布的内容（public 文件夹）的。每发布一篇博文，或者修改一次配置，就 commit 一次。将其 push 到 github 的私有库，并通过码云的仓库导入功能同步过来，这样就轻松有了两份备份，而且自带历史版本管理。 Buffer文件夹不进行备份，借此让我在项目结束后尽快归档，避免数据丢失。 最不重要的是Resource文件夹，里面存放的资源（软件安装包、课件、各种电子书）都是可以再次获取的，并不包含我的心血在其中。基本上不需要备份。偶尔一些比较难以获取的（比如下载速度贼慢的）会备份到百度云盘（莫得选择，坚果云的流量不能浪费）上。 UserFolder\\Video\\Bilibili：在每次录制并上传一个新的视频后，将其资料归档到这个文件夹，因为视频压缩后也很大，所以使用百度云盘备份。备份时机在每次录制并上传一个新的视频后。","link":"/posts/self-management-file-manage-v200417/"},{"title":"【自我管理系统】任务管理系统v200423","text":"梳理我现有的任务管理系统，以做出改进。 目前这个系统我并没有非常严格地在执行，因为没有养成这个习惯，但是我能够感受到它是有用的。 目的（系统需求）建立并运行了这个系统后： 当我得到一个任务的时候，我不会忘记这个任务或者遗失它的相关资料 能够让我明确地知道什么时候应该做什么事情，不会将时间浪费在迷茫上 当我要来执行一个任务的时候，我能够迅速地找到它的相关资料，不会将时间浪费在找资料上面 工具 活页本 充足的方格活页纸 活页本隔页 数据结构参照子弹笔记的集子的概念。原本我使用的是子弹笔记，后来移植到活页本上了。 月集子使用一张活页纸 上个月的目标完成情况 上个月的总结，以无序列表的形式列举一下自己干了啥，附加自己对上个月的一段话概括描述 本月的目标：可以动态添加，但是添加到本部分的内容一定要明确、具体 周集子一周使用一张活页纸 上周的目标完成情况 上周的总结，以无序列表的形式列举一下自己干了啥，附加自己对上周的一段话概括描述 本周的目标：可以动态添加，但是添加到本部分的内容一定要明确、具体。如果全部完成，可以从月集子中选取目标加到这里 日集子一周的内容按照顺序写，一般来说是七天用两张活页纸 今天要做的任务：参考子弹笔记的记号系统 任务结构（均写在一行）： 分类：比如说“数学作业”，总之是一眼就能看出来是啥任务就行 任务内容：尽可能精简 截止时间 数据操作收集 触发条件：被分配了任务时。比如，老师在网课直播中口头提到了作业。 动作： 由其截止时间判断任务级别是日级别、周级别还是月级别，添加到对应的集子 记录 记录载体优先级：活页本，电子产品，大脑。优先级越低的载体在条件满足时尽量将记录整理到优先级高的载体。 整理 触发条件：任务条目过多 动作： 在空白纸页处按照重要紧急度分类，誊抄一遍任务 归档 触发条件：集子周期结束时 动作： 手机 APP 扫描，发送到电脑，按照电脑文件管理系统来进行归档 丢弃上一个周期已归档的活页纸","link":"/posts/self-management-task-manage-v200423/"},{"title":"【毕业实习总结】（1）maven环境配置","text":"前言大三暑假有个毕业实习，是企业的人来我们学校带我们做项目，为期三周。 前半部分是教我们一些框架的基本使用，后面几天就是组成小组利用前面学习的知识开发一个商城项目。感觉和课设其实没有差的太多。 学习到的框架有 mybatis、springmvc、spring、springboot、shiro、mybatis-plus，还在一开始学习了如何建立 maven 项目。 2020 年 7 月 15 日，我们小组完成了答辩。在之前因为要学习框架、做项目，甚至中间夹杂着几场考试，所以抽不出空来写博客，现在结束了，我现在通过 git 提交记录以及幕布学习笔记、工作日报等记录来尝试还原这一次经历以及学习到的技术。 本系列将会先整理学习笔记，最后对本次项目进行总结。 笔者也是刚刚才学习这些东西，所以如果有问题可以给我留言。 maven 环境配置本项目是在 eclipse 下开发的 maven 项目，所以首先需要配置 maven 环境。 什么是 maven首先，什么是 maven？下面是来自菜鸟教程的说明： Maven 翻译为”专家”、”内行”，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven 利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。 Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。 Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。 ——Maven 教程|菜鸟教程 我的理解是，maven 是一个可以帮助我们管理第三方的 jar 包的工具。 当我们在编写项目的时候，除了标准库之外，总会用到第三方依赖，比如说 fastjson、mysql 的驱动等。 在之前几次课设中，如果想要添加 jar，就需要先去官网找这个 jar 包，下载后将其添加到 WEB-INF 目录下的 lib 文件夹，再将其添加到Build Path中。 而在 maven 项目中，只需要在它的配置文件pom.xml中添加对应的依赖的配置即可，maven 会自动将你要的 jar 包从 maven 远程库下载到本地仓库，接着你就可以在项目中使用它了，如果本地仓库内已经有这个版本的 jar 了，就不需要重复下载了，省去了很多麻烦。 除了省去了自己下载和导入的麻烦，还可以方便团队协作。只需要一个pom.xml配置文件，就可以快速统一团队内部使用的依赖的版本。 maven 还有一些其他的功能，不过本项目中，我们只用到依赖管理。 安装 maven首先需要去官网下载 maven（先检查你电脑上有没有 jdk）。下载到的文件的文件名大概是这样的：apache-maven-3.6.3-bin.zip，将其解压之后，放在非中文目录下，我是放在了 D 盘根目录下。 接着将D:\\apache-maven-3.6.3\\bin，也就是你解压目录下的 bin 目录的路径配置到环境变量Path当中。在命令行中输入如下命令： 1$mvn -v 如果成功，那么就安装完毕。 配置 maven 本地仓库接着找个地方建个文件夹作为你的本地 maven 仓库，它用来存放你项目中用到的依赖 jar 包。 打开安装目录下的 conf 目录（本例中为D:\\apache-maven-3.6.3\\conf）下的settings.xml文件，找到这么一段注释： 123456&lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: ${user.home}/.m2/repository &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; --&gt; 将其中的&lt;localRepository&gt;标签解除注释并将内容配置为你刚刚创建的本地仓库文件夹。我的配置如下： 1234567&lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: ${user.home}/.m2/repository &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; --&gt;&lt;localRepository&gt;D:/repository&lt;/localRepository&gt; windows 下注意将复制的路径的反斜杠改为正斜杠。 配置 maven 的阿里云镜像maven 远程库在国外，国内访问比较慢，你可以设置为国内的镜像从而加速下载。 还是刚刚那个配置文件，找到&lt;mirrors&gt;标签，在网上搜索 maven 镜像，配置好之后如下(本例使用阿里云镜像)： 1234567891011121314151617181920212223&lt;mirrors&gt; &lt;!-- mirror | Specifies a repository mirror site to use instead of a given repository. The repository that | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used | for inheritance and direct lookup purposes, and must be unique across the set of mirrors. | &lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt; --&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 配置 eclipse打开 eclipse，打开菜单【windows】-&gt;【preferences】，左边搜索框中搜索 maven，选择Installations选项，点击Add按钮，将你的 maven 安装目录添加进去（选择目录后直接点完成），添加后记得勾选新出现的行。下图为未添加时： 这个选项这样就配置好了。 接着配置下方的User Setting选项，将此页的User Settings框内配置为刚刚的settings.xml配置文件的路径，如果下方的Local Repository出现的是你刚刚设置的 maven 本地仓库的路径，那么你就配置成功了。点击Apply and Close关闭此窗口即可。 在 eclipse 中新建 maven 项目eclipse 菜单【file】-&gt;【new】-&gt;【project】，搜索 maven project，点下一步。 勾选Create a simple project，然后下一步。各个选项及其说明如图，这里的选项并不是太重要，后面可以在pom.xml里面改。 点击完成，你就新建了一个 maven 工程，不过有个问题，那就是新建的工程上面有一个红叉，这说明项目还有些问题。这是因为缺少web.xml这个文件。 你可以再新建一个Dynamic Web Project，注意在新建的时候勾选生成web.xml的选项，然后将WEB-INF这个目录包括下面的web.xml文件都复制到 maven 项目的src/main/webapp下，这时红叉应该就会消失了。 eclipse 导入 maven 项目下面是一个供练习导入的项目，它是当时在学习 mybatis 等框架时我放在码云上的，链接如下： 练习项目 由于我设置了忽略工程文件，所以 clone 下来之后还需要进行一系列操作才能导入到 eclipse。步骤如下： 首先确定你已经按照上文配置好 maven 环境。 接着在 eclipse 菜单【file】-&gt;【import】，搜索project from git这个选项，选择Clone Url，将仓库 clone 到本地，这部分不详细配图说明了。 clone 下来之后，会有三个选项（为了演示方便我就随便放在桌面了，大家不要学，我之后会删除的） 选择图中第三个选项Import as general project，它会为你的项目生成一个新的 project 文件，但是按照这种方式导入进来，它只是一个普通的 eclipse 工程，并不是 maven 工程，这个怎么办呢？ 我们这一步仅仅是为了让它生成一个.project工程文件，所以现在可以在 eclipse 的工作空间视图中将这个工程给删除，但是要注意，千万不要勾选delete project content from disk这个选项（它会将你的工程从磁盘上删除），我们要的仅仅是将它从 eclipse 的工作空间中删除。 然后 eclipse 菜单【file】-&gt;【import】，搜索 maven，选择Existing Maven Project，将刚刚的工程导入进来就可以了。有了之前生成的.project文件以及我仓库里面本来就有的pom.xml配置文件，eclipse 就能够知道这是一个 eclipse 的 maven 项目，从而导入进来。 导入进来会有红叉，这是因为依赖还没下载好，你等它下载。如果下载好了还是有红叉，就打开项目属性，然后找到project facets这个选项，把你的 java 版本调整成你的对应版本就行了。 添加依赖以添加 mysql 驱动 jar 为例。 前往maven 中央仓库的官网，搜索 mysql，选择版本，并将其依赖的配置代码添加到pom.xml中： 123456789101112131415161718&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.test&lt;/groupId&gt; &lt;artifactId&gt;TestMaven&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;!--这里就是新添加的依赖--&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!--这里就是新添加的依赖--&gt; &lt;/dependencies&gt;&lt;/project&gt; 文件保存后，等待 eclipse 把这个依赖自动下载到本地仓库，就可以使用它了。","link":"/posts/graduate_internship_1/"},{"title":"vscode中python自定义包的模块如何导入其子包模块","text":"问题描述如图所示，对于python，有一个自定义包parent，它里面还有一个子包child，当你在parent.module1中import child.module2时，vscode会给你报错，说找不到这个包。 当你单独运行module1.py的时候，可以正常运行，但是当你在parent包外层的main.py中import parent.module1时，就会报错。 详细说明目录结构为： main.py parent __init__.py module1.py child __init__.py module2.py 其中： main.py 12# main.pyimport parent.module1 parent.__init__.py 12# parent.__init__.pyprint('导入了parent包') child.__init__.py 12# child.__init__.pyprint('导入了child包') module1.py 123# module1.pyimport child.module2print('导入了module1模块') module2.py 12# module2.pyprint('导入了module2模块') 分析原因当你单独运行module1.py的时候，可以正常运行，并输出： 123导入了child包导入了module2模块导入了module1模块 这是因为vscode此时将module1.py作为相对路径的起点，从而找到了child.module2的位置。 但是当你在parent包外层的main.py中import parent.module1时，就会报错。 这是因为vscode此时将main.py作为相对路径的起点，对于main.py来说，它所在目录下是没有child包的，只有parent包，所以找不到，报错。 解决方案在parent.__init__.py中添加三行代码，添加完之后如下所示： 123456# parent.__init__.pyimport sysimport ossys.path.append(os.path.dirname(os.path.realpath(__file__)))print('导入了parent包') python找包会在当前路径和sys.path中去查找，所以可以在导入parent包的时候，将它的路径加入sys.path当中，这样就可以找到parent包的子包了。 同时，因为是在__init__.py中加的，包内文件就不必每次都将粘贴一次这部分代码。 其中，os.path.realpath(__file__)获取本文件即parent.__init__.py的真实路径，os.path.dirname()将完整路径中的目录名提取出来，去掉其中的文件名。 添加后main.py运行结果： 1234导入了parent包导入了child包导入了module2模块导入了module1模块","link":"/posts/python-the-module-of-parentpkg-import-the-module-of-childpkg/"},{"title":"记第三次博客切换主题以及主题优化","text":"2019 年 2 月 28 日，第一次换主题，从shana（夏娜）换成了NexT，当时换主题的原因是：虽然二次元主题蛮好看的我挺喜欢，但是由于小众，功能缺乏，而 NexT 作为一个使用人数非常多的主题，功能非常齐全，所以决定换主题。 2020 年 4 月 5 日，第二次换主题，从NexT换成了Matery，原因是这个主题可以放很多图，并且我需要的功能也都有。 2020年10月11日，第三次换主题，也就是这次，换成了Icarus（伊卡洛斯）。原因是，Matery的归档页面不能满足我回看历史文章的需求，以及我觉得整个页面太花哨了，封面图片也不是很好弄，所以还是换成图片量中等的Icarus。 换主题的原因Matery的归档页面长这样： 虽然有个类似于github的heatmap一样的日历，但是这个日历并不能点击就跳转到那一天，而且由于所有的文章用卡片展示，导致无法概览，想看某个时间写的文章，得往下滑很久甚至翻页，很不方便。我难以统计某个月写了哪些文章。 因此，Icarus的归档页一下子就吸引了我： 最终决定切换主题。 主题安装之前切换主题，先将主题clone到本地theme文件夹，然后再根目录的_config.yml修改主题配置即可，不过这次我遇到了一些问题。 clone命令如下： 1$git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 在命令行clone比较慢，于是我使用github desktop进行clone，将目录指定为theme/icarus，也不知道是什么原因，这样就快多了。 可是在运行hexo s的时候，却弹出了如下错误： 查看官网文档-升级指南，找到了相关的描述。原来是这个主题依赖的hexo版本已经到5了，而我还是4，没有升级。 解决方法是，运行错误提示中给出的命令安装新版本的依赖： 1$npm install --save bulma-stylus@0.8.0 hexo@^5.0.2 hexo-log@^2.0.0 hexo-renderer-inferno@^0.1.3 hexo-renderer-stylus@^2.0.0 hexo-util@^2.2.0 hexo-component-inferno@^0.10.1 inferno@^7.3.3 inferno-create-element@^7.3.3 安装好之后运行hexo clean，再使用hexo s就可以看到本地的主题已经切换了。 主题优化和之前的主题不同，Icarus的配置文件不是在theme/Icarus下面，而是在博客根目录下的_config.icarus.yml（在运行hexo clean的时候会自动帮你生成这个文件）。 我在这里只提一些我配置时遇到问题的选项，其余的配置可以查看官方的主题配置文档 permalink切换了主题之后，我点击文章竟然不是跳转到文章详情，而是下载了一个文件名为文章标题的无后缀名文件，用vscode打开一看，里面是该文章的html代码，这就很奇怪了。 当我将文章的permalink从Front-matter（Front-matter 是hexo文章文件最上方以 --- 分隔的区域，用于进行文章的一些配置）中去掉的时候，就可以跳转到详情页了，与此同时，该文章的链接又变成了中文的文章名字。 最后找到的解决方案是，安装插件hexo-abbrlink，自动生成永久链接。我一开始还担心这样弄，我以前设置的永久链接不是全都要变？不过后来找到一篇博客说可以在Front-Matter中设置abbrlink字段来手动指定，没有手动指定时才会自动生成。这样一来，我只需要使用vscode的全局替换，将所有的permalink改成abbrlink就可以了。 具体操作步骤可以参考这一篇文章：Hexo-abbrlink生成唯一永久文章链接 第一步，安装此插件。 1$npm install hexo-abbrlink --save 第二步，配置博客根目录下的_config.yml 1234permalink: posts/:abbrlink.html # 此处可以自己设置，也可以直接使用 :/abbrlinkabbrlink: alg: crc32 #算法： crc16(default) and crc32 rep: hex #进制： dec(default) and hex 第三步，使用vscode全局替换，将permalink替换为abbrlink（注意dismiss不需要替换的地方），这样之前的链接又可以用了，此问题解决。 也不是完全没有问题，在后面检查时发现有一篇文章被整个删去了，md文件中只剩下abbrlink: 2，幸好我每次更改后都用git commit备份一下。 toc初始目录是在左侧的，并且如果固定了左栏，那么就看不到目录的全貌。所以最后我将其调整为在文章页面只显示toc挂件，而不显示profile挂件。 设置方法是，在博客根目录下新建一个_config.post.yml文件，这个文件里面的配置针对文章详情页，并且会覆盖全局配置，所以我在这个文件里面这样配置： 12345678910111213widgets: # Table of contents widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: toc # Whether to show the index of each heading index: truesidebar: left: sticky: false right: sticky: true 也就是说，其他页面是三栏，并且左栏悬浮，不随着向下滑动而移动位置，显示各种挂件；而在文章详情页面，在右侧只显示悬浮目录，而不显示其他挂件，这样阅读体验会好很多。 除了设置toc挂件之外，还得在每篇文章的Front-Matter中设置toc: true，才能打开悬浮目录，同样使用全局替换来完成。 用的是vscode的正则表达式替换。查找的内容是： 1---\\ntitle(.*) 替换的内容是: 1---\\ntitle$1\\ntoc: true 每篇文章的Front-Matter中，title字段都是在第一个，所以查找title，并且在保留title的情况下，在后面添加toc: true。 live2D看板娘接着就是恢复萌萌的看板娘了。 找到了一篇完美的教程，刚好就是讲Icarus如何添加live2D的：Hexo+Icarus3+live2d给博客添加看板娘 照着这篇教程来做，很轻松就配置好了，感谢博主。 看板娘正好可以放在右下角。对于文章详情页面，悬浮目录在右侧折叠起来，右下方正好有一大块空地，不会挡住文章内容；对于其他页面，左栏是固定悬浮的，而右栏是正常滑动的，所以不会影响读者查看右侧的标签和分类、近期文章等挂件。 这个live2D插件默认是在左边的，不过在前一个主题中，我就已经解决了这个问题。转移到这边，只需要调整一下看板娘的z-index，让她在最上方就行了。 修改live2d-widget文件夹下的waifu.css： 123456789101112#waifu { bottom: -1000px; /*left: 0;放到右边*/ right: 100px; line-height: 0; margin-bottom: -10px; position: fixed; transform: translateY(3px); transition: transform 0.3s ease-in-out, bottom 3s ease-in-out; /*z-index: 1;防止遮挡*/ z-index: 1000;} 注释内是原来的内容。 除此之外还有一个问题，那就是初始看板娘并不是我喜欢的那个模型了，所以想要将其改回来。 我在浏览该live2D插件的github仓库时，找到了这样一个issue：如何把模型替换成自定义模型 #6。 greenhaha: waifu-tip.js 中 初始化模型中modelID modeltexture ID 如何指定成 自定义的模型 stevenjoezhang（作者大大）:需要自己搭建后端API，参考 https://github.com/fghrsh/live2d_api 我从中得到了信息，打开waifu-tip.js，然后搜索modelID，从而找到了这样一段代码： 12345678let modelId = localStorage.getItem(&quot;modelId&quot;), modelTexturesId = localStorage.getItem(&quot;modelTexturesId&quot;); if (modelId === null) { // 首次访问加载 指定模型 的 指定材质 modelId = 1; // 模型 ID modelTexturesId = 53; // 材质 ID } loadModel(modelId, modelTexturesId); 可以看到模型的id是储存在localStorage里面的，所以我将看板娘切换成我想要的那个，F12打开开发者工具，打开Application选项卡，查看localStorage里面的modelId，发现是0。接着将上面代码中的初始模型id改为0就可以了。 文章分类优化除了更新博客主题之外，我还重新调整了一下文章分类。 原本的文章分类 分类 内容 过程复盘 记录学习实践一个事物的过程，侧重记录与反思 知识整理 针对某一部分知识进行集中整理方便查阅，例如 API、语法、命令等 解决方案 针对遇到的某个具体问题寻找解决方案 算法理解 针对某个具体算法的理解掌握 工具使用 对于框架、软件、网站等工具的使用方法与心得经验，或是简单推荐 目录索引 定期将本博客的文章索引起来，或者整理一些有用的参考链接 日志随笔 随便写点啥心情，或者年终总结之类的 过程复盘和知识整理，前者我会尽量将我探索的过程记录下来，夹杂着一些知识点，而后者会将知识点进行简单罗列便于查询。 解决方案是针对某个具体的问题编写解决步骤，而工具使用则是将使用这个工具的一些常见的问题集中解决。 日志随笔里面可能会对近期写的一些博文进行索引，但是是按照时间顺序线性串联；而目录索引则是专门索引一个系列的文章。 算法理解是针对某个具体的算法进行解析，从而达到学习的目的。 新的文章分类 分类 内容 复盘总结 对过程进行回顾，总结经验，优化流程。 学习笔记 知识点总结等都放在这里。 解决方案 对某个特定问题的解决办法。 日志随笔 随笔，博客更新日志等。 目录索引 将本博客的文章定期进行汇总分类。 分类之间的一些区别： 复盘总结：以叙述过程与思路为主，一般含有步骤总结，思路记录（比如：我是如何想到这一步的？），一般不含对知识点的讲解。该分类下是比较抽象的文章 学习笔记：以介绍结果与设计为主，长的像教程。可能含有大量代码，一般含有新知识点的总结说明，我在b站上面录了视频的项目对应的博客文章一般也属于这个。该分类下是比较具体的文章。 解决方案：以介绍问题及其解决方法为主，比起学习笔记，更适合作为教程。它将复盘总结中的一些经验提取出来，又不像学习笔记一样冗长复杂。 这个分类也许并不够MECE（不重不漏），不过对我目前的文章来说是够用了。 调整分类前，“过程复盘”这个分类占了五分之三的内容，而其他分类比较少，比较不平衡，而且分类的标准太模糊，以至于我经常不知道该放到哪里去。 调整之后，“知识整理”、“算法理解”归入“学习笔记”，“工具使用”归入“解决方案”，减少了分类数量，并且明确了分类标准。按照新标准对文章调整分类，“学习笔记”和“复盘总结”各占二十多篇，不再是“指南针面板”了 最终效果图","link":"/posts/hexo_blog_switch_theme_3/"},{"title":"基于React+Electron的CraftTweaker脚本生成器","text":"在看到好友StringOD的一篇博客《我的世界自定义配方脚本生成器》之后，我有了些想法。 CraftTweaker是沙盒游戏Minecraft的一个Mod（Modification，模组，游戏的一种修改或增强程序），通过使用一种名为ZenScript的自定义脚本语言，修改游戏中的合成配方。 不过这个mod的最新版本是没有对应的GUI程序的，所以要生成想要的合成配方不是那么容易，得手动编写ZenScript脚本。StringOD的那篇博客中，用易语言实现了一个功能比较完善的GUI程序——AutoSpawnZScript。 恰好我在大四的第一个综合实践中使用过React+Antd来编写前端界面，而且之前用hexo-client的时候了解到了Electron这个东西可以把web程序变为桌面应用程序，所以就想用React+Antd+Electron来尝试编写一下这个逻辑简单的脚本生成器，以巩固React的知识，以及学习一下Electron怎么用。 本文主要讲一下本项目（CraftTweaker-Assistant，托管于gitee）的大致情况与设计思路。 参考链接 结合React创建Electron桌面应用-知乎 React + Electron 搭建一个桌面应用-掘金 CraftTweaker的官方文档 搭建环境步骤概括起来大致是： 创建React项目 添加electron包 进行配置 详细内容可以参考上文给出的参考链接。因为参考链接说的很详细了，所以我这里就不用它们来凑字数了。 界面原型我用ipad上面的notability绘制了一个简单的界面原型如下： 从这张图可以看到，我对StringOD的项目的界面做出的改进主要有： 第一，可以展示物品的图片，物品的名称则在鼠标悬停时出现的提示框中展示； 第二，选择物品不再是用列表或者下拉框，而是点选需要选择物品的格子之后，会弹出一个物品选择对话框，点击想要选择的物品之后就可以选择成功。 而物品选择对话框的数据则是从json文件中读取，我设定的文件规则如下： 1234567{ &quot;mod名&quot;: { &quot;物品名&quot;: { &quot;texture&quot;: &quot;物品材质图片url&quot; } }} 用于测试的数据为： itemsData.json1234567891011121314151617{ &quot;minecraft&quot;: { &quot;arrow&quot;: { &quot;texture&quot;: &quot;https://i.loli.net/2021/01/04/6LFr15vAUhzHESf.png&quot; }, &quot;flint&quot;:{ &quot;texture&quot;:&quot;https://i.loli.net/2021/01/05/phzikbtaQ7qPGSV.png&quot; }, &quot;stick&quot;:{ &quot;texture&quot;:&quot;https://i.loli.net/2021/01/05/La1Vd4TPo7RDZer.png&quot; }, &quot;feather&quot;:{ &quot;texture&quot;:&quot;https://i.loli.net/2021/01/05/UQX4CoJ3EGmatHO.png&quot; } }} 物品材质图片暂时使用上传到图床的图片，在以后的版本中，会兼容本地图片路径。 ZenScript简介自定义合成配方，需要使用ZenScript编写如下的合成配方脚本（借用自StringOD的《我的世界自定义配方脚本生成器》）： test.zs1234567891011121314151617181920// 龙蛋: 黑曜石围绕着鸡蛋, 最坚硬的蛋craftingTable.addShapeless(&quot;StringOD_LongDan&quot;, &lt;item:minecraft:dragon_egg&gt; * 1, [&lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:egg&gt;, &lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:obsidian&gt;, &lt;item:minecraft:obsidian&gt;]); // 刷怪箱: 铁栅栏围绕着箱子, 网格一样的箱子craftingTable.addShapeless(&quot;StringOD_ShuaGuaiXiang&quot;, &lt;item:minecraft:spawner&gt; * 1, [&lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:chest&gt;, &lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:iron_bars&gt;, &lt;item:minecraft:iron_bars&gt;]); // 烈焰粉: 被岩浆桶围起来的木棍craftingTable.addShapeless(&quot;StringOD_LieYanFen&quot;, &lt;item:minecraft:blaze_powder&gt; * 9, [&lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:stick&gt;, &lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:lava_bucket&gt;, &lt;item:minecraft:lava_bucket&gt;]); // 牛蛋: 被生牛肉围绕起来的鸡蛋craftingTable.addShapeless(&quot;StringOD_NiuDan&quot;, &lt;item:minecraft:cow_spawn_egg&gt; * 1, [&lt;item:minecraft:beef&gt;, &lt;item:minecraft:beef&gt;, &lt;item:minecraft:beef&gt;, &lt;item:minecraft:beef&gt;, &lt;item:minecraft:egg&gt;, &lt;item:minecraft:beef&gt;, &lt;item:minecraft:beef&gt;, &lt;item:minecraft:beef&gt;, &lt;item:minecraft:beef&gt;]); // 史莱姆蛋: 被粘液球围绕起来的鸡蛋craftingTable.addShapeless(&quot;StringOD_ShiLaiMuDan&quot;, &lt;item:minecraft:slime_spawn_egg&gt; * 1, [&lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:egg&gt;, &lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:slime_ball&gt;, &lt;item:minecraft:slime_ball&gt;]); // 恶魂之泪: 牛奶桶里面有很多类似的液体, 工作台九宫格中的任意位置craftingTable.addShapeless(&quot;StringOD_EHunZhiLei&quot;, &lt;item:minecraft:ghast_tear&gt; * 9, [&lt;item:minecraft:milk_bucket&gt;]); // 末影人蛋: 末影珍珠围绕着鸡蛋craftingTable.addShapeless(&quot;StringOD_MoYingRenDan&quot;, &lt;item:minecraft:enderman_spawn_egg&gt; * 1, [&lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:egg&gt;, &lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:ender_pearl&gt;, &lt;item:minecraft:ender_pearl&gt;]); 将其保存为扩展名为.zs的文件例如test.zs，并将其置于游戏主目录的scripts目录下（前提是你得安装了CraftTweaker这个mod），启动游戏，就能使用你的新合成表了。 你可以在游戏中使用/reload命令来重新加载脚本，从而不必每次重开游戏来调试新写的zs脚本。 minecraft的配方是由9个材料物品堆和1个成品物品堆构成的，并且分为三种类型：无序配方（Shapeless），有序配方（Shaped），镜像有序配方（Shaped Mirrored）。 在游戏中，它们之间的区别在于，物品在合成台的九宫格内摆放的形状会不会影响合成的物品的类型和数目。 而在zenscript中，他们的区别在于调用的函数不同，以及原料的参数编写方式不太一样。 无序配方： 123// A shapeless recipe can have up to 9 inputs// This also demonstrates that more than one output can be used. In this example, 8 grass will be outputted.craftingTable.addShapeless(&quot;shapeless_example_2&quot;, &lt;item:minecraft:grass&gt; * 8, [&lt;item:minecraft:wheat_seeds&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;, &lt;item:minecraft:dirt&gt;]); 有序配方： 123456// Adding a shaped recipecraftingTable.addShaped(&quot;shaped_example_1&quot;, &lt;item:minecraft:arrow&gt;, [ [&lt;item:minecraft:diamond&gt;, &lt;item:minecraft:diamond&gt;], [&lt;item:minecraft:air&gt;, &lt;item:minecraft:flint&gt;], [&lt;item:minecraft:air&gt;, &lt;item:minecraft:flint&gt;]]); 有序镜像配方： 123456// Adding a shaped mirrored recipecraftingTable.addShapedMirrored(&quot;shaped_mirror_example_1&quot;, &lt;item:minecraft:arrow&gt; * 2, [ [&lt;item:minecraft:diamond&gt;, &lt;item:minecraft:diamond&gt;], [&lt;item:minecraft:air&gt;, &lt;item:minecraft:flint&gt;], [&lt;item:minecraft:air&gt;, &lt;item:minecraft:flint&gt;]]); 组件设计与实现本项目的组件有三个： CraftTable（合成台）：用于容纳主要功能组件 ItemBox（物品框）：合成台组件的主要组成部分，用于展示物品图片，并响应点击事件以弹出物品选择对话框 ItemSelector（物品选择器）：即物品选择对话框 同时需要用到一个普通的非组件类来封装物品相关数据，这里沿用了CraftTweaker的官方文档中的命名，即ItemStack（物品堆）。 之所以是物品堆，是因为除了保存物品本身的信息之外，还需要保存物品堆叠的数目，在minecraft中，一个物品框中是可以堆叠多个物品的。 ItemStack物品堆该类封装了物品的几个基本属性（更多属性以后再加），以及物品当前堆叠数目，默认值为“1个空气物品”，即什么都没有。空气（&lt;item:minecraft:air&gt;即代表空）。 比较简单，故直接上代码： src\\entity\\ItemStack.js123456789101112131415161718192021222324252627282930/** * 物品堆 */class ItemStack { /** * * @param {string} modName mod名称，原版则为'minecraft' * @param {string} itemName 物品名称，如'egg' * @param {string} texture 材质图片url * @param {int} amount 物品数目 */ constructor(modName = 'minecraft', itemName = 'air', texture = '', amount = 1) { this.modName = modName;//mod名称，原版则为'minecraft' this.itemName = itemName;//物品名称，如'egg' this.texture = texture;//材质url this.amount = amount;//物品数目 } toString() { if (this.itemName &amp;&amp; this.modName) { return `&lt;item:${this.modName}:${this.itemName}&gt;`; } else { return ''; } }}export default ItemStack; ItemBox物品框物品框用于展示物品，它目前只有一个state（状态）：ItemStack，用于表明当前物品框内是什么物品，以及堆叠数目。 使用antd的方形头像框来模拟合成台的物品框，鼠标悬停提示框内显示物品名称。 src\\components\\ItemBox.jsx12345678910111213141516171819202122232425262728293031323334353637383940414243import React, { Component } from &quot;react&quot;;import { Avatar } from &quot;antd&quot;;import { CodeSandboxOutlined } from &quot;@ant-design/icons&quot;;import ItemStack from &quot;../entity/ItemStack&quot;;import { Tooltip } from 'antd';/** * 物品框，用于在合成表中显示物品 */class ItemBox extends Component { constructor(props) { super(props); this.state = { itemStack:props.itemStack || new ItemStack(), }; } componentWillReceiveProps(nextProps){ this.setState({ itemStack:nextProps.itemStack || new ItemStack() }); } render() { return ( &lt;Tooltip title={this.state.itemStack.toString()}&gt; &lt;Avatar shape=&quot;square&quot; size=&quot;large&quot; src={this.state.itemStack.texture} icon={&lt;CodeSandboxOutlined /&gt;} {...this.props} &gt; {this.state.itemStack.itemName} &lt;/Avatar&gt; &lt;/Tooltip&gt; ); }}export default ItemBox; ItemSelector物品选择器这个物品选择器，就是点击物品框之后弹出的那个用于选择物品的对话框。 它需要读取存储着物品数据的json文件来加载物品框，普通的js是不能读取本地文件的，需要用到nodejs的文件模块： 1const fs = require(&quot;fs&quot;); 但是直接这样导入，是没办法使用里面的函数的，会报错说该模块没有某某函数。 查了一圈资料（资料的链接忘记保存了），得到下面这个解决方案： 1const fs = window.require(&quot;fs&quot;); 不过这样会导致你从localhost:3000打开的这个项目会报错，不要紧，因为你用electron打开的是可以用的。 还有一个问题，就是如果使用异步的fs.readFile()函数，则会产生一个很奇怪的现象，那就是文件读取时好时坏。 有的时候可以正常工作，而下一次打开有可能就无法读取文件了，使用console.log发现这个函数前面的内容都能执行，但是它就是不调用我给它的回调函数。 但是我改成使用同步的fs.readFileSync()函数后，问题得到了解决，但我还是不明白为什么会出现这种情况。 其代码如下： src\\components\\ItemSelector.jsx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import React, { Component } from &quot;react&quot;;import { Modal, Button,Spin } from &quot;antd&quot;;import ItemStack from &quot;../entity/ItemStack&quot;;import ItemBox from &quot;./ItemBox&quot;;const fs = window.require(&quot;fs&quot;);class ItemSelector extends Component { constructor(props) { super(props); this.state = { loading:true,//加载状态 itemList:[new ItemStack()], onSelectItem:props.onSelectItem, }; } componentDidMount(){ this.readItemList(); } /** * 使用json文件读取itemList * @param {string} fileName */ readItemList=(fileName='itemsData.json')=&gt;{ console.log(fileName); //读取文件 //不知道为啥，异步的方法时不时就会无法调用回调函数 let data = fs.readFileSync(fileName); this.initSelectorByJsonString(data); // fs.readFile(fileName, &quot;utf-8&quot;, (error, data)=&gt; { // // 用error来判断文件是否读取成功 // if (error) return console.log(&quot;读取文件失败:&quot; + error.message); // this.initSelectorByJsonString(data); // }); } /** * 用json字符串来初始化选择器 * @param {string} data json字符串 */ initSelectorByJsonString=(data)=&gt;{ let itemList = [new ItemStack()]; let jsonObject = JSON.parse(data); //console.log(jsonObject); for(let modName in jsonObject){ //遍历每一个mod的每个物品 for(let itemName in jsonObject[modName]){ itemList.push(new ItemStack(modName,itemName,jsonObject[modName][itemName].texture)); } } //console.log(itemList); //设置state this.setState({ loading:false, itemList:itemList, }); } render() { return ( &lt;Modal title=&quot;选择物品&quot; footer={null} {...this.props} &gt; &lt;Spin spinning={this.state.loading} tip=&quot;加载物品列表中，请稍候&quot;&gt; { this.state.itemList.map((item,index)=&gt;{ return ( &lt;ItemBox key={index} itemStack={item} onClick={()=&gt;this.state.onSelectItem(item)}/&gt; ) }) } &lt;/Spin&gt; &lt;p&gt;{this.state.loading}&lt;/p&gt; &lt;/Modal&gt; ); }}export default ItemSelector; CraftTable合成台该组件用于将物品框等主要功能组件组合起来，进行布局，以及存储当前已经设置的配方。 它的state为： state 简介 isItemSelectorVisible 物品选择器是否可见 itemList 元素为ItemStack的数组，下标0为输出框，1~9为原料框 curIndex 当前选择的物品框下标，-1为未选择 recipeName 配方名称 recipeType 配方类型，0-无序，1-有序，2-镜像有序 zenscript 生成的zs脚本 它提供了一个方法onSelectItem()，参数为ItemStack类型，作为子组件ItemSelector的选择物品回调函数。 代码如下（比较长，可以点击代码块左上角图标以折叠）： src\\components\\CraftTable.jsx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210import React, { Component } from &quot;react&quot;;import { Row, Col, Space, Tooltip, Card } from &quot;antd&quot;;import ItemBox from &quot;./ItemBox&quot;;import { ArrowRightOutlined,CopyOutlined } from &quot;@ant-design/icons&quot;;import ItemSelector from &quot;./ItemSelector&quot;;import ItemStack from &quot;../entity/ItemStack&quot;;import { Input } from 'antd';import { InputNumber,Button } from 'antd';import { Select } from 'antd';import { message } from 'antd';const { Option } = Select;const { TextArea } = Input;/** * 合成台组件 */class CraftTable extends Component { constructor(props) { super(props); let itemList = [];//0为输出框，1~9为原料框 for (let i = 0; i &lt;= 9; i++) { itemList.push(new ItemStack());//默认为1个&lt;minecraft:air&gt; } this.state = { isItemSelectorVisible: false, itemList: itemList,//存储物品id curIndex:-1,//当前选择的物品框下标，-1为未选择 recipeName:'',//配方名称 recipeType:0,//配方类型，0-无序，1-有序，2-镜像有序 zenscript:'', }; } /** * 打开物品选择器 * @param {int} index 当前选中的物品框下标 */ openItemSelector = (index) =&gt; this.setState({ isItemSelectorVisible: true ,curIndex:index}); closeItemSelector = () =&gt; this.setState({ isItemSelectorVisible: false }); /** * 选择物品的回调函数 * @param {ItemStack} item 物品 */ onSelectItem = (item) =&gt; { if(this.state.curIndex===-1) return;//未选择物品框 let itemList = this.state.itemList; itemList[this.state.curIndex] = item; console.log(item); this.setState({ isItemSelectorVisible:false, itemList:itemList, },()=&gt;{ console.log(this.state.itemList); }) }; /** * 修改配方名称回调 * @param {*} e */ onRecipeInputChange=(e)=&gt;{ this.setState({ recipeName:e.target.value }) } /** * 修改成品数目回调 * @param {*} value */ onAmountInputChange=(value)=&gt;{ let itemList = this.state.itemList; itemList[0].amount = value; this.setState({ itemList:itemList }); } /** * 配方类型回调 * @param {*} value */ onRecipeTypeChange=(value)=&gt;{ this.setState({ recipeType:value }) } /** * 生成配方的脚本 */ createRecipeZenScript=()=&gt;{ if(!this.state.recipeName){ //未输入配方名 message.error('请输入配方名'); return; } let zenscript = ''; let ingredients =''; let outputItemStr = this.state.itemList[0].toString(); if(this.state.itemList[0].amount!==1) outputItemStr += '*'+ this.state.itemList[0].amount; let a = this.state.itemList; switch(this.state.recipeType){ case 0:default://无序 this.state.itemList.map((itemStack,index)=&gt;{ if(index!==0) ingredients+=',' ingredients+=itemStack.toString(); }) zenscript = `craftingTable.addShapeless(&quot;${this.state.recipeName}&quot;,${outputItemStr},[${ingredients}]);` break; case 1://有序 ingredients=`[${a[1].toString()},${a[2].toString()},${a[3].toString()}],[${a[4].toString()},${a[5].toString()},${a[6].toString()}],[${a[7].toString()},${a[8].toString()},${a[9].toString()}]` zenscript = `craftingTable.addShaped(&quot;${this.state.recipeName}&quot;,${outputItemStr},[${ingredients}]);` break; case 2://有序镜像 ingredients=`[${a[1].toString()},${a[2].toString()},${a[3].toString()}],[${a[4].toString()},${a[5].toString()},${a[6].toString()}],[${a[7].toString()},${a[8].toString()},${a[9].toString()}]` zenscript = `craftingTable.addShapedMirrored(&quot;${this.state.recipeName}&quot;,${outputItemStr},[${ingredients}]);` break; } this.setState({ zenscript:zenscript }); } /** * 复制按钮回调 */ onCopy=(e)=&gt;{ } render() { return ( &lt;div&gt; &lt;ItemSelector visible={this.state.isItemSelectorVisible} onSelectItem={this.onSelectItem} onCancel={this.closeItemSelector} /&gt; &lt;Row&gt; &lt;label&gt;配方名称&lt;/label&gt; &lt;Input size=&quot;small&quot; onChange={this.onRecipeInputChange}/&gt; &lt;/Row&gt; &lt;br/&gt; &lt;Row&gt; &lt;Space&gt; &lt;Col&gt; &lt;ItemBox key={1} itemStack={this.state.itemList[1]} onClick={()=&gt;this.openItemSelector(1)} /&gt; &lt;/Col&gt; {/* 中间省略9个重复的格子*/} &lt;Col&gt; &lt;Tooltip title=&quot;成品数目&quot;&gt; &lt;InputNumber min={1} defaultValue={1} size=&quot;small&quot; onChange={this.onAmountInputChange}/&gt; &lt;/Tooltip&gt; &lt;/Col&gt; &lt;/Space&gt; &lt;/Row&gt; &lt;br/&gt; &lt;Row&gt; &lt;label&gt;配方类型：&lt;/label&gt; &lt;Select defaultValue={0} style={{ width: 120 }} onChange={this.onRecipeTypeChange}&gt; &lt;Option value={0}&gt;无序&lt;/Option&gt; &lt;Option value={1}&gt;有序&lt;/Option&gt; &lt;Option value={2}&gt;有序镜像&lt;/Option&gt; &lt;/Select&gt; &lt;/Row&gt; &lt;br/&gt; &lt;Row&gt; &lt;Space&gt; &lt;Col&gt; &lt;Button type=&quot;primary&quot; shape=&quot;round&quot; onClick={this.createRecipeZenScript}&gt; 合成 &lt;/Button&gt; &lt;/Col&gt; &lt;Col&gt; &lt;Button id='copy' type=&quot;primary&quot; shape=&quot;round&quot; icon={&lt;CopyOutlined/&gt;}onClick={this.onCopy}&gt; 复制脚本 &lt;/Button&gt; &lt;/Col&gt; &lt;/Space&gt; &lt;/Row&gt; &lt;br/&gt; &lt;Card &gt; {this.state.zenscript} &lt;/Card&gt; &lt;/div&gt; ); }}export default CraftTable; 最终效果图 写在最后本文主要讲的是CraftTweaker-Assistant这个项目的大致情况，以及遇到的一些问题。这个项目逻辑比较简单，主要是让我巩固一下React的相关知识。 现在完成的是最初的版本，只实现了最基本的功能，后续如果有时间，可能会和StringOD一起继续更新。","link":"/posts/CraftTweaker-Assistant/"},{"title":"python爬虫学习笔记3封装爬虫类","text":"在完成了基本的爬取任务之后，接到了将其封装为一个爬虫类的任务 传送门： python 爬虫学习笔记 1 一个简单的爬虫 python 爬虫学习笔记 2 模拟登录与数据库 前言转载注明出处。 任务介绍1、尝试不使用 session 去进行爬取，最好能将 cookies 保存下来可以供下次使用。2、第二个是尝试将这些封装成面向对象的方式，模拟登陆，爬取，解析，写入数据库这几个部分分离开来。 先做第二个任务 过程记录190310 周日创建爬虫类12345678class spider: ''' 爬虫类 ''' def __init__(self): self.session=requests.session()#初始化登录session self.is_login=False#登录状态 获取登录所需信息获取登录信息（账号密码以及校验码）这部分与登录可以分开，单独写一个成员函数。 在输入密码这个地方，本来查到可以使用getpass这个库里面的getpass()函数来使用类似 linux 的密码不回显，用法如下： 123import getpasspasswd=getpass.getpass()print(passwd)#测试用输出 但是直接在 pycharm 里面运行是会卡在输入那里，并且也会回显。后来查到了，这个方法是在命令行当中才管用，我试了一下在 python 命令行中使用， 123456&gt;&gt;&gt;import getpass&gt;&gt;&gt;passwd=getpass.getpass()Warning: Password input may be echoed.Password: &gt;? 123&gt;&gt;&gt;print(passwd)123 虽然可以使用了，但是仍然会回显。所以这个命令行说的应该不是 python 命令行，而是 cmd 或者 shell。 在虚拟环境的 cmd 里面，成功了，Password 后面未回显我的输入，下面的数字是测试用的输出，将密码打印出来。 123(venv) F:\\DEVELOP\\py_develop\\spider&gt;python test.pyPassword:123 不过为了方便调试代码，我还是使用了input()函数 参考链接： python3-password 在输入密码时隐藏密码-博客园 Python 之控制台输入密码的方法-博客园 12345678910111213141516171819202122232425def get_login_data(self,login_url): ''' 获取登录需要的数据 :param login_url: 登录页面url :return: 一个存有登录数据的字典 ''' # 获取登录校验码 html = self.session.post(login_url, headers=self.headers).text soup = BeautifulSoup(html, 'lxml') lt = soup.find('input', {'name': 'lt'})['value'] dllt = soup.find('input', {'name': 'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data = { 'username': input(&quot;请输入学号：&quot;), 'password': input(&quot;请输入密码：&quot;), 'btn': '', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } return login_data 登录123456789101112131415def login(self,login_url): &quot;&quot;&quot; 登录并返回已经登录的会话 :return: 已经登录的会话（session） &quot;&quot;&quot; login_data=self.get_login_data(login_url)#获取登录信息 # 登录 response = self.session.post(login_url, headers=self.headers, data=login_data) if response.url!=login_url:#如果没有跳转回登录页面，那么就是登录成功 print(&quot;登录成功&quot;) self.is_login=True else: print(&quot;登录失败&quot;) return self.session day8 进度 了解了一下 Python 类与对象的语法，尝试将代码封装到类中（一些中间代码未保留），不过想要将它改的有通用性（能够爬取其他网站）有些困难，还是先固定只能爬取信息门户 接下来的计划：将类完成之后再慢慢优化，学习使用 cookie 代替 session 保持登录，以及数据库的更多知识 190311 周一day9 进度 图书馆借了一本 mysql 的书籍，在 mysql 命令行上练习创建数据库，表以及字段的操作 在将代码封装成类的过程中，学习了如何将参数作为一个字典传入，以及将一个字典作为参数传入 190312 周二获取单页目录内的公告 url目录网页的内容： 关于……的通知 关于……获奖 …… 2700 条记录，分为 138 页显示，下一页 123456789101112131415161718192021222324252627def get_url_from_cata(self,url,params): ''' 返回当前页面的url组成的列表 :param url: 无参数的url#如：http://portal.xxx.edu.cn/detach.portal :param params:url的？后参数#如：?pageIndex=1 :return:以页面指向的标题和url组成的元组为元素的列表，即[(title,content),(title,content)]的形式 ''' #获取url域名部分 #如：http://portal.xxx.edu.cn base=url.split('/') base=base[0]+'//'+base[2] #获取当前页所有链接 html = self.session.post(url,params=params).text#用params参数来拼接参数 soup = BeautifulSoup(html, 'lxml') rss_title = soup.find_all('a', class_='rss-title')#获取所有链接 result_list=[] for url in rss_title: title=url.get_text().strip() page_url=base+'/'+url['href']#将url拼接完整 l=(title,page_url) result_list.append(l) #print(result_list) return result_list 获取所有目录内的公告 url1234567891011121314151617181920212223242526272829303132333435def get_url_from_cata_all(self, url): ''' 获取页面的底部跳转到其他页的链接并获取目录，给出一个目录页的url，获取相关的所有目录页的url并获取链接 :param url: 其中任何一个目录页的url#如：http://portal.xxx.edu.cn/detach.portal?pageIndex=1 :return:以所有页面的标题和url组成的元组为元素的列表，即[(title,content),(title,content)]的形式 ''' #获取除去参数之后的url #如：http://portal.xxx.edu.cn/detach.portal base=url.split('?')[0] html = self.session.post(url).text soup = BeautifulSoup(html, 'lxml') # 获取页数 reg = '共.*?条记录 分(.*?)页显示' reg = re.compile(reg, re.S) num = int(re.findall(reg, html)[0]) #获取url para = { 'pageIndex': 1, 'pageSize': '', '.pmn': 'view', '.ia': 'false', 'action': 'bulletinsMoreView', 'search': 'true', 'groupid': 'all', '.pen': 'pe65' } ret=[] for i in range(1,num+1): ret.extend(self.get_url_from_cata(base,params=para)) para['pageIndex'] = i return ret day10 进度实现了自动获取目录页数，并从每一页目录获取所有的 url，返回当前所有公告的 url 的列表 190313 周三获取正文123456789101112131415def get_page(self,url): ''' 提取页面中的公告正文 :param url: 页面url :return: 正文 ''' html = self.session.post(url, headers=self.headers).text soup = BeautifulSoup(html, 'lxml') bulletin_content = soup.find('div', class_='bulletin-content') bulletin_content =bulletin_content.get_text() return bulletin_content 保存到 txt123456789101112131415def save_by_txt(self,file_content,file_name): ''' 获取单个公告页面的公告并保存到txt :param file_content:文件内容(str) :param file_name:输出文件名(str) :return:无 ''' # 转换为可以作为文件名字的形式 reg = r'[\\/:*?&quot;&lt;&gt;|]' file_name = re.sub(reg, &quot;&quot;, file_name) with open(file_name, 'w', encoding='utf8') as fout: fout.write(file_content) print('成功保存到{}'.format(file_name)) 保存到 db1234567def save_by_db(self,content,title): #未改造完成 db = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd='root', db='news', charset='utf8') cursor = db.cursor() cursor.execute(&quot;insert into spider(`title`,`content`) values('{0}','{1}')&quot;.format(title, content)) db.commit() print('已经成功保存公告到数据库：“{}”'.format(title)) day11 进度尝试将保存到数据库的函数里面的数据库参数放到函数形参处，怎么弄都觉得不太合适，于是还是将原本的代码放入 190314 周四cookie 保持登录参考链接： Python——Cookie 保存到本地-知乎（解决了问题的主要链接） 爬虫保存 cookies 时重要的两个参数（ignore_discard 和 ignore_expires）的作用 首先是库 1import http.cookiejar 初始化12345def __init__(self,headers): self.session=requests.session()#初始化登录session self.is_login=False#登录状态 self.headers=headers#头信息 self.cookiejar=http.cookiejar.LWPCookieJar('cookie.txt') 保存 cookie 的函数大概是将已登录的 session 对象的 cookies 转换为字典（用了一个类似列表生成式的东西，查了一下，是字典生成式，python 还真是方便，这么多简写方式），然后保存到 cookiejar 对象中，调用save()函数来将 cookie 内容保存到第一个参数指定的文件中，即使 cookie 已经被抛弃和过期。 1234def save_cookie(self): requests.utils.cookiejar_from_dict({c.name: c.value for c in self.session.cookies}, self.cookiejar) # 保存到本地文件 self.cookiejar.save('cookies', ignore_discard=True, ignore_expires=True) 加载 cookie 的函数首先初始化一个 LWPCookieJar 对象 1load_cookiejar = http.cookiejar.LWPCookieJar() 接着从文件中加载 cookie 1load_cookiejar.load('cookies', ignore_discard=True, ignore_expires=True) 这里有个问题，这里如果加载失败了（没有这个文件，之前没有保存），需要知道已经失败了。所以使用一个 try 语句块测试一下。 然后把这个 LWPCookieJar 对象给转换成字典，再转换赋值给 session.cookie，这样就加载成功了 1234567891011121314151617def load_cookie(self): ''' 加载cookie :return: 是否成功 ''' load_cookiejar = http.cookiejar.LWPCookieJar() # 从文件中加载cookies(LWP格式) try: load_cookiejar.load('cookies', ignore_discard=True, ignore_expires=True) except: return False # 转换成字典 load_cookies = requests.utils.dict_from_cookiejar(load_cookiejar) # 将字典转换成RequestsCookieJar，赋值给session的cookies. self.session.cookies = requests.utils.cookiejar_from_dict(load_cookies) return True 修改后的 login()1234567891011121314151617181920def login(self,login_url): &quot;&quot;&quot; 登录并返回已经登录的会话 :return: 已经登录的会话（session） &quot;&quot;&quot; if self.load_cookie(): self.is_login = True else: #获取登录信息 login_data=self.get_login_data(login_url) # 登录 response = self.session.post(login_url, headers=self.headers, data=login_data) if response.url!=login_url: print(&quot;登录成功&quot;) self.is_login=True self.save_cookie() else: print(&quot;登录失败&quot;) return self.session day12 进度 完成了爬虫类的封装 使用 http.cookiejar 库实现了登录一次，在 cookie 有效期内不必再次登录的功能 代码总览import12345import requestsfrom bs4 import BeautifulSoupimport pymysqlimport reimport http.cookiejar 构造函数12345678910class spider: ''' 爬虫类 ''' def __init__(self,headers): self.session=requests.session()#初始化登录session self.is_login=False#登录状态 self.headers=headers#头信息 self.cookiejar=http.cookiejar.LWPCookieJar('cookie.txt') 获取登录信息12345678910111213141516171819202122232425def get_login_data(self,login_url): ''' 获取登录需要的数据 :param login_url: 登录页面url :return: 一个存有登录数据的字典 ''' # 获取登录校验码 html = self.session.post(login_url, headers=self.headers).text soup = BeautifulSoup(html, 'lxml') lt = soup.find('input', {'name': 'lt'})['value'] dllt = soup.find('input', {'name': 'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data = { 'username': input(&quot;请输入学号：&quot;), 'password': input(&quot;请输入密码：&quot;), 'btn': '', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } return login_data 登录12345678910111213141516171819202122def login(self,login_url): &quot;&quot;&quot; 登录并返回已经登录的会话 :return: 已经登录的会话（session） &quot;&quot;&quot; if self.load_cookie(): self.is_login = True else: #获取登录信息 login_data=self.get_login_data(login_url) # 登录 response = self.session.post(login_url, headers=self.headers, data=login_data) if response.url!=login_url: print(&quot;登录成功&quot;) self.is_login=True self.save_cookie() else: print(&quot;登录失败&quot;) return self.session 获取单页目录1234567891011121314151617181920212223242526def get_url_from_cata(self,url,params): ''' 返回当前页面的url组成的列表 :param url: 无参数的url :param params:url的？后参数 :return:以页面指向的标题和url组成的元组为元素的列表，即[(title,content),(title,content)]的形式 ''' #获取url域名部分 base=url.split('/') base=base[0]+'//'+base[2] #获取当前页所有链接 html = self.session.post(url,params=params).text#用params参数来拼接参数 soup = BeautifulSoup(html, 'lxml') rss_title = soup.find_all('a', class_='rss-title')#获取所有链接 result_list=[] for url in rss_title: title=url.get_text().strip() page_url=base+'/'+url['href']#将url拼接完整 l=(title,page_url) result_list.append(l) #print(result_list) return result_list 获取全部目录123456789101112131415161718192021222324252627282930313233def get_url_from_cata_all(self, url): ''' 获取页面的底部跳转到其他页的链接并获取目录，给出一个目录页的url，获取相关的所有目录页的url并获取链接 :param url: 其中任何一个目录页的url :return:以所有页面的标题和url组成的元组为元素的列表，即[(title,content),(title,content)]的形式 ''' #获取除去参数之后的url base=url.split('?')[0] html = self.session.post(url).text soup = BeautifulSoup(html, 'lxml') # 获取页数 reg = '共.*?条记录 分(.*?)页显示' num = int(re.findall(reg, html)[0]) #获取url para = { 'pageIndex': 1, 'pageSize': '', '.pmn': 'view', '.ia': 'false', 'action': 'bulletinsMoreView', 'search': 'true', 'groupid': 'all', '.pen': 'pe65' } ret=[] for i in range(1,num+1): ret.extend(self.get_url_from_cata(base,params=para)) para['pageIndex'] = i return ret 获取正文123456789101112131415def get_page(self,url): ''' 提取页面中的公告正文 :param url: 页面url :return: 正文 ''' html = self.session.post(url, headers=self.headers).text soup = BeautifulSoup(html, 'lxml') bulletin_content = soup.find('div', class_='bulletin-content') bulletin_content =bulletin_content.get_text() return bulletin_content 保存到 txt123456789101112131415def save_by_txt(self,file_content,file_name): ''' 获取单个公告页面的公告并保存到txt :param file_content:文件内容(str) :param file_name:输出文件名(str) :return:无 ''' # 转换为可以作为文件名字的形式 reg = r'[\\/:*?&quot;&lt;&gt;|]' file_name = re.sub(reg, &quot;&quot;, file_name) with open(file_name, 'w', encoding='utf8') as fout: fout.write(file_content) print('成功保存到{}'.format(file_name)) 保存到数据库123456def save_by_db(self,content,title): db = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd='root', db='news', charset='utf8') cursor = db.cursor() cursor.execute(&quot;insert into spider(`title`,`content`) values('{0}','{1}')&quot;.format(title, content)) db.commit() print('已经成功保存公告到数据库：“{}”'.format(title)) 保存 cookie1234def save_cookie(self): requests.utils.cookiejar_from_dict({c.name: c.value for c in self.session.cookies}, self.cookiejar) # 保存到本地文件 self.cookiejar.save('cookies', ignore_discard=True, ignore_expires=True) 加载 cookie123456789101112131415161718def load_cookie(self): ''' 加载cookie :return: 是否成功 ''' load_cookiejar = http.cookiejar.LWPCookieJar() # 从文件中加载cookies(LWP格式) try: load_cookiejar.load('cookies', ignore_discard=True, ignore_expires=True) except: print('cookie加载失败') return False # 转换成字典 load_cookies = requests.utils.dict_from_cookiejar(load_cookiejar) # 将字典转换成RequestsCookieJar，赋值给session的cookies. self.session.cookies = requests.utils.cookiejar_from_dict(load_cookies) return True 爬取12345678def crawl(self,login_url,cata_url): self.login(login_url)#登陆 item_list=self.get_url_from_cata_all(cata_url)#获取所有标题以及对应链接 for i in item_list: title,url=i#解包 text=self.get_page(url)#获取内容 self.save_by_txt(text,title+'.txt')#保存 #self.save_by_db(text,title) 调用123456789headers={ 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',}login_url='http://xxx.xxx.xxx.cn/authserver/login?service=http%3A%2F%2Fportal.chd.edu.cn%2F'cata_url='http://xxxxxx.xxx.xxx.cn/detach.portal?pageIndex=1&amp;pageSize=&amp;.pmn=view&amp;.ia=false&amp;action=bulletinsMoreView&amp;search=true&amp;groupid=all&amp;.pen=pe65'#调用spiderman=spider(headers)spiderman.crawl(login_url, cata_url)","link":"/posts/python_spider_note3class_spider/"},{"title":"java基于AWT的对战小游戏","text":"这学期的 java 课设弄完了，写个博客总结一下。 哔哩哔哩对应视频的传送门 课设目的与要求根据讲义中策略模式的案例，设计和实现一个基于策略模式的角色扮演游戏。其中包括主要有角色类及其子类、相关的行为类集合和测试类等。 通过本次实验，能够在掌握面向对象程序设计的基本思想基础上；深化理解 Java 面向对象程序设计中消息、继承、多态、接口、抽象类和抽象方法等概念和实现方式；并进一步掌握 Java 程序设计中的基本语法和 Java 程序运行方法等；理解和应用包（package）。 内容一个游戏中有多种角色(Character)，例如：国王（King）、皇后（Queen）、骑士（Knight）、老怪（Troll）。角色之间可能要发生战斗(fight)，每场战斗都是一个角色与另一角色之间的一对一战 斗。 每个角色都有自己的生命值 (hitPoint) 、 魔法值（magicPoint）、攻击力值(damage)和防御力值(defense)。 每种角色都有一种武器进行攻击（fight）；在程序运行中，可以动态修改角色的武器(setWeaponBehavior)。 每种角色都有一种魔法对自己或者其他角色施法（performMagic）；可以动态改变拥有的魔法（setMagicBehavior）。 首先设计和实现抽象类 Characters。 设计和实现 Character 类的几个子类：King、Queen、Knight、Troll。位 设计接口 WeaponBehavior 和 MagicBehavior。 接 口 WeaponBehavior 的 实 现 类 ： KnifeBehavior （ 用 刀 ） BowAndArrowBehavior （ 用 弓 箭 ） AxeBehavior （ 用 斧 ） SwordBehavior（用剑） 接口 MagicBehavior 的实现类： HealBehavior（治疗） InvisibleBehavior（隐身）。 实现接口中的抽象方法，可以只在屏幕输出简单信息，也可以结合生命值(hitPoint)、攻击力值(damage)和防御力值(defense)计算。 编写测试代码，对以上设计的系统进行测试。要求在程序运行期间，能动态改变角色拥有的武器或者魔法。 自己添加一种角色、或者添加一种武器及魔法，设计相应的类，并编写测试代码进行测试。 按照 Java 的规范，添加详细的文档注释，并用 Javadoc 生成标准的帮助文档。 将上述编译、运行、生成帮助文档的命令，填写至实验报告相应位置。 填写实验报告。并将程序代码及生成的帮助文档打包上交。 涉及的主要内容 单例模式。游戏窗口只能有一个对象，因此使用了单例模式。 策略模式。在角色类中有两个抽象策略（武器策略和魔法策略），具体策略在类中实现。 双缓冲技术。在绘制游戏画面的时候使用了双缓冲技术，防止画面闪烁。 多线程。在两处使用了多线程，一处是为了解决按键冲突的问题，另一处是为了实现游戏周期性判定的功能。 awt。 基本逻辑流程 抽象角色类由具体子类实现，子类主要实现了抽象方法getAppearance，用于获取角色的外貌（即图片），外貌会根据角色状态的不同而改变，比如角色死亡时外貌是墓碑； 根据角色的坐标以及属性（例如是否隐身，当前武器是什么）来绘制角色以及属性条、武器栏和魔法栏。 游戏时钟周期线程用于周期性地执行一些操作，例如每秒钟恢复一定的 HP 和 MP，对于隐身状态的角色，每秒钟扣除一定量的 MP 等。 游戏说明 玩家 1 操作：键盘上 A 键 D 键分别对应左右移动，J 键使用武器攻击，K 键使用魔法，L 键切换武器，O 键切换魔法； 玩家 2 操作：键盘上 ← 键 → 键分别对应左右移动，小键盘上，1 键使用武器攻击，2 键使用魔法，3 键切换武器，6 键切换魔法； 每把武器有自己的攻击威力和攻击距离，只有在两个角色的距离在武器的攻击范围内时，才能够攻击成功； 伤害计算公式为：被攻击者受到的最终伤害=攻击者攻击力+攻击者武器威力-被攻击者的防御力。若伤害小于等于 0，则不予扣除； 每秒钟会恢复一定量的 HP 和 MP； 一方死亡（HP 降为 0 及以下）则游戏结束。 设计与实现主要框架12345678910111213141516171819202122public class FightFieldFrame extends Frame{ //一些游戏常量以及窗口 public static final Dimension SCREEN_DIMENSION=Toolkit.getDefaultToolkit().getScreenSize(); public static final int FFF_X=0; public static final int FFF_Y=0; public static final int FFF_HEIGHT=SCREEN_DIMENSION.height; public static final int FFF_WIDTH=SCREEN_DIMENSION.width;//……省略其他成员函数，下面会列举来说明/*******************main函数**************************/ public static void main(String args[]) { FightFieldFrame f=getInstance(&quot;战斗领域&quot;); f.initFrame(); //初始化角色 f.initCharacter(); //添加事件监听者 f.addWindowListener(new MyWindowListener()); f.addKeyListener(new GamePad(player1,player2,f)); //新建时钟线程，用于游戏中的周期性属性检查 Thread clockThread=new Thread(new ClockThread(player1, player2, fff)); clockThread.start(); }} 单例模式FightFieldFrame 类中： 1234567891011//只能有一个窗体对象，使用单例模式private static FightFieldFrame fff;//单例模式使用的对象private FightFieldFrame(String title) { super(title);}public static FightFieldFrame getInstance(String title) { if(fff==null) { fff=new FightFieldFrame(title); } return fff;} 双缓冲双缓冲因为有两个绘图对象而得名，先在一个 image 对象上绘图然后再将此对象绘制到 Frame 上，用于减少重绘时的闪烁。 123456789101112/** * 初始化框架的位置和大小，以及缓冲对象 */public void initFrame() { //这里准备一些对象构造完成之后才能做的事情 fff.setVisible(true); setBounds(FFF_X, FFF_Y, FFF_WIDTH, FFF_HEIGHT); Dimension d=getSize(); imgBuffer=createImage(d.width, d.height); gBuffer=imgBuffer.getGraphics();} 创建好缓冲对象后，在缓冲对象上绘制： 123456789101112131415161718192021222324public void paint(Graphics g) { //全都先绘制在缓冲区 //绘制背景 Image background=getToolkit().getImage(&quot;image\\\\background.jpg&quot;); if(background!=null) { gBuffer.drawImage(background, FFF_X, FFF_Y, FFF_WIDTH, FFF_HEIGHT, this); } //绘制人物 if(player1!=null) { drawCharacter(gBuffer,player1); drawStrand(gBuffer, player1); } if(player2!=null) { drawCharacter(gBuffer,player2); drawStrand(gBuffer, player2); } drawSlot(gBuffer); //drawStrand(gBuffer);//绘制绝对位置的属性条，由于没有什么技术含量就只做了一个示例 //由于使用了背景图片，所以不必特地清空背景 g.drawImage(imgBuffer, 0, 0, this);} 但是，即便如此仍然会闪烁，这是因为重绘时调用的 update 函数会将 Frame 用背景色填充一次 再绘制。所以应该覆盖掉原本的方法，让它只绘制，不清空： 123456//======================//public void update(Graphics g) { //覆盖原本的方法 paint(g);}//======================/*/ 玩家操纵使用 GamePad 类作为键盘监听者，监听 Frame 的按键，调用角色对应的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * 游戏手柄类 * 用于将键位与角色的动作对应起来 */public class GamePad implements KeyListener{ private Characters player1;//玩家1 private Characters player2;//玩家2 private FightFieldFrame fff; public GamePad(Characters p1, Characters p2, FightFieldFrame f) { // TODO Auto-generated constructor stub player1=p1; player2=p2; fff=f; } @Override public void keyPressed(KeyEvent e) { int code=e.getKeyCode(); switch (code) { case KeyEvent.VK_J://玩家1攻击 player1.fight(player2); player2.display(); break; case KeyEvent.VK_K://玩家1使用魔法 player1.performMagic(player2); break; case KeyEvent.VK_A://玩家1左 player1.setMoveLeftFlag(true); player1.setDirection(true);//false为朝右，true为朝左 break; case KeyEvent.VK_D://玩家1右 player1.setMoveRightFlag(true); player1.setDirection(false); break; case KeyEvent.VK_L://玩家1切换武器 player1.changeWeapon(); break; case KeyEvent.VK_O://玩家1切换魔法 player1.changeMagic(); break; /****************************************************************/ case KeyEvent.VK_NUMPAD1://玩家2攻击 player2.fight(player1); player1.display(); break; case KeyEvent.VK_NUMPAD2://玩家2使用魔法 player2.performMagic(player1); break; case KeyEvent.VK_LEFT://玩家2左 player2.setMoveLeftFlag(true); player2.setDirection(true);//false为朝右，true为朝左 break; case KeyEvent.VK_RIGHT://玩家2右 player2.setMoveRightFlag(true); player2.setDirection(false); break; case KeyEvent.VK_NUMPAD3://玩家2切换武器 player2.changeWeapon(); break; case KeyEvent.VK_NUMPAD6://玩家2切换魔法 player2.changeMagic(); break; default: break; } fff.repaint();//重绘 } @Override public void keyReleased(KeyEvent e) { int code=e.getKeyCode(); switch (code) { case KeyEvent.VK_J: break; case KeyEvent.VK_A://左 player1.setMoveLeftFlag(false); break; case KeyEvent.VK_D://右 player1.setMoveRightFlag(false); break; case KeyEvent.VK_K: break; case KeyEvent.VK_NUMPAD1: break; case KeyEvent.VK_LEFT: player2.setMoveLeftFlag(false); break; case KeyEvent.VK_RIGHT: player2.setMoveRightFlag(false); break; default: break; } fff.repaint();//重绘 } @Override public void keyTyped(KeyEvent e) {}} 注意，这里控制角色左右移动并不是直接调用角色的移动方法，而是更改角色移动的标志变量，利用线程来调用角色的移动方法。这样可以解决角色的按键冲突问题。 角色移动线程移动线程只负责发送消息给角色，而角色移动的具体判定由角色自身完成，从而更好地实现面向对象的思想。 1234567891011121314public class MoveThread implements Runnable{ private Characters character; public MoveThread(Characters c) { character=c; } public void run() { while(true) { //线程只负责发送消息，让角色自己判断移动 character.moveRight(); character.moveLeft(); } }} 下面这是 Characters 类中的角色移动函数，添加了延时以免在按下移动按键的一瞬间，角色移动太快出了屏幕外面。 12345678910111213141516171819202122232425262728293031/** * 向左移动&lt;br/&gt; * 由于两个线程各自操作自己的角色，所以此函数不需要同步 */public void moveLeft() { if(!isAliveFlag) return; if(moveLeftFlag) { x-=1; try { Thread.sleep(1);//防止跑得太快 } catch (InterruptedException e) { e.printStackTrace(); } }}/** * 向右移动&lt;br/&gt; * 由于两个线程各自操作自己的角色，所以此函数不需要同步 */public void moveRight() { if(!isAliveFlag) return; if(moveRightFlag) { x+=1; try { Thread.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } }} 武器攻击实现机制在 Characters 类中，使用武器进行攻击的方法如下，它的主要逻辑是调用 useWeapon 方法： 1234567891011121314151617181920212223/** * 攻击某个角色 * @param c 要攻击的角色 * @return 造成的真实伤害 */public int fight(Characters c) { //由于武器有不同的特性，所以伤害的逻辑让武器实现 //比如后期编写高级玩法时，弓需要计算射程 if(!isAliveFlag) return 0;//如果已死亡，直接返回，下同 if(weapon==null) { System.out.println(name+&quot;没有武器，无法攻击&quot;); return 0; } int attackRange=weapon.getAttackRange(); if(attackRange&gt;distance(c)) { //攻击距离大于角色之间的距离才可攻击 return weapon.useWeapon(this,c);//此角色攻击角色c } else { return 0; }} 角色类的两个属性，武器和魔法，使用的都是对应接口的引用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152protected WeaponBehavior weapon;//武器protected MagicBehavior magic;//魔法以下是武器接口：public interface WeaponBehavior { /** * 使用武器 * @param attacker 武器持有者 * @param victim 被攻击者 * @return 造成的真实伤害 */ public int useWeapon(Characters attacker,Characters victim);//使用武器 public String getName(); public int getAttackRange(); public Image getAppearance();}以下是具体的武器实现（以剑为例，其他大同小异）：/** * 剑 * 实现武器接口 * 威力中等，攻击距离中等 */public class SwordBehavior implements WeaponBehavior { private String name=&quot;剑&quot;; private Image appearance; private static final int DAMAGE=6;//武器基础威力 private static final int ATTACK_RANGE=200;//武器攻击距离,单位px private static final String APPEARANCE_PATH=&quot;image\\\\Weapon\\\\Sword.png&quot;; public SwordBehavior() {} public SwordBehavior(String _name) { name=_name;//剑，岂能无名OVO } /** * 使用武器攻击 * @param attacker 攻击者 * @param victim 被攻击者 */ @Override public int useWeapon(Characters attacker,Characters victim) { int attackDamage=DAMAGE+attacker.getDamage();//造成的伤害为攻击者的伤害加上武器威力 int finalDamage=victim.hitBy(attacker, attackDamage); System.out.println(attacker.getName()+&quot;使用&quot;+name+&quot;对&quot;+victim.getName()+&quot;造成了&quot;+finalDamage+&quot;点伤害&quot;); return finalDamage;//返回最终伤害 } public String getName() {return name;} public int getAttackRange() {return ATTACK_RANGE;} public Image getAppearance() { appearance=Toolkit.getDefaultToolkit().getImage(APPEARANCE_PATH); return appearance; }} 这里面主要的代码是 useWeapon 方法里面调用的角色类的 hitBy 方法，里面有着伤害计算逻辑： 123456789101112131415/** * 被某个角色攻击 * @param attacker 攻击者 * @param attackDamage 攻击者给予的攻击伤害 * @return 最后造成的真实伤害 */public int hitBy(Characters attacker,int attackDamage) {//被攻击 if(!isAliveFlag) return 0; int finalDamage=(attackDamage-defense);//伤害计算：最终伤害=敌方攻击伤害-我方防御力 if(incHP(-finalDamage)==-1) {//如果血量被扣到负数 this.killedBy(attacker); } return finalDamage;//返回最后造成的真实伤害} 魔法的实现机制大同小异，不做特殊说明。 武器切换和魔法切换实现方法是在角色类里面声明数组： 12345protected WeaponBehavior weaponSlots[];//武器栏位，用于存储角色携带的武器protected MagicBehavior magicSlots[];//魔法栏位protected int weaponSlotsIndex=0;//栏位索引，指示当前武器protected int magicSlotsIndex=0; 以切换武器为例，如果当前武器是最后一把，那么换回第一把，否则索引自增： 123456789101112/** * 按顺序切换武器 */public void changeWeapon() { setWeaponBehavior(weaponSlots[weaponSlotsIndex]); if(weaponSlotsIndex+1&gt;=weaponSlots.length) { weaponSlotsIndex=0; } else { weaponSlotsIndex++; }} 时钟线程时钟线程用于进行一些游戏周期性方法的调用，比如周期性恢复 HP，对角色属性值的判断等。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 时钟线程，用于一些周期性的计算 */public class ClockThread implements Runnable{ private Characters player1;//玩家1 private Characters player2;//玩家2 private FightFieldFrame fff; private int interval=1000;//时钟周期 public ClockThread(Characters p1, Characters p2, FightFieldFrame f) { player1=p1; player2=p2; fff=f; } /** * 核对属性，并对于特定属性作出不同的事情 * @param c 核对角色c的属性 */ public void cheackStatus(Characters c) { switch (c.getStatus()) { case Characters.ST_INVISIBLE://隐身魔法每个周期扣除一定的魔力 if(c.incMP(-InvisibleBehavior.COST)==-1) {//如果魔力不够 c.setStatus(Characters.ST_NORMAL); } break; default: break; } } /** * 周期性恢复属性值（回血回魔） * @param c 周期性恢复角色c的HP和MP */ public void recover(Characters c) { if(!c.getIsAliveFlag()) return;//角色死亡就不再回血 c.incHP(Characters.HP_RECOVER); c.incMP(Characters.MP_RECOVER); } public void run() { while(true) { //做这个周期要做的事情 cheackStatus(player1); cheackStatus(player2); recover(player1); recover(player2); fff.repaint(); //等待下一个周期 try { Thread.sleep(interval); } catch (InterruptedException e) { e.printStackTrace(); } } }} 参考链接 java.awt.Image 官方文档 使用 eclipse 生成 javadoc-博客园 java 双缓冲技术-CSDN java 获取屏幕大小-CSDN java 线程传参三种方式-脚本之家 游戏角色移动流畅度的处理-ITeye eclipse 调试方式和快捷键-CSDN 一个讲 eclipse 调试的 b 站视频（靠这个视频解决了调试问题）-bilibili 绘制字体修改-CSDN 体会这次课设对我来说是个挑战，首先时间比较紧张，和考试放在了一周，并且用的是学了几周还没私底下练习多少的 JAVA。不过还是做的让我自己比较满意。 我选择的是看上去较为简单的一道题目，虽然简单，但是这个题目的可扩展性很强，可以尽情开脑洞，我看中的就是这一点。我在高中的时候就尝试使用 Visual Basic 来编写类似的小游戏，一些可能会遇到的困难在那时已经思考过了，所以总体来说没有遇到太过麻烦的地方。 随着经验的增长，我逐渐开始一边编程一边整理，让以后的自己也能够回顾这一次的项目。在写完这个课设之后，我用录屏软件录制了一个视频来整体讲述我编写过程中的思路，并上传到了 Bilibili 弹幕视频网站，总结经验，分享思路，以及为了便于以后回顾。地址是（https://www.bilibili.com/video/av54526303/） 当然，过程中也遇到了一些问题。 比如绘制图片的时候遇到了只能使用绝对路径的问题，在老师上课演示的过程中也遇到过这个问题，后来我知道了 JAVA 相对路径是以项目根目录为基准而不是以文件目录为基准的。 比如角色控制按键冲突。解决方法是使用多线程，两个线程控制分别控制两个角色。 比如游戏周期性事件。在以前我使用 Visual Basic 的时候，是利用时钟控件来解决这个问题的，而 JAVA 里面可以使用线程来模拟那个时钟控件。这让我对时钟控件的原理有了比较好的认识。 在假期里面，我可能会通过继续完善这个小游戏，来更加深入地学习 JAVA。","link":"/posts/java_game_FightFieldFrame/"},{"title":"【课设总结】基于LAN的即时通信软件","text":"本学期开了计算机网络课程，期末的课程设计我选了这个题目——基于 LAN 的即时通讯软件，题目就只有这么短，剩下的全部自己发挥，不限平台不限语言。 由于以前自学过 c++网络编程，写了个简易的聊天室（bug 百出），所有刚开始也想用 c++来写，新建了 MFC 项目正在画界面的时候，才想起今时不同往日，我会的语言不止 c++了，还有 java 和 python。最后决定用 python，虽说 java 写的可能以后会更好扩展更好维护一些，但是 python 写起来应该会更加轻松（个人看法）。 本文基于我当时写的课设报告，在之后可能会将其中学到的知识整理成其他的博文，并在此文中列出。 b 站视频已上传：【课设思路分享】基于 LAN 的即时通讯软件 对应 github 库传送门：simuqq 比较长，配合侧边栏目录食用。 效果展示程序分为服务端和客户端两部分，服务端无图形界面，客户端具有登录界面、主界面以及聊天窗口界面总共三个图形界面。 先开启服务端程序，再打开客户端程序。 客户端的初始界面是登陆界面，在这个界面可以输入用户名、密码，具有“登录”和“注册”两个按钮。 在输入用户名和密码登录之后，会跳转到主页面。 主页面显示账号个人信息，以及当前在线的其他账号的用户名。用户可以双击选择当前在线的其他账号打开聊天窗口进行聊天。 其中一人断开连接之后： 环境 操作系统 windows10 编辑器（没影响） visual studio code 解释器 python3.7.0 需求分析画个用例图先： 客户端的用例有注册、登录、连接到服务端、查看在线的其他客户端以及选择聊天对象。 其中，选择聊天对象进行聊天需要先查看当前有哪些客户端在线，而在这之前需要登录。 代码文件结构 client.py：客户端业务逻辑代码 server.py：服务端代码 gui home_page.py：登录后跳转到的主页面 login_dlg.py：登录界面 chat_dlg.py：聊天界面 account_database.json：用于存放注册账号数据的数据文件 utility.py：存放一些自己写的工具函数 概要设计及对应代码为了方便阅读，就将代码部分与设计部分放在一起。 类 界面类图形界面使用的是 python 自带的 tkinter 模块。对每个界面，单独编写一个类，放在单独的模块中，存放在代码根目录下的 gui 文件夹内。而业务逻辑另外编写 client 类和 server 类。 令界面与业务逻辑结合的方式是，在 client 类中初始化界面时，将自身的处理函数作为回调函数传入界面类中，从而使界面的组件与回调函数绑定。 登录界面代码示例因为界面不是重点，故仅放出登录界面代码，其他两个界面类类似。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768'''登录模块login_dlg.py展示登录窗口并实现登录功能'''import tkinter as tkimport gui.chat_dlgclass LoginDlg(tk.Frame): def __init__(self, loginCallback, regCallback, master=None): super().__init__(master=master) self.master = master self.geometry() # 设置按钮回调函数 self.loginCallback = loginCallback self.regCallback = regCallback # 初始化 self.userName = tk.StringVar() # 与文本框双向绑定 self.password = tk.StringVar() # self.pack() # self.grid(row=0,column=0) self.createWidgets() def createWidgets(self): # 登录框架============= loginLF = tk.LabelFrame(self, text='登录') loginLF.grid(row=0, column=0, sticky=tk.E+tk.W) self.loginLF = loginLF # 这里需要将它保存为属性，否则这个函数结束后会出问题 # 用户名 self.userNameLab = tk.Label(loginLF, text='用户名') self.userNameLab.grid(row=0, column=0) self.userNameEntry = tk.Entry(loginLF, textvariable=self.userName) self.userNameEntry.grid(row=0, column=1, columnspan=2) # 密码框 self.passwdLab = tk.Label(loginLF, text='密码') self.passwdLab.grid(row=1, column=0) self.passwdEntry = tk.Entry( loginLF, show='*', textvariable=self.password) self.passwdEntry.grid(row=1, column=1, columnspan=2) # 登录按钮 self.loginBtn = tk.Button( loginLF, text='登录', command=self.loginCallback) self.loginBtn.grid(row=2, column=1) # 注册按钮 self.signupBtn = tk.Button( loginLF, text='注册', command=self.regCallback) self.signupBtn.grid(row=2, column=2) def test(self): print(self.userName.get()) print(self.password.get()) def geometry(self): self.master.geometry('300x100')#用于调整窗口大小def test2(): pass#用于在本模块内测试用的函数if __name__ == '__main__': window = tk.Tk() loginDlg = LoginDlg(test2, test2, window) loginDlg.mainloop() 客户端类 Client客户端掌握着界面对象的引用，在初始化它们时，将自身的处理函数传入给它们，以便在触发界面事件时调用。 客户端主要提供了以下方法： 方法 简介 connect 连接到服务器 login 登录，需要调用 connect，由服务端进行合法性检测 register 注册，为了简化而直接由客户端写入文件 send 构造消息并发送给服务端 recv 接收消息并解析 为了客户端与服务端交流的便利，我自定义了消息格式，所以发送时需要封装，接收时需要解析，下文会讲。 服务端类 Server服务端没有界面（做了就做不完了），负责接收连接以及转发客户端之间的聊天消息。ip 以及端口是固定的。 数据文件格式已经注册的账号信息使用 json 文件保存（即account_database.json），保存格式如下： 12345678910{ &quot;用户名1&quot;: { &quot;password&quot;: &quot;密码1&quot;, &quot;registerTime&quot;: 注册时间1 }, &quot;用户名2&quot;: { &quot;password&quot;: &quot;密码2&quot;, &quot;registerTime&quot;: 注册时间2 }} 使用用户名作为键，每个用户对应一个密码以及一个注册时间。 自定义消息（这个是我自己规定的服务端和客户端之间交换信息的格式） 客户端不直接与另一个客户端通信，而是通过服务端转发。 客户端与服务端之间发送规定格式的 json 字符串来交流，此字符串以下称之为“消息”，聊天的文字称作“聊天消息”。此格式解析出来是 python 的一个字典，也就是 json 里面的对象，可以方便地使用键值对来找到需要的字段值。字段如下（不是所有的字段都同时被设置）： 字段 说明 type 当前消息类型（必选） userName 用户名 password 密码 errStr 错误字符串 infoStr 信息字符串 message 聊天消息 data 传递的数据 其中 type 字段的值以及对应的必选字段如下： 登录 login：必须设置 userName 和 password，用于客户端发送登录请求以及服务端发送确认； 数据刷新 data：必须设置 data，且为字典，用于服务端给客户端发送更新后的当前在线列表； 聊天消息 msg: 必须设置 message 和 userName，用于客户端向另一个客户端发送聊天消息时使用，其中 message 是聊天消息的内容。当源客户端向服务端发送此消息时，userName 是目的客户端的用户名，服务端接收到消息之后，将 userName 改为源客户端的用户名，然后转发消息给目的客户端； 提示 info: 必须设置 infoStr，发送提示信息 错误 err:必须设置 errStr，发送错误信息 注册注册时客户端读取数据文件并检查注册信息合法性，用户名不可重复，密码可以重复，用户名和密码都是字符串。 当注册信息合法，就组装 json 字符串，并写入数据文件。 注意：这里本来应该是客户端将注册信息发送给服务端，然后服务端修改数据文件的，但是我为了防止自己写不完，就简化了这个流程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#...import utility#只强调一下这个是自定义模块class Client: #... def register(self): ''' 注册 在填写了用户名和密码之后，如果信息合法，则将信息写入数据文件 :return: 注册成功返回0,失败返回-1 ''' # 从登录对话框获取信息 userName = self.gui['loginDlg'].userName.get() password = self.gui['loginDlg'].password.get() # 检查合法性 if userName == '': utility.showerror('用户名不能为空') return -1 if password == '': utility.showerror('密码不能为空') return -1 with open(self.dataFile, 'a+') as fp: # 使用a+方式打开，防止文件内容被覆盖 fp.seek(0) # 调整指针到开头 accountStr = fp.read() if accountStr == '': # 如果文件内没有内容，即刚刚创建 accountData = {} else: # 否则读取文件内容 fp.seek(0) accountData = json.loads(accountStr) if userName in accountData.keys(): utility.showerror('该用户名已经被注册') return -1 # 写入数据文件 accountData.update({ userName: { 'password': password, 'registerTime': time.time() } }) utility.showinfo('注册成功！') fp.seek(0) fp.truncate() # 只保留从开头到当前位置，其余删除#当前位置为开头，故为全部删除 json.dump(accountData, fp, indent=4, separators=(',', ':')) return 0 这一部分的要点在于，文件中存储的是 json 字符串，不能简单地添加到文件末尾，而是需要将数据先读取出来，添加完数据后，再将整个文件覆盖。 登录客户端首先尝试连接服务端，如果成功再进行下一步。 请求登录客户端向服务端发送登录请求消息，并等待服务端的确认消息。 登录请求消息的结构： 字段 值 type login userName 用户名输入框中的值 password 密码输入框中的值 12345678910111213class Client: def sendLoginData(self, userName: str, password: str): ''' 发送登录数据 ''' # 构造并发送消息 accountData = { 'type': 'login', 'userName': userName, 'password': password } accountStr = utility.dumpJson(accountData) self.send(accountStr) 服务端收到登录请求消息之后，检查账号信息的合法性。会向客户端回复两种消息，错误消息或者登录确认消息。 处理登录请求登录失败如果账号信息错误，服务端向此客户端发送错误消息，并断开与它的连接。错误消息包含以下字段： err 消息的结构： 字段 值 type err errStr 错误信息 客户端收到此错误消息后，显示警告对话框，并重置 socket。 登录成功若服务端检测到账号信息无误，则向此客户端发送确认消息，并将它的 socket、地址以及登录时间加入到在线列表中，并向其他在线的客户端发送数据刷新消息（见下文）。 登录确认消息的结构： 字段 值 type login userName 置为空字符串 password 置为空字符串 infoStr 可选，登录成功提示 data 设置为当前在线账户列表 这是服务端处理登录请求的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Server: def acceptLogin(self, cliSock, cliAddr): ''' 接受已连接的客户端的登录请求 :return: 登录成功返回0，失败返回-1 ''' # 获取客户端提交的账号密码，客户端以json字符串的形式发送过来 loginStr = cliSock.recv(self.bufsize).decode() loginDict = utility.loadJson(loginStr) # 检查登录消息是否正确 if not utility.isCorrectMsg(loginDict): errStr = '数据有误，请重新连接' self.closeLink(cliSock, errStr) # 关闭连接 return -1 # 检查账号 cliUserName = loginDict['userName'] cliPassword = loginDict['password'] res = self.checkAccount(cliUserName, cliPassword) if res == -1: errStr = '账号不存在' self.closeLink(cliSock, errStr) # 关闭连接 return -1 elif res == -2: errStr = '密码错误' self.closeLink(cliSock, errStr) # 关闭连接 return -1 else: logging.info('用户[userName={}]登录成功'.format(cliUserName)) # 将新用户加入在线列表 self.onlineClients.update({ cliUserName: { 'socket': cliSock, # 客户端socket 'address': cliAddr, # 客户端地址 'loginTime': time.time() # 登录时间 } }) # 登录成功，向该客户端发送确认消息 self.sendLoginAck(cliSock) return 0 def sendLoginAck(self, cliSock): ''' 登录成功之后向客户端发送确认消息以及当前在线客户端列表 ''' curOnline = self.getCurOnline() # 获取当前在线列表 msgDict = { 'type': 'login', 'infoStr': '登录成功！', 'data': curOnline, 'userName': '', 'password': '' } self.send(cliSock, **msgDict) 等待确认发送了登录请求消息之后，客户端会等待服务端发来的登录确认消息或者错误消息。 12345678910111213141516171819202122232425262728293031323334353637class Client: def recvLoginAck(self): ''' 等待服务端传回确认 :return: 成功返回0，失败返回-1 ''' res = self.recv() res = utility.loadJson(res) # 检查消息合法性 if not utility.isCorrectMsg(res): self.resetSock() return -1 if res['type'] == 'err': # 如果收到的是服务端的错误消息 utility.showerror(res['errStr']) self.resetSock() # 重启socket return -1 elif res['type'] == 'login': # 登录成功，输出信息 if 'infoStr' in res.keys(): utility.showinfo(res['infoStr']) else: utility.showinfo('登录成功') if 'data' in res.keys(): self.contactList = res['data']['curOnline'] self.gui['homePage'].refreshList(self.contactList) else: contactList = {} return 0 else: # 如果不是err消息也不是确认消息，则登录失败 self.resetSock() return -1 客户端登录代码1234567891011121314151617181920212223242526272829303132333435363738class Client: def login(self): ''' 登录 :return: 登录成功返回0，失败返回-1 ''' # 从登录对话框获取信息 userName = self.gui['loginDlg'].userName.get() password = self.gui['loginDlg'].password.get() # 检查合法性 if userName == '': utility.showerror('用户名不能为空') return -1 if password == '': utility.showerror('密码不能为空') return -1 # 如果连接成功，向服务器发送信息 res = self.connect() if res != 0: return -1 # 构造并发送消息 self.sendLoginData(userName, password) # 如果发送信息成功，且账号信息正确，则弹出好友列表页面 # 等待服务端的确认信息 if self.recvLoginAck() == 0: # 跳转到主页面 self.userName = userName self.gotoHomePage() # 开启接收消息线程 self.recvThread = threading.Thread(target=self.recvLoop) self.recvThread.setDaemon(True) self.recvThread.start() else: return -1 登录的流程如下图所示： 客户端界面跳转登录成功后，会从登陆界面跳转到主页面。 原理是将登录界面隐藏，再显示主界面。 12345678910111213class Client: def gotoHomePage(self): ''' 跳转到主页面 ''' for page in self.gui.keys(): self.gui[page].grid_forget() self.window.title('SimuQQ主页面') self.gui['homePage'].grid(row=0, column=0) self.gui['homePage'].userName.set(self.userName) self.gui['homePage'].geometry() 打开聊天窗口： 1234567891011class Client: def openChatWindow(self, userName): ''' 打开聊天窗口 :param userName: 聊天对象的用户名 ''' self.chatWith = userName # 设置聊天对象 self.gui['chatDlg'].grid(row=0, column=0) self.chatWindow.title('[{}]向[{}]发起的聊天'.format(self.userName, userName)) self.chatWindow.deiconify() # self.chatWindow.mainloop() 发送聊天消息用户在客户端的在线列表中双击选择一个在线客户端，会打开对选择对象的聊天窗口。 用户在输入框中输入聊天消息并点击发送按钮后，客户端将会构建并发送 msg 消息给服务端，该消息的内容如下： msg 消息的结构： 字段 值 type msg message 需要发送给聊天对象的聊天消息 userName 聊天对象的用户名 服务端在收到客户端的 msg 消息后，将 userName 字段修改为发送端的用户名，并转发给目的端。 12345678910111213141516171819202122232425class Client: def sendChatMsg(self): ''' 发送聊天消息 ''' # 获取聊天窗口的输入框内文字 chatMsg = self.gui['chatDlg'].getInputContent() # 构造消息 msgDict = { 'type': 'msg', 'userName': self.chatWith, 'message': chatMsg } msgStr = utility.dumpJson(msgDict) # 发送消息 self.send(msgStr) # 同时在自己这边显示自己说的话 # 构建输出内容 outputContent = '[{}]{}\\n{}'.format( self.userName, time.strftime('%Y/%m/%d %H:%M:%S'), chatMsg) self.gui['chatDlg'].addOutputContent(outputContent) # 清空输入框 self.gui['chatDlg'].clearInputContent() 客户端消息处理客户端在登录成功后，开启消息接收线程，它的线程体是一个无限循环，并将其置为守护线程（Deamon Thread），在所有前台线程结束之后，消息接收线程也随之结束。 在没有注意到这一点前，我调试了这个 bug 很久——关闭窗口会无响应，后来才知道不是 tkinter 的问题，而是我开的这个线程没有随之关闭。 客户端主要会收到两种消息，数据刷新消息和聊天消息。同样的，这里本来还应该处理 err 消息以及 info 消息的，担心做不完就简化了。 数据刷新消息在服务端接收一个新的连接时，或是服务端检测到一个旧有连接断开时，会向当前在线的客户端发送一个数据刷新消息，该消息包含以下字段： data 消息的结构： 字段 值 type data data 当前在线账号的用户名的列表 客户端收到此消息时，调用界面类的对应方法刷新主页面的在线列表。 1234567891011121314151617181920212223class Client: def recvLoop(self): ''' 接收消息的循环 ''' while True: msgStr = self.recv() msgDict = utility.loadJson(msgStr) if not utility.isCorrectMsg(msgDict): continue # 如果消息不正确，忽略这个消息 if msgDict['type'] == 'data': # 如果接收到数据刷新消息 self.contactList = msgDict['data']['curOnline'] self.gui['homePage'].refreshList(self.contactList) if msgDict['type'] == 'msg': # 如果接收到聊天消息 self.openChatWindow(msgDict['userName']) # 构建输出内容 outputContent = '[{}]{}\\n{}'.format( msgDict['userName'], time.strftime('%Y/%m/%d %H:%M:%S'), msgDict['message']) self.gui['chatDlg'].addOutputContent(outputContent) 服务端消息处理接下来是比较核心的部分。 在编写客户端时，为了专注于客户端的编写，对于服务端，我采用的是比较简单的无限循环： 1234567891011121314class Server: def acceptLoop(self): ''' 接受连接的线程循环 刚开始的时候测试客户端用的， 客户端的登录测试完毕之后，将其中的代码提取出来封成另一个函数acceptLogin()， 供selectLoop使用 ''' while True: logging.info('正在等待新的连接') # 接受新的连接请求 cliSock, cliAddr = self.serSock.accept() self.acceptLogin(cliSock, cliAddr) 客户端大致成型之后，我开始编写服务端的这一部分。 我想起来之前在编写 c++聊天室的时候，用到了一个事件模型，可以解决以上线程循环遇到的问题。 上面这个写法会出现的问题，以前我就遇到过。 如果服务端想要监听多个客户端发送过来的聊天消息，第一种方法是遍历每个客户端，recv 每个客户端（将客户端 socket 改成非阻塞的就行）；第二种方法是为每个客户端建立单独的接收消息线程。 这两个方案其实都不太好。后来我找到了一个叫做事件选择模型的东西（WSAEventSelect），解决了一部分问题，当时知识还是太浅薄，不能完全理解那东西，所以还是写出了一堆 bug。 现在回想起来，python 里面应该也有类似的东西吧？我就记着个 select 了，一搜，还真是叫做 select。 找到可用的资料好像并不太多，其中一个对我很有用的文章的链接是这个：python Select 模块简单使用 后来翻了一下文档，找到了关于 select 的英文原版简介 我简单描述一下我在这个项目里面是如何使用 select 模型的： 设置三个需要处理消息的队列，分别存放所有的 socket（包括服务端 socket 和客户端 socket）、用于存放存在待处理消息的 socket 的等待队列、需要检查错误的 socket 的队列。 select 函数接收上述三个队列，并在阻塞 timeout 时间后返回三个队列，分别是可读取队列、可写入队列和错误队列。 可读取队列中的 socket 是已经接收到消息的 socket，即接收缓冲区中存在消息，需要处理。如果是服务端 socket，表明有新的客户端连接请求到达，对连接请求进行处理；如果是客户端 socket，表明有已经连接的客户端发送消息过来，先将它们放入对应的消息队列中，并将它们加入到第二个监听队列即等待消息处理的队列。 可写入队列中的 socket 是从等待消息处理的队列中选择出目前能够接受消息、即接收缓冲区可用的 socket。遍历这个队列，对其中的 socket 进行消息处理，处理完毕后删除它的消息队列，以及将它移出等待队列。 错误队列存放从需要检查错误的 socket 队列中选择出的出错的 socket，在本项目中将需要检查设置为存放所有 socket 的队列，即检查所有的 socket。遍历此队列，将错误的 socket 移除。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Server: def selectLoop(self): ''' 使用select函数来进行处理的循环 ''' readList = [self.serSock] writeList = [] message_dict = {} # 存储消息用的字典，键为socket，值为消息列表 i = 0 logging.info('服务器已经启动，正在等待客户端的连接') while True: logging.debug('循环数：'+str(i)) i += 1 # select函数阻塞timeout时间，从参数的三个列表中，选择出此时可读取、可写入、出现错误的元素返回 readableList, writableList, exceptionList = select.select( readList, writeList, readList, 1) # 1. 遍历当前可读取的socket for sock in readableList: if sock is self.serSock: # 如果是服务端socket，那么就是有客户端来连接了 cliSock, cliAddr = sock.accept() if self.acceptLogin(cliSock, cliAddr) == 0: # 如果登录成功 readList.append(cliSock) # 将新的客户端socket加入监听列表 message_dict[cliSock] = [] # 为新的socket创建消息列表 self.refreshCurOnline() # 给所有在线客户端刷新在线信息 else: # 已连接的用户发送消息过来 # 接收一下 try: data = sock.recv(self.bufsize) except: # 如果收到空数据，代表客户端已经断开连接 readList.remove(sock) del message_dict[sock] # 删除对应的消息队列 logging.info('客户端[userName={}]断开了连接'.format( self.getUserNameBySock(sock))) self.closeLink(sock) else: # 如果没有出现异常，再检查是否收到空数据 if not data: # 如果收到空数据，代表客户端已经断开连接 readList.remove(sock) del message_dict[sock] # 删除对应的消息队列 self.closeLink(sock) print('客户端[{}]断开了连接'.format( self.getUserNameBySock(sock))) else: # 收到老用户的消息 dataStr = data.decode() # 将消息加入对应的消息队列 message_dict[sock].append(dataStr) writeList.append(sock) # 2.处理待回复的消息 for sock in writableList: while len(message_dict[sock]) &gt; 0: dataStr = message_dict[sock][0] # 取出消息队列中第一个消息 del message_dict[sock][0] self.addressMsg(sock, dataStr) # 处理消息 # 测试代码：测试消息处理是否可用 # sock.sendall(('echo:'+dataStr).encode()) # 将消息队列中所有消息处理完毕，则将它从待回复队列中删除 writeList.remove(sock) # 3.处理出错的socket for sock in exceptionList: readList.remove(sock) 待我更加理解这个东西，可能会回来补充完善这个部分。 小结以上便是我的计算机网络课设的核心思路以及核心代码了，其他未列出的方法，读者看方法名字大致也能猜到它们的作用，就不浪费篇幅去说了。 本文耗费 5 个小时完成（结合课设报告）。 如有错漏欢迎在下方评论区指出。","link":"/posts/IMS_base_on_LAN/"},{"title":"【作业总结】声卡数据采集及处理","text":"这学期开了网络化测控课，第二周开头就布置了一个相当有难度的作业： 以小组为单位，写一个声卡数据采集程序，功能要求： 以曲线形式显示波形； 利用数字滤波器对数据进行平滑滤波； 对声音信号进行 FFT 变化，计算信号的主频。 对于缺乏很多前置知识的我们专业的学生来说，这确实非常有难度。 到编写本文的时候，已经进行了三天，基本功能编写完成，还需要进一步优化，为了能够偷懒，为了让队员能够更加了解本次项目，以及我自己能够从中学到东西，撰写本文如下。 本文并不专业，作者本身不是控制专业，所以出现错误在所难免，本文不是教程，仅仅是一次作业的记录复盘，不能保证正确性。 码云仓库开源链接 参考链接 Windows 上的音频采集技术：采集过程整体流程说明 About WASAPI：音频 API 官方文档 使用 WASAPI 捕获声卡音频：对官方文档示例代码的改写 WASAPI 01 采集默认设备的音频：对 API 分段解析的一篇博文 如何对时域声音信号进行 FFT 变换：一个 B 站的视频，蛮不错的，比较清晰，不过没讲 FFT 原理，我从中知道了 FFT 的输入输出分别应该是什么。 【算法讲堂】【电子科技大学】【ACM】快速傅里叶变换（FFT）：也是 B 站视频，代码主要参考的是这个，不过是递归版本的。但是好理解 简单易懂的 FFT 【信号处理】信号处理中的 FFT 后的意义及常用处理方法 准备工作还是得写啊，我先确认一下小组成员的配置。 小组总共四个人，我、leesin、咸鱼米、简白。 我只和咸鱼米一起写过代码，大致了解她的水平。 预估编程能力：我 &gt; leesin &gt; 咸鱼米 &gt; 简白； 对 git 了解程度： 我 ≈ leesin &gt; 咸鱼米 &gt; 简白； 硬件配置简白没有带电脑，无法参与编程； 咸鱼米的电脑非常卡顿，存储空间也非常小，上学期写课设的时候，她甚至是把 eclipse 放在 U 盘里面打开的，不指望她能用 vs。 leesin 的电脑应该和我相当，目前没有出现过啥问题。 我的电脑以及网络应该是小组里面最好的，游戏本外加非常快的网络，看网课从来只有老师那边卡（说起这个就想起网络测控老师那边卡成壁纸的网速） 软件配置首先应该会用到 windows 的 API，用 C++比较好，组员们最熟悉的也是它（大概吧），而且课设是做个小车，曾经接触过单片机编程，知道是需要用 C 来编程的，java、python 啥的别想用，所以最终选了 C++。 这次除了这上面的作业外，还有一个略简单的作业，PID 控制程序，这个就用 VC++6.0 来写了，照顾一下没有 vs 的咸鱼米，正好我也在学校机房写习惯了它。 但是写完 PID 之后，发现声卡数据采集程序要是拿 VC++6.0 来写，未知原因跑不通，加上调试起来确实没有 vs 方便，就决定这个项目还是用 vs 吧。 IDE 决定是 vs，接着是协作方式的问题，果断 git，平台的话，还是用国内的码云吧，毕竟要考虑网速问题。 在码云上建立了私有仓库，用 master-develop 分支结构。 时间轴周二-2020-03-03初步了解组员情况，分析题目要求。 在码云建立私有库，并邀请组员加入。PID 项目初始化。 周三-2020-03-04了解了一下 PID 算法，然后交给 leesin 和咸鱼米去整了。 真正的难点在于声卡数据采集和处理这个项目。我们都对此非常不了解。 声卡数据采集首先，需要采集声音信息。 该如何采集？我当时想到的是，应该是有 API 可以调用的，但是并没有查到那种讲解 API 的博客，能找到的只有官方文档：About WASAPI。 在本次项目之前，我是不太喜欢读文档的，因为有很多讲解得很详细的博客，没理由去自己啃文档啊，而且一般那种时候我都是处于课设周，需要查询大量资料，没有时间去看英文文档，除非遇到看博客解决不了的问题。 这次只能看了，当然，还是得配合翻译插件（chrome 刚装彩云小译没几天就用上了，中英对照效果还不错）。 The Windows Audio Session API (WASAPI) enables client applications to manage the flow of audio data between the application and an audio endpoint device. Windows 音频会话 API (WASAPI)使客户端应用程序能够管理应用程序和音频端点设备之间的音频数据流。 Header files Audioclient.h and Audiopolicy.h define the WASAPI interfaces. 头文件 Audioclient.h 和 audiopolis. h 定义了 WASAPI 接口。 懂了，想用这个 API 得先包含两个头文件，Audioclient.h和Audiopolicy.h，不过在 vc++6.0 我编译不了，说没有这俩文件，但是 vs 可以，所以后来统一用了 vs。 接着看后面的说明，照着做但是不行。 比如，让我调用IMMDevice::Activate这个方法，写上去却找不到这个方法，说是::前面得是命名空间或者类。后来折腾了很久才发现，原来IMMDevice不是命名空间而是类名啊！ 然而我还是不太清楚如何弄出来它说的那些客户端，各种参数太多了，不知道传啥。好在后面终于找到了一些有用的资料。 对于采集数据的流程和原理不是很明白，但是通过读文档以及后来找到的一些博客互相配合着理解，总算对整个流程有了一个大致的了解。 流程分为以下几步（Windows 上的音频采集技术：采集过程整体流程说明）： 创建多媒体设备枚举器(IMMDeviceEnumerator) 通过多媒体设备枚举器获取声卡接口(IMMDevice) 通过声卡接口获取声卡客户端接口(IAudioClient) 通过声卡客户端接口(IAudioClient)可获取声卡输出的音频参数、初始化声卡、获取声卡输出缓冲区的大小、开启/停止对声卡输出的采集 通过声卡采集客户端接口(IAudioCaptureClient)可获取采集的声卡输出数据，并对内部缓冲区进行控制 由于用到的函数太多了，就只给出函数官方文档链接，以及在代码中做出简单的注释。注释内容大部分为机翻。 为了清晰，没有加入错误处理的代码。 下面的示例代码解析自官方的示例程序Capturing a Stream，会有一些改动。 初始化最开始，得使用CoInitialize函数来在当前线程上初始化 COM 库（CoInitialize 函数） 1CoInitialize(NULL);//初始化com库 采集结束后，记得关闭 1CoUninitialize(); 创建多媒体设备枚举器定义一些常量 1234const CLSID CLSID_MMDeviceEnumerator = __uuidof(MMDeviceEnumerator);const IID IID_IMMDeviceEnumerator = __uuidof(IMMDeviceEnumerator);const IID IID_IAudioClient = __uuidof(IAudioClient);const IID IID_IAudioCaptureClient = __uuidof(IAudioCaptureClient); 这些常量是这些类的 UUID，总之就是用来标识这些类的。 Cocreateinstance 函数 12345678//创建多媒体设备枚举器 IMMDeviceEnumerator *pEnumerator = NULL; CoCreateInstance( CLSID_MMDeviceEnumerator, //创建与指定 CLSID (Class ID，即类标识符)关联的类的单个未初始化对象。 NULL,//如果为 NULL，则表示该对象不是作为聚合的一部分创建的 CLSCTX_ALL,//管理新创建对象的代码将在其中运行的上下文。 这些值取自枚举 CLSCTX IID_IMMDeviceEnumerator,//对用于与对象通信的接口标识符的引用 (void**)&amp;pEnumerator);//接收 riid 请求的接口指针的指针变量的地址。 成功返回后，* ppv 包含请求的接口指针。 失败时，* ppv 包含 NULL。 获取声卡接口使用刚刚获取的枚举器来获取默认音频端点设备。 IMMDeviceEnumerator::GetDefaultAudioEndpoint 方法 123456//获取声卡接口 IMMDevice *pDevice = NULL;//声卡接口 pEnumerator-&gt;GetDefaultAudioEndpoint( eCapture,//端点设备的数据流方向。 调用方应该将此参数设置为以下两个 EDataFlow 枚举值之一:eRender,eCapture,前者渲染，后者捕获 eConsole,//端点设备的角色。 调用者应该将这个参数设置为以下 ERole 枚举值之一:eConsole,eMultimedia,eCommunications &amp;pDevice);//指向一个指针变量，该方法将默认音频端点设备的端点对象的 immmdevice 接口的地址写入该指针变量 设置默认音频格式这里用的是使用最小音频格式，也可以手动设置自己的音频格式。 WAVEFORMATEX 结构体 123//获取音频格式WAVEFORMATEX *pwfx = NULL;pAudioClient-&gt;GetMixFormat(&amp;pwfx); 获取声卡客户端IMMDevice::Activate 方法 123//通过声卡接口获取声卡客户端接口 IAudioClient *pAudioClient = NULL; pDevice-&gt;Activate(IID_IAudioClient, CLSCTX_ALL, NULL, (void**)&amp;pAudioClient); 初始化声卡客户端IAudioClient::Initialize 方法 123456789REFERENCE_TIME hnsRequestedDuration = REFTIMES_PER_SEC; //采样持续时间，单位100纳秒pAudioClient-&gt;Initialize( AUDCLNT_SHAREMODE_SHARED,//与其他设备共享音频端点设备 0,//选项 hnsRequestedDuration,//以时间值表示的缓冲区容量 0,//设备周期，共享模式下设为0 pwfx,//音频格式 NULL//指向session的GUID的指针，设置为NULL表示打开一个新session); REFTIMES_PER_SEC是一个宏，作为参考时间单位。100 纳秒 = 1e-7 秒，即这个宏定义的值。也就是说，上面的代码是采样 1 秒的意思。 123// REFERENCE_TIME time units per second and per millisecond#define REFTIMES_PER_SEC 10000000#define REFTIMES_PER_MILLISEC 10000 获取捕获客户端IAudioClient::GetService 方法 12345//获取捕获客户端 IAudioCaptureClient *pCaptureClient = NULL; hr = pAudioClient-&gt;GetService( IID_IAudioCaptureClient, //客户端接口ID (void**)&amp;pCaptureClient); 启动音频流IAudioClient::Start 12//启动音频流m_pAudioClient-&gt;Start(); 采集数据启动音频流之后，就可以开始捕获数据了，音频流有一个缓冲区 流程如下： 从缓冲区获取下一个数据包 处理数据包 释放缓冲区 获取下一个数据包大小，循环直到缓冲区为空 获取数据包大小，以确定流中是否有数据。 1234567UINT32 packetLength = 0;//数据包长度BYTE *pData = NULL;//数据包首地址UINT32 numFramesAvailable;//数据包中可用的音频帧数DWORD flags;//缓冲区状态标志vector&lt;BYTE&gt; recorder;//用于存储数据pCaptureClient-&gt;GetNextPacketSize(&amp;packetLength);//获取下一个数据包的大小 处理其中的数据。 IAudioCaptureClient::ReleaseBuffer IAudioCaptureClient::GetNextPacketSize IAudioCaptureClient::GetBuffer 12345678910111213141516171819202122232425262728293031323334while (packetLength != 0) { //获取缓冲区中的数据 pCaptureClient-&gt;GetBuffer( &amp;pData,//数据包指针变量的地址 &amp;numFramesAvailable, //数据包中可用的音频帧数 &amp;flags, //缓冲区状态标志 NULL, NULL ); //判断是否静音 if (flags &amp; AUDCLNT_BUFFERFLAGS_SILENT) { pData = NULL; } int dataSize = numFramesAvailable * 4;//可用帧数*4=BYTE数 //采集数据 for (int i = 0; i &lt; dataSize; i++) { BYTE tem = pData[i]; recorder.push_back(pData[i]);//添加进自己实现准备好的数据数组中 } //释放缓冲区 pCaptureClient-&gt;ReleaseBuffer(numFramesAvailable); //获取下一个数据包大小 pCaptureClient-&gt;GetNextPacketSize(&amp;packetLength); } 当然，由于缓冲区会不断地进来数据，你可以加一个判断，读取了多少个数据包后退出循环，否则会无限循环。 关闭音频流1pAudioClient-&gt;Stop(); 测试输出1234for (int i = 0; i &lt; recorder.size(); i++) { printf(&quot;%d\\n&quot;, recorder[i]); } 周三大概做到这里 周四-2020-03-05周四主要将波形曲线画出来。 绘制波形创建了一个 MFC 项目，并新建了一个类，主要是将上面说到的代码简单封装了一下，没有用到的暂时不显示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//CRecorder.h#pragma once#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;stdio.h&gt;#include &lt;cmath&gt;#include &lt;algorithm&gt;#include &lt;dshow.h&gt;#include &lt;Windows.h&gt;#include &lt;winerror.h&gt;#include &lt;mmdeviceapi.h&gt;#include &lt;Functiondiscoverykeys_devpkey.h&gt;#include &lt;Audioclient.h&gt;#include &lt;Audiopolicy.h&gt;#include &lt;complex&gt;using namespace std;// REFERENCE_TIME time units per second and per millisecond#define REFTIMES_PER_SEC 10000000#define REFTIMES_PER_MILLISEC 10000#define EXIT_ON_ERROR(hres) \\ if (FAILED(hres)) { goto Exit; }#define SAFE_RELEASE(punk) \\ if ((punk) != NULL) \\ { (punk)-&gt;Release(); (punk) = NULL; }class CRecorder{private: vector&lt;BYTE&gt; m_recorder;//数据记录器 IAudioClient *m_pAudioClient;//声卡客户端 IAudioCaptureClient *m_pCaptureClient;//捕获流客户端 WAVEFORMATEX *m_pwfx;public: CRecorder(); //手动提取出来的代码 void init();//初始化 void refreshRecorder();//刷新采样数据 void onError(HRESULT hres);//错误处理（也没咋用，懒得写那么多错误处理） HRESULT RecordAudioStream();//整块的示例代码，用于测试，现在不使用 ~CRecorder(); int drawWaveform(CDC* pDC, CRect rect,vector&lt;BYTE&gt; output);//绘制图像}; 实现部分和上面差不多就不赘述了。 主要是绘制方面。 第三个参数vector&lt;BYTE&gt; output是为了后面的滤波所准备的，是由 leesin 提出的改进 1234567891011121314int CRecorder::drawWaveform(CDC* pDC,CRect rect,vector&lt;BYTE&gt; output){ //RecordAudioStream(); int height = rect.Height(); int width = rect.Width(); int x_coefficient = 5; //int a = dataStart; pDC -&gt; MoveTo( 0, output[dataStart] ); for (int i = dataStart; i &lt; output.size() &amp;&amp; (i-dataStart+1)*x_coefficient &lt;= width; i++) { pDC-&gt;LineTo((i-dataStart+1) * x_coefficient, output[i]); } return 0;} 在对话框类中获取 pDC 1234567891011121314151617181920212223void CsoundcarddataacquisitionDlg::drawWaveform(){ m_pPanel = GetDlgItem(IDC_PANEL);//获得静态窗口对象指针 //清屏 m_pPanel-&gt;ShowWindow(FALSE);//偷懒用的方法 m_pPanel-&gt;ShowWindow(TRUE); //获取控件区域 CRect rect; m_pPanel-&gt;GetClientRect(&amp;rect); //获取控件画笔 CDC* pDC = m_pPanel-&gt;GetDC(); //绘制原始采样数据 m_pPanel-&gt;UpdateWindow(); //m_recorder.RecordAudioStream(); m_recorder.refreshRecorder(); m_recorder.drawWaveform(pDC, rect,m_recorder.NoFiltering()); ReleaseDC(pDC);} 其中： 1234vector&lt;BYTE&gt; CRecorder::NoFiltering(){ return m_recorder;} 滤波算法老师给了个 txt，里面就是各种滤波算法，我也没啥精力去研究了，就交给 leesin 了，他完成得很不错，就是刚刚上面说的设计就是他整的。不过一开始用的算法效果不太好，让他继续研究。此时咸鱼米在弄 vc6.0 的 PID 那个项目，因为她没有 vs。 周五周六-2020-03-06~07这两天都在学习那个 FFT 快速傅里叶变换 FFT参考各方资料写出来这个递归版本的（迭代版本的看不懂），参考链接见本文开头。 输入：多项式系数表示法的系数，值为时域下的幅值 输出：多项式点值表示法的点（以复数表示），其模为频域下的幅值 12345678910111213141516171819202122232425262728293031323334/**FFT传入的复数数组里面都是实数，含义是多项式系数表示法的系数，值为时域幅值系数数组长度得是2的整数次方返回值的模为频谱幅值*/vector&lt;complex&lt;double&gt;&gt; CRecorder::FFT(vector&lt;complex&lt;double&gt;&gt; A){ const double PI = 3.141592651; int len = A.size(); if (len == 1) return A;//递归结束条件 vector&lt;complex&lt;double&gt;&gt; A1, A2;//A(x) = A1(x^2) + x * A2(x^2) //将系数分类 for (int i = 0; i &lt; len; i++) { if (i % 2 == 0) A1.push_back(A[i]); else A2.push_back(A[i]); } A1 = FFT(A1); A2 = FFT(A2); complex&lt;double&gt; Wn(cos(2.0*PI / len), sin(2.0*PI / len));//len等分点的角度增量 complex&lt;double&gt; W(1.0, 0.0);//用于遍历复平面单位圆上的len个等分点 for (int i = 0; i * 2 &lt; len; i++, W *= Wn) { A[i] = A1[i] + W * A2[i]; A[i + len / 2] = A1[i] - W * A2[i]; } return A;} 完成之后的效果是下面这样的： 上图的坐标都是没有变换的，还是以左上角为原点。 发现重装系统前写的东西都没了啊啊啊啊啊啊！后面那么一大段就这样没了！不太想补了。 其实核心部分也基本上说完了，剩下的就是坐标转化以及动态采样了，读者们可以移步本项目的码云仓库查看代码。","link":"/posts/sound-card-data-acquisition/"},{"title":"【毕业实习总结】（2）mybatis框架的基本使用","text":"前言大三暑假有个毕业实习，是企业的人来我们学校带我们做项目，为期三周。 前半部分是教我们一些框架的基本使用，后面几天就是组成小组利用前面学习的知识开发一个商城项目。感觉和课设其实没有差的太多。 学习到的框架有 mybatis、springmvc、spring、springboot、shiro、mybatis-plus，还在一开始学习了如何建立 maven 项目。 2020 年 7 月 15 日，我们小组完成了答辩。在之前因为要学习框架、做项目，甚至中间夹杂着几场考试，所以抽不出空来写博客，现在结束了，我现在通过 git 提交记录以及幕布学习笔记、工作日报等记录来尝试还原这一次经历以及学习到的技术。 一开始想的是本系列先整理学习笔记，最后对本次项目进行总结。不过碍于时间不足，可能会直接将以前的旧项目改为 springboot 架构，实习最终完成的商城项目就不进行分析了，项目开源链接：SpringBootMall 笔者也是刚刚才学习这些东西，所以如果有问题可以给我留言。 仓库链接本文的练习项目已在码云开源，链接如下： 学习 mybatis 的练习项目，这个链接是本项目首页 这个链接会直接跳转到本文所对应的版本 导入方式见本系列的第一篇文章。 mybatis 框架的基本使用mybatis 官网文档 什么是 mybatis下面是 mybatis 官网的说明： MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 它可以将 sql 语句和业务代码分开，从而方便修改。 本学期我做的另外几个课设中，sql 语句都是直接写在代码中的，类似于下面这样： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 添加考试信息 * @param exam * @return 是否添加成功 */ public static boolean addExam(ExamBean exam)//单个考试添加函数 { SimpleDateFormat sdf =new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);//用于日期格式化 String date =sdf.format(exam.getDate()); String applyDate = sdf.format(exam.getApplyDate()); //添加exam表相关的属性 String sql = String.format(&quot;insert into &quot; + &quot;exam(exam_id,term_id,course_id,exam_wl,exam_date,location,period,teacherNeed,exam_status,`comment`,teacher_id,apply_date,refuse_reason)&quot; + &quot;values('%s','%s','%s',%d,'%s','%s','%s',%d,'%s','%s','%s','%s','%s');&quot; ,exam.getExamNo() ,exam.getTerm() ,exam.getCourseNo() ,exam.getWorkload() ,date ,exam.getLocation() ,exam.getTime() ,exam.getNeed() ,exam.getStatus() ,exam.getComment() ,exam.getApplierNo() ,applyDate ,exam.getRefuseReason() ); boolean success = databaseBean.executeUpdate(sql); if(!success) return false; //添加考试-班级表的记录 String[] classNoList = exam.getClassNo(); if(classNoList!=null) { for(String classNo :classNoList) { sql = String.format(&quot;insert into examclasses(exam_id,class_id)&quot; + &quot;values('%s','%s');&quot; , exam.getExamNo(),classNo); success = databaseBean.executeUpdate(sql); if(!success) return false; } } //添加监考记录 InvigilatorBean[] invigilatorList = exam.getInvigilator(); if(invigilatorList!=null) { boolean isMain = true; for(InvigilatorBean invigilator:invigilatorList) { success = InvigilatorBean.arrange(exam.getExamNo(), invigilator.getStaffNo(), isMain); isMain=false; if(!success) return false; } } return true; } 这是考务管理系统的 ExamBean 类中的内容（jsp+servlet+javabean 的架构，将业务逻辑写在了 javabean 中），可以看到，它需要手动进行日期的转换、多表查询的 sql 语句的拼接，而且 sql 语句是直接写在代码里面的，如果需要改动 sql 语句，会非常麻烦。 想要连接数据库，还需要自己写一个 DatabaseBean 来将数据库的用户名、密码、驱动名写在里面，提供获取数据库连接的类方法。 而使用了 mybatis 之后，sql 语句写在专门的 xml 文件当中，代码和 sql 语句分开，更方便管理。下文会展示如何简单地使用它，不作深入讲解（哈哈，因为更深的我也还不会）。 配置 mybatis添加 mybatis 依赖前往maven 中央仓库的官网，搜索 mybatis，选择版本，并将其依赖的配置代码添加到pom.xml中： 12345678910111213141516171819202122232425262728293031323334&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.test&lt;/groupId&gt; &lt;artifactId&gt;TestMaven&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt; &lt;!--这里就是新添加的依赖--&gt; &lt;!--和servlet相关的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;!--mysql驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt; &lt;!--这个才是mybatis的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--这里就是新添加的依赖--&gt; &lt;/dependencies&gt;&lt;/project&gt; 文件保存后，等待 eclipse 把这个依赖自动下载到本地仓库，就可以使用 mybatis 了。 新建 mybatis 配置文件在工程的src/main/resources目录下新建一个 xml 文件mybatis-config.xml，内容如下： 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default=&quot;dev&quot;&gt; &lt;environment id=&quot;dev&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot; /&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;!--数据库相关配置--&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://127.0.0.1:3306/test&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot; /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;!--指定sql映射文件位置，此文件现在还没有创建，见下文--&gt; &lt;mapper resource=&quot;mapper/StudentMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 里面的驱动名（mysql5 以后的驱动名变了，请注意。本例中的 mysql 是 5.1 版本的）、url、用户名和密码都改成自己的。 在同目录下新建一个文件夹mapper，用于存放 SQL 映射文件。 增删改查举例以教务管理系统的学生信息的增删改查为例。本地 mysql 的test数据库中的student表中存放着学生信息，grade表中存放着班级信息。 为了便于讲解，本例中的代码和上文给出的码云仓库的代码可能会有所不同。 目录结构一览 src/main/java com.test bean Student.java：用于存储学生信息的 javabean utils MybatisUtils.java：用于获取 SqlSession 的工具类 dao StudentMapper.java：用于处理对学生信息的 src/main/resource mapper StudentMapper.xml：SQL 映射文件，SQL 语句写在这里 mybatis-config.xml：mybatis 配置文件 新建包com.test.bean在你自己的工程包下（这里以com.test为例），新建一个bean包，存放的就是 javabean，用于将数据库的数据封装为类。 在其中新建一个学生 javabean，名为Student，其属性与数据库的学生信息表的字段一一对应（比如表中的sname字段对应 javabean 的sname属性）。 com.test.utilsutils 包存放一些工具类或者说是公共类。在此包下新建MybatisUtils类，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839package com.test.utils;import java.io.IOException;import java.io.Reader;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;/** * @author 憧憬少 */public class MybatisUtils { private static SqlSessionFactory factory=null; static{ Reader reader; try { reader = Resources.getResourceAsReader(&quot;mybatis-config.xml&quot;); factory = new SqlSessionFactoryBuilder().build(reader); } catch (IOException e) { e.printStackTrace(); } } public static SqlSession getSqlSession(){ return factory.openSession(); } public static void close(SqlSession sqlSession){ if(sqlSession!=null){ sqlSession.close(); } }} 这里涉及到 mybatis 如何进行 sql 映射，来看看官网文档是怎么说的： 每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为核心的。 SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。 而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或一个预先配置的 Configuration 实例来构建出 SqlSessionFactory 实例。 这个类在静态块里面读取了我们刚刚写的配置文件，并将其传给SqlSessionFactoryBuilder以创建SqlSessionFactory对象。 这个类的主要作用就是读取 mybatis 配置文件，并提供获取SqlSession对象的静态方法。我们可以使用SqlSession对象的方法，来使用 sql 映射文件中的 sql 语句。 com.test.dao再新建一个名为dao的包，它的含义为 DAO(Data Access Object)数据访问对象，它是这个项目的数据访问层，业务代码通过它对数据库进行访问，有了这一层抽象，业务逻辑和数据访问就分开了。 dao包中新建一个StudentMapper类，它用来和 SQL 映射文件产生联系。它的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738package com.test.dao;import java.io.IOException;import org.apache.ibatis.session.SqlSession;import com.bean.Student;import com.utils.MybatisUtils;public class StudentMapper { public static int save(Student student) throws IOException{ SqlSession session = MybatisUtils.getSqlSession(); int flag = session.insert(&quot;saveStudent&quot;,student); session.commit(); MybatisUtils.close(session); return flag; } public static int update(Student student) throws IOException{ SqlSession session = MybatisUtils.getSqlSession(); int flag = session.update(&quot;updateStudent&quot;,student); session.commit(); MybatisUtils.close(session); return flag; } public static int delete(int id) throws IOException{ SqlSession session = MybatisUtils.getSqlSession(); int flag = session.delete(&quot;deleteStudent&quot;,id); session.commit(); MybatisUtils.close(session); return flag; }} 可以看到，这里面调用了SqlSession对象的三个方法insert、update和delete，并且第一个参数是一个字符串，第二个参数就是操作的对象，操作对象中打包了用于增删改数据库的参数。 由于查询相比增删改要复杂一些，所以先写增删改的内容，等会儿再加上查询的代码。 操作完成后，使用 commit 方法进行事务提交，并关闭 SqlSession 对象。 那么第一个参数是什么呢？是 SQL 映射文件里面的 sql 语句的标识，接下来来看看 sql 映射文件吧~ 新建 sql 映射文件在刚刚新建的mapper文件夹中新建一个 xml 文件StudentMapper.xml，大体框架如下 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.test.dao.StudentMapper&quot;&gt;&lt;/mapper&gt; 其中，mapper 标签的namespace的属性值为与此文件绑定的映射类的包括类名在内的包路径，eclipse 按住 ctrl+左键可以跳转到对应的类（如果没有跳转说明可能是拼写错误） 在这里编写 sql 语句： 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.dao.StudentMapper&quot;&gt; &lt;insert id=&quot;saveStudent&quot;&gt; insert into student(sname) values(#{sname}) &lt;/insert&gt; &lt;update id=&quot;updateStudent&quot;&gt; update student set sname=#{sname} where sid=#{sid} &lt;/update&gt; &lt;delete id=&quot;deleteStudent&quot;&gt; delete from student where sid=#{sid} &lt;/delete&gt;&lt;/mapper&gt; 其中，标签对应的是 sql 语句所进行的操作，id 则是上文中调用SqlSession对象的方法时所传入的第一个字符串参数，在 sql 语句中夹杂着这样的内容：#{sname}，它在映射后会作为一个占位符，类似 JDBC 的预编译。mybatis 会将传入的第二个 Object 参数的属性设置进去。 增改操作传入的都是Student对象，这个对象的属性就包含sname。 这就是增删改操作，可以新建一个测试类来测试一下 测试用建表语句为了简单起见，删除了一些字段 123456789101112131415161718192021222324252627282930313233343536373839404142CREATE DATABASE IF NOT EXISTS test;USE test;# 删除表DROP TABLE IF EXISTS student;DROP TABLE IF EXISTS grade;# 创建班级表CREATE TABLE grade( gid INT AUTO_INCREMENT primary key, gname char(30), deleted INT DEFAULT 0# 删除标记);# 创建学生信息表create table student( sid INT AUTO_INCREMENT primary key, snum char(30),# 学号 sname char(30),# 姓名 deleted INT DEFAULT 0,# 删除标记 gid INT, FOREIGN KEY(gid) REFERENCES grade(gid));INSERT INTO grade(gname)VALUES('软件工程六班'),('软件工程七班');insertinto student(snum,sname,gid)values('2017901006','张三',1),('2017901007','李四',2),('2017901008','王五',1),('2017901009','赵六',2),('2017901026','张三',1); 增删改测试示例测试类： 12345678910111213141516171819202122package com.test;import com.bean.Student;import com.dao.StudentMapper;public class TestStudentCRUD { public static void main(String[] args){ try { Student student = new Student(); student.setSname(&quot;张三&quot;); int flag=0; flag = StudentMapper.insert(student); //flag = StudentMapper.update(student); //flag = StudentMapper.delete(student.getId()); System.out.println(flag); } catch (Exception e) { e.printStackTrace(); } }} 如果插入成功，那么可以看到控制台输出了 1，这是影响的行数。如果是 0，那么就是插入失败，看一下报错信息，检查一下数据库用户名和密码是否正确，检查一下 javabean 和数据库字段对应情况 查询操作再创建一个班级信息的 bean，字段如下： 12345678910111213package com.bean;import java.io.Serializable;import java.util.*;public class Grade implements Serializable { private static final long serialVersionUID = 1L; private Integer gid;//班级主键 private String gname;//班级 private List&lt;Student&gt; list = new ArrayList&lt;Student&gt;();//学生列表 //省略setter和getter} 12345678910111213package com.bean;import java.io.Serializable;public class Student implements Serializable { private static final long serialVersionUID = 1L; private Integer sid; private String sname; private Grade grade;//学生所属的班级 //省略setter和getter} 下面的代码都是在StudentMapper.xml中写的。 单表查询最简单的方式是单表查询，也就是仅仅查询一个表中的字段，不涉及另一个表。 以下的 sql 映射可以实现单表查询，不过有一定的限制，那就是查询结果中的字段名必须和 resultType 所指定的 javabean 的属性名一一对应，比如说数据库表中的字段名为sname，那么com.bean.Student这个 javabean 中的字段也必须有一个sname，否则会报错。 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.dao.StudentMapper&quot;&gt; &lt;!--省略增删改语句--&gt; &lt;select id=&quot;selectStudent&quot; resultType=&quot;com.bean.Student&quot; &gt; select * from student &lt;/select&gt;&lt;/mapper&gt; 结果集映射如果数据库表字段名和 javabean 的属性名不一样，那么可以使用结果集映射 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.dao.StudentMapper&quot;&gt; &lt;!--省略增删改语句--&gt; &lt;select id=&quot;selectStudent&quot; resultMap=&quot;StudentMapper&quot; &gt; select * from student &lt;/select&gt; &lt;resultMap type=&quot;com.bean.Student&quot; id=&quot;StudentMapper&quot;&gt; &lt;id property=&quot;sid&quot; column=&quot;ID&quot;/&gt; &lt;result property=&quot;sname&quot; column=&quot;Sname&quot;/&gt; &lt;/resultMap&gt;&lt;/mapper&gt; select标签中的resultMap属性指定所使用的resultMap标签（结果集标签），resultMap标签由id属性所指定。 结果集标签中嵌套了id标签和result标签，前者指定结果集中的主键，而后者则是其他普通类型的属性，它们的property属性对应 javabean 的属性名，column对应数据库表的列名也就是字段名。 多表查询如果要实现多表查询，那么就必须使用上述的结果集映射了。多表查询即涉及到多个表的字段的查询，需要进行连接操作。 在本例中，学生表中有一个班级字段，指明学生属于哪个班级。在查询学生的班级名时，需要连接学生表和班级表。 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.dao.StudentMapper&quot;&gt; &lt;!--省略增删改语句--&gt; &lt;select id=&quot;selectStudent&quot; resultMap=&quot;StudentMapper&quot; &gt; select s.*,g.* from student s left join grade g on s.gid= g.gid &lt;/select&gt; &lt;resultMap type=&quot;com.bean.Student&quot; id=&quot;StudentMapper&quot;&gt; &lt;id property=&quot;sid&quot; column=&quot;sid&quot;/&gt; &lt;result property=&quot;sname&quot; column=&quot;sname&quot;/&gt; &lt;association property=&quot;grade&quot; javaType=&quot;com.bean.Grade&quot;&gt; &lt;id property=&quot;gid&quot; column=&quot;gid&quot;/&gt; &lt;result property=&quot;gname&quot; column=&quot;gname&quot;/&gt; &lt;/association&gt; &lt;/resultMap&gt;&lt;/mapper&gt; 这里多了一个association标签，它用于把结果集中的其他表的字段映射到本 javabean 的字段，本例中就是将查询结果中的gid和gname字段映射到Student类的grade对象的对应属性中。 一对多查询除了表的字段和类的属性的一一映射之外，有时还需要进行一对多的映射。 比如班级类中有一个列表，想要将所有属于该班级的学生都加入到这个列表当中，那么可以按照上文的方式新建对应的GradeMapper类和GradeMapper.xml，在映射文件中这样写： 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.dao.GradeMapper&quot;&gt; &lt;select id=&quot;getStudentListById&quot; resultMap=&quot;GradeMapper&quot;&gt; select grade.*,student.* from grade left join student on grade.gid=student.gid where grade.gid=#{gid} &lt;/select&gt; &lt;resultMap type=&quot;com.bean.Grade&quot; id=&quot;GradeMapper&quot;&gt; &lt;id property=&quot;gid&quot; column=&quot;gid&quot; /&gt; &lt;result property=&quot;gname&quot; column=&quot;gname&quot; /&gt; &lt;collection property=&quot;list&quot; ofType=&quot;com.bean.Student&quot;&gt; &lt;id property=&quot;sid&quot; column=&quot;sid&quot;/&gt; &lt;result property=&quot;sname&quot; column=&quot;sname&quot;/&gt; &lt;/collection&gt; &lt;/resultMap&gt;&lt;/mapper&gt; 用的是collection标签，它的ofType属性是集合类中所装元素的类型，其他的和上面差不多","link":"/posts/graduate_internship_2/"},{"title":"【项目复盘】网络软件开发综合实践","text":"尝试使用规范化的复盘方法来进行复盘总结，本文使用的方法来自： 如何做好一次复盘？这是我的经验-少数派 一、回顾经历1、背景（Situation）这是大四第一学期的四大综合实践的第一个，主题是网络软件开发，需要写的项目是“基于 web 的高校教学考试成绩管理系统”。 与此同时，我需要准备考研，所以虽然经过暑假的毕业实习学习了 SSM 后，我挺想认真来做这些题目，从而将这些学到的技术巩固与提升，但是我并没有太多的时间与精力可以投入其中。再加上并不是非常愉快的以往的课设与毕业实习经历，我决定“跳槽”到另一个小组内。 老师最终同意了重新分组，我和好友 LeeSin 加入了 S 的小组。S 是一位大佬，在每次的课设检查答辩时都有优异的表现，能够做出各种我们意想不到的优秀功能。 我一开始想的是，他让我做什么，那我就去做，大佬的任务分配能力应该比我要好，我只需要完成分配给我的任务，就可以去安心复习了。 不过到了组内后，发现组内原本的六个人，只有 S 和 L 是有产出能力的大佬，其他四人基本上是被带着走的，两个男生暑假就开始实习直到现在还没回来，两个准备考研而并不会花太多时间在这里的女生（这次项目结束已经保研了），而且在之前的项目中做前端的 L 也找到了实习。 也就是说，如果 L 不是因为疫情而无法出校，而且有我们两个人的加入，那么整个组就只剩下 S 能够产出，太惨了。 2、任务目标（Task）需求开发基于 web 的高校教学考试成绩管理系统。 该系统的用户有三类，分别是教师、学生、管理员。 A. 教师使用该系统进行正考、补考、缓考成绩的录入和查看、录入成绩分析表、申请撤销等活动； B. 学生利用该系统查看成绩； C. 管理员使用该系统查看并审批教师提交的成绩撤销申请。 更加详细的需求见下图： 实习阶段实习的过程主要分为以下四个阶段： 第一阶段：8 月 31 日~9 月 6 日，进行需求分析，撰写需求分析报告，前端成员学习 React 框架，前端后端搭建本地开发环境以及新建 git 远程仓库。 第二阶段：9 月 7 日~9 月 13 日，进行总体设计，划分模块，撰写概要设计文档。 第三阶段：9 月 14 日~9 月 20 日，进行编码，对设计的各个模块予以实现。 第四阶段：9 月 21 日~9 月 25 日，项目调试以及项目答辩，各小组对项目的完成情况进行汇报，展示与答辩。 每天都需要编写工作日志，记录自己做了什么事情，遇到了什么问题，以及第二天的工作计划。 目标 编写出符合需求的软件 进行良好的团队协作 进行标准的软件开发流程 通过答辩 3、行动（Action）最后的技术选型确定为 React 前端框架+SpringBoot 后端框架，分工是我、LeeSin 和 L 做前端，S 一个人做后端供我们三个人。S 说我们是前后端分离开发，他提供后端接口，而我们前端从接口获取数据与提交数据进行操作。 L 是本组的前端担当，我们来之前就是 S 后端加上 L 前端的组合。 虽然我提出，数据库设计等后端的活我都能干，但还是给我分配了前端。估计 S 是想 L 带我们两个新人做一做前端，看看我们的能力，同时也不想自己设计后端被我们影响。 理解，换成我也是会这样做的。在不清楚他人的能力之前，贸然合作并不是个好主意，有可能做出很糟糕的设计。而且做前端应该比后端要轻松一些，我有更多的时间来复习考研。 第一周由于没有接触过 Vue 以及 React 之类的前端框架，之前只用过 layui 这样给后端开发者准备的 UI 框架，我的前端知识并不是很充足，LeeSin 就更加如此了，他甚至连 javascript 的一些常用语法都不是太清楚。 在项目开始的第一天，也就是 8 月 31 日，我就学习了九个小时的 React，并没有看视频，而是跟着官网的示例来学习。自己去学习和理解的效率确实比较低。 当时我比较关心如何将 React 实现的页面与 Springboot 整合起来，毕竟之前做的项目都是将 layui 直接引入到项目文件夹中，一边写后端代码一边调试前端代码。当我尝试了很久之后，询问 S 应该怎么弄时，他说我们并不需要整合，前后端分离，约定好接口即可。 之前的项目中，使用 layui 的表格时学习到了数据接口的概念，所以理解起来并不是特别困难，很快就接受了这个事情。 同时，将 React 和 layui 对比学习之后，我对二者有了不一样的理解，原来两者并不是同一种东西，一个是 JS 框架，主要提供一些“动作”方面的便利。另一个则是 UI 框架，主要提供界面组件，注重外观，不过也会提供一些工具，例如数据表格等。 也就是说，用了 React 作为基础框架之后，还需要一个 UI 框架来设计界面。我做了错误的一件事情，那就是随便搜索了一下就说“要不使用 Material-UI 吧”，没有认真去筛选该使用哪个框架。 接下来的几天，我建立了一个码云 git 仓库用于存放前端页面项目，编写了登录页面样例（之所以说是样例是因为他们又重新写了登录组件）、应用栏、导航栏、React 路由、课程信息展示表格、班级信息展示表格、成绩系数编辑组件等组件，一边写一边继续学习。除了学习到 React 和 js 的知识外，也了解了内网穿透、前后端分离是怎么回事，安装了一些好用的工具：postman、React 调试插件等。 让我有些忧虑的是，S 并没有带领大家做详细的需求分析，将大家召集起来也并没有讨论此事。需求分析可是非常重要的事情，没有进行需求分析，我并不知道我要做成什么样子，而且看样子 S 也并不打算让我们做一个原型出来确定需求。 在第一周周五下午的时候，需要检查需求分析文档，但是并没有什么可以交的。我在周五上午组内开会的时候，拿着 ipad 来绘制，勉强拉着他们讨论出了一个简单的手绘的原型，如下图： 本来以为 L 会给我和 LeeSin 分配任务，但是即使我提出了给我们分配任务的事情，他也并不是很上心的样子截图了我绘制的原型图说随口说让我们做里面的组件，我心里吐槽这不是什么都没说吗，但还是去写了。 关于第一周的进度： S 一个人很早就搞定了数据库设计，写好了后端接口，并且用 Swagger 生成了接口文档给我们三人看，使用内网穿透让我们能够在宿舍就访问到他的接口。这操作当时就让我觉得非常厉害，不愧是大佬。 L 和 LeeSin 第一周似乎没有做什么事情。说是在学习 React，这我能理解。 我新建了 git 仓库（L 和 S 他们之前好像没有用过 git），对新建的前端项目进行管理，用于与 L 和 LeeSin 两人进行协作，后端在我建仓库之前都完成的差不多了那就没有必要新建一个了。 我写了几个必然会使用到的组件来作为 React 的练习。 这一周结束的时候，我对这个小组的未来有了一些忧虑，但是并没有什么太大的危机感。而且压力也比以前当组长的时候小了很多。 毕竟有大佬兜底，无论如何，项目最终都是可以做出来的。 本周耗费在这上面的时间：45.25h（26.9%）。约每天 6.5 小时，注意这还是周日完全没做事的情况下的平均，如果不算周日，就是每天 7 小时。第一周学习 React 用的时间比较多。 第二周因为 MaterialUI 的组件太难写了，官网的文档写得不太好懂，而且资料太少，所以决定前端换一个 UI 框架。可惜的是前一周已经用 MaterialUI 写了那么多组件，好在转换起来也不是完全推翻之前的，学到的知识也都还用得上。 说起来这个其实是我的错，是我提出使用这个框架的。所以我也没必要抱怨太多，就当练习 React 了。 第二周进度： 我将之前的组件利用 antd 来改写，周二完成改写 学习 React 路由相关知识 编写成绩分析表格组件 用一个下午帮 LeeSin 理解官网上可编辑表格的代码，让他去完成成绩录入表格，不过他对本项目并不是非常上心，鸽了很久，我把其他组件写完了他还没有写完 L 新建了一个新的 git 仓库，并设置好了路由表文件。 至于第二周结束后要检查的概要设计文档啥的，S 又是一个人搞定了然后交了。 本周耗费在这上面的时间减半：22.75h（13.5%）。约每天 3.25 小时，因为我做得太多，另外两人似乎就打算摸鱼了。 第三周我的进度： 整合各个组件 编写学生端成绩表组件 编写下载成绩单按钮组件 编写学生端首页以及路由跳转 L 的进度： 完成登录功能 完成整体框架，可以将我们写的组件装进去 Leesin 的进度： 没啥进度，仍然在写他的第一个组件：成绩录入组件。他主要是在复习考研。对此事我有些意见，我不用考研吗？不帮我分担工作量的话我就没时间复习了。 本周耗费在这上面的时间：16h（9.5%）：约每天 2.29 小时。 第四周组件基本上都写好了，只差集成和修复 bug 了。那一周我们都在学校的咖啡吧内进行编码，轮流去吃饭，提前体验 996。 本周耗费在这上面的时间：44.5h。 4、结果（Result）S 和 L 将项目打包部署到服务器上，整体来看挺不错的。 前一天晚上时并没有什么问题，不过答辩时出现了很多问题，导致整个演示非常失败。 同时我介绍自己的工作时，因为没有提前打草稿，并且因为演示出现了问题而有些慌乱，所以虽然我做了很多的工作，但是并没有表达出来。 二、评估结果将结果与目标进行对比：1. 编写出符合需求的软件：因为需求分析并不完善，差不多就是乱来，所以直到答辩的时候，仍然有没有实现的需求，甚至老师在答辩时问出来，才想起来还有这个功能。 2. 进行良好的团队协作：团队协作一团糟，各人心不在此，不愿意为项目出力，前端另外两人的摸鱼，打击了认真工作的我的积极性，让我认为没有必要投入这么多时间在这上面。 组长 S 和副组长 L 完全不管任务分配，我写组件写功能完全是自己主动想还有哪些部分没做，然后去写。 哪怕是我给他们两个分配了任务，他们也不干事情，特别批评 LeeSin，如果不是因为最后一周 S 要求 996，估计他整个项目只写了那一个组件。 八个人的小组，实际上干活的只有四个人，到最后一周的周四，也就是答辩前一天，组长 S 叫他们过来“对口供”，让他们知道自己“做了”什么工作。其中一人甚至在答辩描述自己工作的时候抢了 LeeSin 的工作。 这能叫做“团队”？ 3. 进行标准的软件开发流程我们真的是软件工程专业的学生吗？ 需求分析阶段，要不是我主动绘制了一下原型，主动和他们统一了需求，可能所有人连需求都不清楚。 概要设计和详细设计，到了交文档的时候，组长这才想起来要叫人写这个。我看他一直没说啥，还以为他已经写好了。这个文档似乎也没发小组群里，咱到最后也不知道咱们的设计是怎样的。 我干脆也不提了，反正那个主要是后端的设计，设计得如何也不会影响前端，我调接口就行。不当组长就是好，我能体会到之前我的组员的感受了。 负责后端的 S 不和前端商量接口文档，他写完了直接把接口文档给我们。 接口名是中英文混杂的，最离谱的一个是这样的： /user/findxuyaolurubukaochengjideren，功能是“查找需要录入补考成绩的人”，强迫症看了想打人。 而且需要前端传的参数的名字都是 tool1， tool2之类的没有具体含义的名称，不同的接口这几个参数的顺序还都不一样，例如接口 1 的 tool1 是课程号，tool2 是教师职工号，功能相似的接口 2 就有可能是 tool1 为教师职工号，tool2 为课程号。 返回值的标识符命名也非常诡异，比如 status， statuss和 statusss这三个莫名其妙的名字，让人不清楚到底代表什么含义。 本应该返回相同结构的数据的接口返回的结构截然不同，甚至一个是对象数组，另一个是含有数组属性的对象，好在和他说了之后，他改回来了，否则光是转换数据都很麻烦。 编码阶段，既然没有人来分配任务，那么谁想到哪个功能还没做就主动去写一下就好了。我一开始知道 L 并不打算当前端的领袖之后，就是这么想的。 但是 L 和 LeeSin 的表现着实让我有些生气，完成了任务之后不主动想想还有什么自己可以做的任务，而是开始刷 LOL 视频，或者其他的事情。这可是都最后一周了，大家都被 S 叫来聚在一起写代码了，还在摸鱼？ 本来好像没有那么气的，现在回忆起来越想越气。 测试阶段还好，虽然不是遵循标准的测试方法，但好歹是测试出了大部分错误，并且修复。 周五答辩，直到周四上午，组长才提出除了百分制的成绩之外，咱们还要加等级制的成绩。对了，确实需求里面有明确提到这一点，不过我想起来好像一开始提出这个需求的时候，S 说的是等级制之后再考虑。 4. 通过答辩如上文所述，答辩并不成功，出现了很多失误，我自己的个人工作汇报也做得不好，没有把全部的工作都说出来，估计老师在下边听着还觉得我是来划水了，但实际上我做了很多工作。 总结这次项目可以说是失败了，虽然做出了一个能用的项目，甚至还实现了可选的需求，但是并没有满足客户的全部基础需求，并且可选的附加需求也因为演示失误而没有展现出来。 各种区别于其他组的优势并没有在演示时表现出来，例如咱们组将项目部署到了阿里云服务器上面，例如咱们用的是新框架 React 而不是之前学的 Layui，例如咱们使用了 Git 进行项目管理，例如咱们用了前后端分离的方式进行开发，例如咱们组实现了成绩通知邮件的发送。 成员的积极性并没有充分调动起来，效率极其低下，互相甩锅，沟通不善。 项目管理混乱，几乎没有项目管理。 前端和后端的设计非常糟糕，想到哪里写到哪里，时不时还得重构一下才能写得下去。 三、分析原因这里分析的主客观原因以我为主体，而不是整个小组。 主观原因 我参与本次项目的积极性并不强，不当组长而是加入别人的小组本身就是有减少工作量的打算。 没有重视需求分析。（不过还是比组里其他人要重视一些的） 秉持着加入别人的小组就要遵守新小组的规矩的原则，担心与 S、L 起冲突，而很少主动提出自己的看法。 客观原因 客观环境如此，现在大四了，考研的准备考研，找工作的找工作，基本上没有人愿意将心力耗费在这种综合实践上。 两位大佬 S 和 L 已经习惯了一个人搞定后端，一个人搞定前端，可能不太适应团队协作。新人的加入会打乱他们的节奏。 四、找到规律 一个软件项目最重要的就是需求分析 表达得不好并不是因为表达能力不行，而是因为没有提前做准备，如果本次答辩我提前准备好腹稿，那么即使演示出现了问题，我也不会那么紧张 在开始编码之前，一定要明确截止到什么时间要完成哪一个功能或者修复哪一个 bug。大脑记不住太多东西，最好将目标记录下来。在本项目前期，我总是想到什么功能就写什么；后期我开始在云笔记软件内添加待办项目，做一个划掉一个，与该项目有关的参考链接（文档、博客等）和相关代码都放在对应的待办事项后，这样写起每天的工作日志也比较方便，效率也提升了。 积极与队友进行沟通。沟通可以发现队友与你的理解不一致的地方。 五、总结以上便是本次综合实践的复盘总结，本文用了我两个下午的时间，效率有些低，光是整理本次项目相关的资料，就用了我很多的时间。主要时间花费在对经历的回顾上。 下次综合实践应当在每一周做好项目的周总结，这样在最终总结时就能够节约一些时间。下次尽量将复盘的时间压缩到一个小时内。","link":"/posts/project-review-score-system/"},{"title":"scrapy+selenium爬取智联招聘","text":"这是第三个大四综合实践——数据处理与分析。我们小组打算爬取各个招聘网站进行数据分析。 我负责其中的爬虫模块，教了两个队友怎么使用scrapy，打算我解决完爬取数据的一些难题之后，剩余的解析就交给他们。 我觉得解析数据只是苦力活，只要爬取到带有数据的html，剩下的就很轻松了。最后我选择使用selenium，这样就不用分析接口了，两个刚学爬虫的队友也能轻松搞定。 很快地搞定了前程无忧网和拉勾网之后，我在爬取智联招聘网遇到了很多问题。本文将这些问题以及解决方案记录下来，供读者参考。 参考链接以下链接为我在发现问题和解决问题的过程中参考的资料。 INSERT IGNORE 与INSERT INTO的区别：INSERT语句加一个IGNORE可以跳过数据库中已经存在的记录 爬虫scrapy+selenium带cookie免密码登录状态 selenium中get_cookies()和add_cookie（）的用法详解 selenium报错：Invalid cookie domain 记录-爬取智联招聘 selenium的检测与突破 selenium 参数设置-window.navigator.webdriver selenium设置了启动配置，但是window.navigator.webdriver的结果依然为true （新）关于修改window.navigator.webdriver代码失效问题（不必退版本的解决方案） scrapy.Request使用meta传递数据，以及deepcopy的使用 1106Selenium web自动化测试思路分享-打开多个窗口，切换句柄 解决：出现Message: element not interactable元素不可交互的问题 Python selenium错误：ElementNotInteractableException: Message: element not interactable: Element is not Other element would receive the click:解决之一【最终选择的解决方案】 python之selenium调用js(execute_script) 登录智联招聘这个网站，如果不登陆，一个职位都不给你显示，所以第一步是登录。 使用cookies登录一开始打算手动登录之后保存cookies到文件（全自动的吃力不讨好，于是弄成半自动的了），然后启动scrapy时从文件里面读取cookies并加载刷新。 先用下面这个工具模块登录后获取到cookies，保存到文件当中，需要的时候再读取出来。 12345678910111213141516171819202122232425262728293031'''工具模块'''import jsonfrom selenium import webdriverdef getCookies(websiteName): ''' 获取cookies，会打开一个浏览器，然后手动登录，会获取登录后的cookies写入cookies.json中 @return 是否成功 ''' website_map = { 'zhaopin': &quot;https://sou.zhaopin.com/?jl=543&quot; } website_url = website_map.get(websiteName) if website_url == None: return False browser.get(website_url) input('请随便输入点什么代表你已经登录完成：') dictCookies = browser.get_cookies() jsonCookies = json.dumps(dictCookies, sort_keys=True, indent=2) print(jsonCookies) with open(websiteName+'.json', 'w') as f: f.write(jsonCookies) print('获取成功') return Trueif __name__ == &quot;__main__&quot;: getCookies('zhaopin') 读取cookies的代码： 1234567891011121314151617181920212223242526class EmploymentDownloaderMiddleware(object): # Not all methods need to be defined. If a method is not defined, # scrapy acts as if the downloader middleware does not modify the # passed objects. spider_need_login = [ 'zhaopin' ] # 需要登录的爬虫的名字，为了防止影响其他网站的爬虫而存在 isLogin = False # 是否已经登录 def __init__(self): self.browser = webdriver.Chrome() def login(self, websiteName: str): ''' 利用cookies登录 @param websiteName:网站名字，目前支持的网站：'zhaopin'(智联招聘) ''' with open(websiteName+'.json', 'r', encoding='utf8') as f: listCookies = json.loads(f.read()) print('===============================================cookies===============================') print(listCookies) print('===============================================cookies===============================') for cookie in listCookies: self.browser.add_cookie(cookie) self.isLogin = True 去除selenium特征但是即使我读取cookies成功了，页面右上角都显示我用户名了，仍然一直显示加载动画。甚至连“登录之后再搜索，海量职位等你挑！”这一句提示都没有。 用chrome开发者工具比较手动打开的网页以及selenium打开的网页，发现selenium打开的网页发送给接口https://fe-api.zhaopin.com/c/i/sou的请求并没有收到Response，多试几次之后发现了另一个已经收到Response，但是状态码为400 Bad Request。 猜测是selenium打开的网页传递的参数会与人工打开的网页有所区别。 查询资料后，发现是因为selenium打开的网页会有特征变量window.navigator.webdriver（参考：selenium的检测与突破），网站只要检测那个特征变量，就可以判断这次访问是不是selenium打开的，如果这个变量为True，则不加载数据，从而实现反爬虫的目的。看来智联招聘真的是被各种爬虫爬怕了。 找了两三个方法，修改了selenium的启动选项，都无法修改这个变量，因为他们的方法是针对旧版本的chrome的，不过我在博客的评论下找到了一位老哥，他写了一篇不需要退版本的解决方案。（参考：（新）关于修改window.navigator.webdriver代码失效问题（不必退版本的解决方案）） 解决方案是：在selenium启动浏览器之前，让它执行js脚本，修改掉那个变量，详细方法见参考链接。 最后middleware.py里面的核心代码是这样的： 1234567891011class EmploymentDownloaderMiddleware(object): def __init__(self): self.browser = webdriver.Chrome() self.browser.execute_cdp_cmd(&quot;Page.addScriptToEvaluateOnNewDocument&quot;, { &quot;source&quot;: &quot;&quot;&quot; Object.defineProperty(navigator, 'webdriver', { get: () =&gt; undefined }) &quot;&quot;&quot; # 在开启浏览器之前执行脚本去除selenium特征避免被发现是爬虫 无奈使用半自动登录解决特征变量的问题后，终于不再是无尽的加载动画了，但是读取cookies登录显示“登录之后再搜索，海量职位等你挑！”这样的提示信息，不给数据。 可能是因为当次的cookies只能当次使用，之后即使没有过期，也会因为sessionid对不上或者别的什么参数对不上而不给数据。 最后在Middleware获取selenium模拟浏览器网页的源代码之前，加了一个input函数等待我手动在模拟浏览器内登录好了之后再继续执行，方法比较low，但是管用。缺点是每次启动都得登录，有点担心被封号，不过后面频繁爬取时并没有被封过。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class EmploymentDownloaderMiddleware(object): # Not all methods need to be defined. If a method is not defined, # scrapy acts as if the downloader middleware does not modify the # passed objects. spider_need_login = [ 'zhaopin' ] # 需要登录的爬虫的名字，为了防止影响其他网站的爬虫而存在 isLogin = False # 是否已经登录 def __init__(self): self.browser = webdriver.Chrome() self.browser.execute_cdp_cmd(&quot;Page.addScriptToEvaluateOnNewDocument&quot;, { &quot;source&quot;: &quot;&quot;&quot; Object.defineProperty(navigator, 'webdriver', { get: () =&gt; undefined }) &quot;&quot;&quot; # 在开启浏览器之前执行脚本去除selenium特征避免被发现是爬虫 self.loadTime = 3 # 留给浏览器的加载时间 def login(self, websiteName: str): ''' 利用cookies登录 @param websiteName:网站名字，目前支持的网站：'zhaopin'(智联招聘) ''' with open(websiteName+'.json', 'r', encoding='utf8') as f: listCookies = json.loads(f.read()) print('===============================================cookies===============================') print(listCookies) print('===============================================cookies===============================') for cookie in listCookies: self.browser.add_cookie(cookie) self.isLogin = True def process_request(self, request, spider): if request.meta.get('next_page_css') != None: # 如果存在，则说明需要翻页 # 并不下载，因为下载之后又会回到第一页 nextPageBtn = self.browser.find_element_by_css_selector( request.meta['next_page_css']) nextPageBtn.click() time.sleep(self.loadTime) # 给浏览器加载数据的时间 page_text = self.browser.page_source else: self.browser.get(request.url) if spider.name in self.spider_need_login and not self.isLogin: # 如果该爬虫需要登录且未登录 # self.login(spider.name) # self.browser.refresh() # 刷新 input('请手动登录，登录好了之后输入1：') self.isLogin = True # 顺便保存一下cookies，不过后面还是没用到 dictCookies = self.browser.get_cookies() jsonCookies = json.dumps(dictCookies, sort_keys=True, indent=2) print(jsonCookies) with open(spider.name+'.json', 'w') as f: f.write(jsonCookies) print('cookies保存成功') time.sleep(self.loadTime) # 给浏览器加载数据的时间 # 获取渲染后的数据 page_text = self.browser.page_source # 篡改响应对象 return HtmlResponse(url=self.browser.current_url, body=page_text, encoding='utf-8', request=request) 翻页按照我以前的方式来爬取详情页并没有什么问题，但是问题在于爬取详情页的时候，当前标签页会跳转到详情页，之后就回不去目录页了。 开启两个标签页当爬取完第一页的所有职位数据后，selenium模拟浏览器的页面是停留在最后一个职位的详情页的，无法找到“下一页按钮”，也就无法翻页。如果此时手动跳转回目录页，那么之前翻的页是无法保留的，又回到第一页。 解决方案：打开两个标签页，如果正在爬取详情页，则切换到第二个标签页来进行爬取，第一个标签页始终是目录页。 等到详情页爬取完毕，则切换回第一个标签页，翻页并继续解析。 以下是开启第二个标签页并获取句柄的代码： 123456789101112131415161718192021222324252627class EmploymentDownloaderMiddleware(object): spider_need_login = [ 'zhaopin' ] # 需要登录的爬虫的名字 isLogin = False # 是否已经登录 homePageHandle = None # 主页（即目录）的句柄 subPageHandle = None # 子页面（即详情页）的句柄 def __init__(self): self.browser = webdriver.Chrome() self.browser.execute_cdp_cmd(&quot;Page.addScriptToEvaluateOnNewDocument&quot;, { &quot;source&quot;: &quot;&quot;&quot; Object.defineProperty(navigator, 'webdriver', { get: () =&gt; undefined }) &quot;&quot;&quot; }) # 在开启浏览器之前执行脚本去除selenium特征避免被发现是爬虫 self.loadTime = 3 # 留给浏览器的加载时间 self.homePageHandle = self.browser.current_window_handle js = 'window.open(&quot;https://www.baidu.com/&quot;)' self.browser.execute_script(js) # 新建一个窗口 time.sleep(self.loadTime) # 等新窗口创建好 all_handles = self.browser.window_handles self.subPageHandle = all_handles[-1] 接着在process_request函数中判断当前request是否为爬取详情页的请求，如果是，那么就切换到第二个标签页，如果不是，那么就回到目录页进行翻页： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def process_request(self, request, spider): # 如果meta中存在item，则代表需要爬取详情页，在新的页面打开并爬取 if request.meta.get('item') != None: self.browser.switch_to.window(self.subPageHandle) self.browser.get(request.url) # 下载 time.sleep(self.loadTime) # 获取渲染后的数据 page_text = self.browser.page_source else: # 爬取目录页 self.browser.switch_to.window(self.homePageHandle) time.sleep(self.loadTime) # 给浏览器加载数据的时间 if request.meta.get('next_page_css') != None: # 如果存在，则说明需要翻页 # 并不下载，因为下载之后又会回到第一页 nextPageBtn = self.browser.find_element_by_css_selector( request.meta['next_page_css']) self.browser.execute_script( &quot;arguments[0].click();&quot;, nextPageBtn) # nextPageBtn.click() time.sleep(self.loadTime) # 给浏览器加载数据的时间 page_text = self.browser.page_source else: self.browser.get(request.url) if spider.name in self.spider_need_login and not self.isLogin: # 如果该爬虫需要登录且未登录 # self.login(spider.name) # self.browser.refresh() # 刷新 input('请手动登录，登录好了之后输入1：') self.isLogin = True # 顺便保存一下cookies dictCookies = self.browser.get_cookies() jsonCookies = json.dumps( dictCookies, sort_keys=True, indent=2) print(jsonCookies) with open(spider.name+'.json', 'w') as f: f.write(jsonCookies) print('cookies保存成功') time.sleep(self.loadTime) # 给浏览器加载数据的时间 # self.browser.implicitly_wait(self.loadTime) # 获取渲染后的数据 page_text = self.browser.page_source # 篡改响应对象 return HtmlResponse(url=self.browser.current_url, body=page_text, encoding='utf-8', request=request) 多线程问题默认情况下，scrapy开启多个线程来进行爬取，这就导致上一个问题的解决方案会出现问题——一个线程正在爬取详情页的时候，另一个线程开始切换回目录页进行翻页了。 解决方法是，在settings.py里面将同时允许的线程数设置为1，也就是单线程运行，反正我对速度没有要求： 123# settings.py# Configure maximum concurrent requests performed by Scrapy (default: 16)CONCURRENT_REQUESTS = 1 下一页按钮被遮挡翻页时，会出现“下一页按钮”被遮挡而无法点击的情况。 也就是出现Message: element not interactable元素不可交互的问题，解决方法参考：Other element would receive the click:解决之一 将模拟点击的代码改为： 1234nextPageBtn = self.browser.find_element_by_css_selector(request.meta['next_page_css'])# nextPageBtn.click() # 原本的点击代码self.browser.execute_script(&quot;arguments[0].click();&quot;, nextPageBtn) # 新的模拟点击代码 这里arguments[0]代指后面跟着的第一个参数，也就是nextPageBtn。 这个方法虽然解决了翻页，但是新的问题又出现了。 翻页后，数据并没有刷新，虽然显示跳转到了下一页，但是数据仍然是第一页的数据，延长等待时间仍然不行，一看开发者工具，好嘛，request又变红了。 这个问题我现在也没有解决。","link":"/posts/scrapy-selenium-zhilian-zhaopin-spider/"},{"title":"python爬虫学习笔记2模拟登录与数据库","text":"为了加入学校里面一个技术小组，我接受了写一个爬取学校网站通知公告的任务。这个任务比以前写的爬虫更难的地方在于，需要模拟登录才能获得页面，以及将得到的数据存入数据库。 本文按照日期来记录我完成任务的过程，然后再整理一遍全部代码。读者可以通过侧栏目录跳转阅读。不介绍库的安装。 传送门：爬虫学习笔记 1 转载声明关于参考链接：本文用到的其他博客的链接都以（我自己对内容的概括或者文章原标题-来源网站-作者名）的格式给出，关于作者名，只有博客作者自己明确声明为“原创”，我才会加上作者名。引用的文章内容我会放在来源链接的下方。 关于本文：我发一下链接都注明出处了，如果想转载，也请这样做。作者憧憬少，链接的话看浏览器地址栏。 任务介绍爬取信息门户新闻并且存入数据库。 首先分解任务： 实现爬取综合新闻页面的公开新闻存入 markdown 文件中(190303 完成) 将数据存到数据库（190304 完成） 学习模拟登录（190305 到 190307 完成） 爬取信息门户新闻（190308 完成） （进阶）将代码进行封装、优化（目前未封装） （进阶）动态更新（目前未着手） 过程记录190303 周日练习爬取公开页面我的第一个爬虫是在 2 月多的时候在家写的，那个只是个简单的爬虫，目标是公开的页面，不需要模拟登录，也不需要存储到数据库，直接存到 txt 文件中。 先爬取学校官网的综合新闻页面复习一下。 首先讲一下我的思路： 由于新闻和公告页面通常是有一个目录页面的，也就是包含子页面的链接，在目录的子页面内才是正文内容。 假设这一页目录有三个新闻，就像是下面： 新闻目录 新闻一 新闻二 新闻三 点击查看下一页 这样的结构。 如果要写一个爬虫函数来爬取所有新闻页面，那么就要从目录着手。目录中含有前往别的新闻页面的链接，所以可以在目录页获取本页所有新闻的链接，遍历所有链接并提取新闻内容。 至于翻页也可以这样做到，“下一页”按钮也是一个链接，可以通过这个链接获取到下一页的内容。翻页部分原理比较简单，我是先攻克其他难关，把它留到最后写的。 提取单页面新闻首先是提取单个页面的新闻。向目标 url 发出访问请求： 1234567891011import requestsdef getNews(url): ''' 提取页面的新闻与图片并存储为markdown文件 :param url: 要爬取的目标网页url :return: 无 ''' #发送请求 r=requests.get(url)#r为response对象 html=r.text#r.text是请求的网页的内容 print(html) 编码问题这里遇到了第一个问题，提取到的页面有乱码。 解决方法：先获取响应对象的二进制响应内容，然后将其编码为 utf8 参考链接： python 中 response.text 与 response.content 的区别-CSDN requests.content 返回的是二进制响应内容 而 requests.text 则是根据网页的响应来猜测编码 UNICODE,GBK,UTF-8 区别（一个比较好的编码的教程，便于理解编码的概念）-博客园 Python 解决抓取内容乱码问题（decode 和 encode 解码）-CSDN-浅然_ 字符串在 Python 内部的表示是 unicode 编码，在做编码转换时，通常需要以 unicode 作为中间编码，即先将其他编码的字符串解码（decode）成 unicode，再从 unicode 编码（encode）成另一种编码。 decode 的作用是将其他编码的字符串转换成 unicode 编码，如 str1.decode(‘gb2312’)，表示将 gb2312 编码的字符串 str1 转换成 unicode 编码。 encode 的作用是将 unicode 编码转换成其他编码的字符串，如 str2.encode(‘utf-8’)，表示将 unicode 编码的字符串 str2 转换成 utf-8 编码。 修改代码为： 1234#发送请求r=requests.get(url)html=r.content#获取二进制字节流html=html.decode('utf-8')#转换为utf8编码（该网页使用的是utf8编码） 解析网页（bs4）一开始我和之前一样使用正则表达式来提取，但是不够熟悉，总是写不出匹配的上的正则表达式。还是使用另一个东西——BeautifulSoup 库 具体如何使用请查看其他教程，本文只说我自己用到的部分。 参考链接： Python 爬虫常用的几种数据提取方式-CSDN-凯里潇 零基础入门 python3 爬虫-bilibili（里面的视频 p11） beautifulsoup（基本选择器，标准选择器，css 选择器）-CSDN-Halosec_Wei（基本上是上面一个 b 站链接的文字版，不知道是不是同一个人） beautifulsoup 详细教程-脚本之家 beautifulsoup 基本用法总结-CSDN-kikay BeautifulSoup 是 Python 的一个库，最主要的功能就是从网页爬取我们需要的数据。BeautifulSoup 将 html 解析为对象进行处理，全部页面转变为字典或者数组，相对于正则表达式的方式，可以大大简化处理过程。 我目前的理解是，这个 BeautifulSoup 库需要用到其他 html 解析库，可以使用 python 自带的，也可以安装第三方库，其他的库就像功能扩展插件一样，没有的话它自己也能解析。我安装了名为 lxml 的解析库。 查看源代码，找到网页中有关新闻的代码，手动将其格式化之后如下（内容不重要，省略）： 12345678910111213141516171819202122232425262728&lt;h1 class=&quot;arti-title&quot;&gt;标题省略&lt;/h1&gt;&lt;p class=&quot;arti-metas&quot;&gt; &lt;span class=&quot;arti-update&quot;&gt;发布时间：2019-01-23&lt;/span&gt; &lt;span class=&quot;arti-update1&quot;&gt;作者：xx&lt;/span&gt; &lt;span class=&quot;arti-update2&quot;&gt;来源：xxx&lt;/span&gt;&lt;/p&gt;&lt;div class=&quot;entry&quot;&gt; &lt;article class=&quot;read&quot;&gt; &lt;div id=&quot;content&quot;&gt; &lt;div class=&quot;wp_articlecontent&quot;&gt; &lt;p&gt;新闻前言省略&lt;/p&gt; &lt;p&gt;&lt;br /&gt;&lt;/p&gt; &lt;p&gt;新闻内容省略&lt;/p&gt; &lt;p&gt; &lt;img width=&quot;556&quot; height=&quot;320&quot; align=&quot;bottom&quot; src=&quot;url省略&quot; border=&quot;0&quot; /&gt; &lt;/p&gt; &lt;p style=&quot;text-align:right;&quot;&gt;（审稿：xx &amp;nbsp;网络编辑：xx）&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; 接着上面的代码： 123456789#解析htmlsoup=BeautifulSoup(html,&quot;lxml&quot;)#返回已解析的对象#获取标题title=soup.find('h1',class_='arti-title').string#获取时间update=soup.find('span',class_='arti-update').string#获取正文标签content=soup.find('div',class_='wp_articlecontent') 提取图片我打算将新闻保存到 markdown 文件中，提取新闻中的图片的链接的地址，这样在 md 文件中就能显示出图片了。 1234567#获取图片链接base='学校官网url，用于和img标签中的相对地址拼接成绝对地址'imgsTag=content.find_all('img')imgsUrl=[]for img in imgsTag: imgsUrl.append(base+img['src'])#拼接成完整的url img.extract()#删除图片标签 删除多余标签123456#删除多余标签for p in content.find_all('p',{'style':&quot;text-align:center;&quot;}): p.extract()p=content.find('p', {'style': &quot;text-align:right;&quot;})if(p!=None): p.extract() 保存到文件123456789101112# 拼接成字符串#后来知道这样的提取方式其实不能完全提取到所有内容fileContent=''for i in content.contents:#遍历正文内容的所有子标签 if(i.string!=None):#如果子标签里面有内容 #print(i.string)#调试 fileContent+=i.string#基本只剩下p标签了 fileContent+='\\n\\n'#保存到md文件with open('data.md','w') as fout: fout.write(fileContent) 代码总览12345678910111213141516171819202122232425262728293031323334353637383940414243444546import requestsfrom bs4 import BeautifulSoup#第4个版本改名bs4而不是全名那么长了def getNews(url): ''' 提取页面的新闻与图片并存储为markdown文件 :param url: 要爬取的目标网页url :return: 无 ''' #发出请求 r=requests.get(url) html=r.content html=html.decode('utf-8')#转换编码 #解析html soup=BeautifulSoup(html,&quot;lxml&quot;) content=soup.article #获取标题 title=soup.find('h1',class_='arti-title').string #获取时间 update=soup.find('span',class_='arti-update').string #获取正文 content=soup.find('div',class_='wp_articlecontent') #获取图片链接 base='http://xxxxx.xxx'#学校官网url，用于和img标签中的相对地址拼接成绝对地址 imgsTag=content.find_all('img') imgsUrl=[] for img in imgsTag: imgsUrl.append(base+img['src'])#拼接成完整的url img.extract()#删除图片标签 #删除多余标签 for p in content.find_all('p',{'style':&quot;text-align:center;&quot;}): p.extract() p=content.find('p', {'style': &quot;text-align:right;&quot;}) if(p!=None): p.extract() # 拼接成字符串 fileContent='' for i in content.contents: if(i.string!=None): #print(i.string)#调试 fileContent+=i.string fileContent+='\\n\\n' with open('data.md','w') as fout: fout.write(fileContent) 提取多页面新闻原理在上面说了，提取完单页基本上就完成了。 12345678910111213141516171819import requestsfrom bs4 import BeautifulSoupdef getNewsContents(url): ''' 爬取目录页面链接到的页面 :param url: 新闻目录页面的url :return: 无 ''' #获取网页内容 r=requests.get(url)#以get方式访问 html=r.content html=html.decode('utf-8') #获取每篇新闻的链接 base='http://xxxxx.xxx'#学校官网url，用于和相对地址拼接成绝对地址 soup=BeautifulSoup(html,'lxml') for page_url in soup.find_all('a',class_='column-news-item'): page_url=base+'/'+page_url['href'] print(page_url) getNews(page_url)#调用提取单页函数 day1 进度 实现爬取长安大学综合新闻页面的公开新闻存入 markdown 文件中 复习了 requests 库的使用 学习了 BeautifulSoup4 库的基本使用 190304 周一这一天主要是将前一天爬取的数据存入数据库。 将数据存入数据库安装 MySQL 数据库参考链接： 零基础入门 python3 爬虫-bilibili（里面的视频 p4） 使用 MySQL WorkbenchMySQL Workbench 是一个可视化工具，安装 MySQL 的时候自带（我安装的是最新版的），在安装目录找到它的 exe 然后加个快捷方式在桌面，可以方便地查看数据和执行 SQL 查询指令，具体使用方法可以问度娘。我现在也不是很会。 我创建的数据库名为 news，里面创建了一个数据表 chdnews。 连接数据库和大多数数据库一样，MySQL 是 C/S 模式的，也就是客户端（client）/服务端（server）模式的。数据库有可能在远程服务器上。想要使用数据库，就需要连接到数据库。 python 中要使用数据库需要一个 pymysql 库。 下面是连接的代码： 123import pymysql#连接数据库db = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd='root', db='news', charset='utf8') 这个连接函数看参数名就可以看出含义了。 host：主机 ip，127.0.0.1 是回传地址，指本机。也就是连接本电脑的 MySQL 的意思 port：端口号，用来和 ip 一起指定需要使用数据库的软件。在安装的时候会让你设置，默认 3306 user&amp;passwd：用户名和密码，在安装的时候已经设置好了 db：你要连接的数据库的名字。一台电脑上可以有很多数据库，数据库里面可以有很多数据表。 charset：字符编码 插入数据接着可以准备一个游标，游标大概是一个用于存储结果集开头地址的指针吧，我是这么理解的。在我学了更多数据库知识后可能会更新这一部分。 12#创建游标cursor = db.cursor() 接着执行 SQL 的插入语句： 12#插入cursor.execute(&quot;insert into chdnews(`title`,`article`) values('{0}','{1}')&quot;.format(title,fileContent))#此处变量为上文代码中的变量 这里的 SQL 语句是这样的： 1insert into 数据表名(字段名1，字段名2) values(值1，值2) 后面的format函数是 python 的格式化函数，将变量的值加入到字符串中对应位置。 最后提交： 12#提交更改db.commit() 接着打开 workbench，就会发现已经存入数据库了。（你得把代码放在上面提取单页新闻的函数那里，放在保存到文件的那部分代码那儿） day2 进度 下载并安装 MySQL 以及 MySQL Workbench 使用 pymysql 库进行数据库的连接，实现了把第一天得到的数据存入数据库 190305 周二初步了解模拟登录最后的任务需要爬取登录后才能查看的页面，于是我去搜索了很多博客，只放一部分对我有帮助的链接。 参考链接： 模拟登录 CSDN-博客园 模拟登录 github-博客园 首先查看一下需要的登录数据： 打开登录网页，用 F12 打开开发者工具，选择 network（网络）选项卡 登录你的账号，此时控制台会显示一大堆请求与响应，找到以 post 方式发送的请求，一般排在第一个 那里会显示几个栏目，找到Form Data（表单数据），这个里面是你填写登录表单之后使用 POST 方式发送给服务端的内容。这里面除了自己填写的账号密码之外还有一些东西，比如下图的lt,dllt,execution,_eventId,rmShown这些都是在表单的隐藏域中，查看登录页面的源代码是可以看的到的。这些隐藏起来的东西是为了检验你是否是从浏览器进来的，只要获取到这些东西，再加上头部信息，就能伪装成浏览器了 至于头部信息，在下图也可以看到我折叠起来的几个栏目，有一个是Request Headers，这是我们在点击登录按钮时发送的 POST 请求信息的信息头。将里面的User-Agent给复制到你代码里面存在一个字典里面等会用 把头部信息和表单数据都看一下，准备一下 12345678910111213141516171819202122#登录前的准备login_url = 'http://xxxx.xxx'#登录页面的url#头部信息headers={ 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36' #加上后面这些会后悔的，别加。 'Host':'xx.xx.xx.xx', 'Referer':'http://xxx.xxx?xxx=http://xxx.xx', 'Origin':'http://xxx.xxx.xx'}#登录用的数据login_data={ 'username': '你的账号', 'password': '你的密码', 'btn':'', 'lt': LT-790162-J9kW2aEFsK3ihu4AzXcovdsJy6cYBM1552123884047-D1Nx-cas， #实际上lt并不能这样写上去，下文会解释。这里记录我自己的错误 'dllt': 'userNamePasswordLogin', 'execution': 'e1s1', '_eventId': 'submit', 'rmShown': 1 } 数据准备好之后就开始登录，使用的是 requests 的另一个方法——post。 向服务器发出请求（request）的方式有 get 和 post，查看 html 源代码的时候在表单标签处可以看到表单提交的方法。如： 1&lt;form id=&quot;casLoginForm&quot; method=&quot;post&quot;&gt;&lt;/form&gt; 像这样写 html 代码会让浏览器在你按下登录按钮的时候以 post 的方式提交表单，也就是以 post 的方式向服务器发起 request，将 form data 发送过去。 post 方法的好处是在发送过程中会隐藏你的表单数据，不会被直接看到； 而前面使用过的 get 方法，会把你的表单数据加在 url 后面，网址后边以问号开头，以&amp;连接的就是发送过去的参数。 涉及登录用 post 比较好，以免轻易泄露密码。 12#以post方式发出登录请求r=requests.post(login_url,headers=headers,data=login_data) 按理来说应该可以了呀，为什么不行？仍然得到登录页面。在这一天我折腾了很久，没有得到答案。 不过在找资料时却学到了其他的一些知识，关于 cookie 和 session。 cookie 和 session我目前的理解（如果不对欢迎留言）： http 是无状态协议，两次访问都是独立的，不会保存状态信息。也就是你来过一次，下次再来的时候网站还是当你第一次来。那么怎么知道你来过，从而给你还原之前的数据呢？就有人想出 cookie 和 session 两种方式。 cookie（直译：小甜饼）是服务端（网站服务器）收到客户端（你电脑）的 request（请求）的时候和 response（响应）一起发给客户端的数据。客户端把它存在文件里面，并在下一次访问这个网站时将 cookie 随着 request 一起发送过去，这样服务端就会知道你就是之前来过的那个人了。cookie 存储在客户端。 客户端发送 request 服务端发送 response 附带一个 cookie（一串数据） 客户端第二次访问时把 cookie 复制一份一起发过去 服务端看到你的 cookie 就知道你是谁了 session（会话）是在服务端内存中保存的一个数据结构，一旦有客户端来访问，那么就给这个客户端创建一个新的 session 在服务端的内存，并将它的 session ID 随着 response 发回给客户端。客户端第二次访问时，会将被分配的 SID 随着 request 一起发过来，服务端在这边验证 SID 之后就会知道你来过。session 存储在服务端。 客户端发送 request 服务端发送 response 并在自己这边创建一个 session（一堆数据）并发送一个 session ID 给客户端 客户端第二次访问时把 session ID 一起发过去 服务端看到你的 session ID 就知道你是谁了 不过这俩是用来保持登录的，我还没登录成功想这个干啥？请看下一天。 day3 进度 初步了解 cookie 和 session 的概念 了解如何使用 chrome 浏览器的控制台查看 post 表单信息 尝试使用 requests 的 post 方法模拟登录，失败，返回登录页面 190306 周三表单校验码（非验证码）怎么弄都不成功，都跳回登录页面。我只好去询问组长这是为什么。 原来我没发现表单校验码会变的！ 一直没注意啊啊啊啊啊啊！ 我没有认真比对过两次打开的乱码不一样，看结尾一样就以为一样了。其中的lt这个域每次打开网页都是不一样的，随机出的！ 既然知道了问题，就好解决了。 123456789101112131415161718#获取登录校验码html=requests.post(login_url,headers=headers).textsoup=BeautifulSoup(html,'lxml')lt=soup.find('input',{'name':'lt'})['value']dllt=soup.find('input',{'name':'dllt'})['value']execution = soup.find('input', {'name': 'execution'})['value']_eventId = soup.find('input', {'name': '_eventId'})['value']rmShown = soup.find('input', {'name': 'rmShown'})['value']login_data={ 'username': input(&quot;请输入学号：&quot;), 'password': input(&quot;请输入密码：&quot;), 'btn':'', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown} 为了保险，我把其他的表单域也给解析赋值给变量了。 不过仍然无法登陆成功，而是进入了一个诡异的页面: 1234567891011121314151617181920212223242526272829&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Welcome to nginx!&lt;/title&gt; &lt;style&gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Welcome to nginx!&lt;/h1&gt; &lt;p&gt; If you see this page, the nginx web server is successfully installed and working. Further configuration is required. &lt;/p&gt; &lt;p&gt; For online documentation and support please refer to &lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br /&gt; Commercial support is available at &lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;. &lt;/p&gt; &lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 确实有进展，但是这是啥？nginx？查了一下是一个高性能的 HTTP 和反向代理服务器，但是和我现在登录有什么关系呢？（黑人问号.jpg） 利用 session 保持校验码即使登录成功，还有一个问题无法解决，那就是我获取校验码的 request 和登录用的 request 是两次不同的访问请求呀，这样校验码又会变化。 我想起了前一天看到的 session，这玩意不就能让服务端记住我？（cookie 试了一下，保存下来的是空的文件不知道怎么回事） 于是新建一个会话： 12#新建会话session=requests.session() 在获取校验码的时候改成使用 session 变量来发起请求： 12#获取登录校验码html=session.post(login_url,headers=headers).text 这里的 session 是在客户端创建的，并不是服务端那个，我想它可能存储的是服务端发送过来的 session ID 吧。 同理在正式发送请求时这样： 12#登录r=session.post(login_url,headers=headers,data=login_data) 这样就能让服务端知道我是刚刚获取校验码的那个小伙汁：D 在这一天我没有办法验证是否有效，不过在之后我验证了这个方法的成功性。 day4 进度 知道了原来有个每次会变化的校验码“lt”，找到了跳转回登录页面的原因。使用 Beautifulsoup 来获取每次的校验码，不过仍然没有解决无法登录的问题 使用 session 对象来保证获取校验码和登录时是同一个会话，未验证 190307 周四多余的头部信息我终于发现了问题所在！！！！！ 1234567headers={ 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36', #'Host':'xxx.xxx.xxx.xxx', #'Referer':'http://xxx.xxx.xxx.xxx...',#不详细打码了 #'Origin':'http://xxx.xxx.xxxx' #去掉多余的头信息才成功登录！！！！！卡了很久没想到是因为这个} 头部信息写多了，我只保留了User-Agent之后成功登录了，你们能体会到我当时有多开心吗！ 我将成为新世界的卡密小组里面最快完成的人！ 解决了这个问题，剩下的就特别简单了。 当时我有一个下午的时间，于是我将进度迅速推进。 爬取通知公告设登录页面为 pageA，登录之后的页面跳转到 pageB，而 pageB 有一个按钮跳转到 pageC，这个 pageC 就是 day1 的时候的目录页面，里面有着 pageC1、pageC2、pageC3……等页面的链接，而这个 pageC 最后面还有个按钮用于跳转到目录的下一页，也就是 pageC?pageIndex=2，还有 137 页公告栏目录。 没有什么新的东西，和 day1 说的爬取方式差不多，只是页面正文的格式和 day1 的新闻不太一样。核心结构如下，我省略了很多： 12345678910111213&lt;html&gt; &lt;body&gt; &lt;div class=&quot;bulletin-content&quot; id=&quot;bulletin-contentpe65&quot;&gt; &lt;p style=&quot;;background: white&quot;&gt; &lt;a name=&quot;_GoBack&quot;&gt; &lt;/a&gt; &lt;span style=&quot;font-size: 20px;font-family: 仿宋&quot;&gt; 校属各单位： &lt;/span&gt; &lt;/p&gt; &lt;p&gt; &lt;br /&gt; &lt;/p&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 大概就是一个&lt;p&gt;标签里面放一个或多个&lt;span&gt;标签，而这里面可能还会嵌套几个&lt;span&gt;标签，里面才有内容，而两个内部的&lt;span&gt;之间还可能有内容。 这要怎么解析？ 在尝试了很多方案之后，我终于百度到一个函数： 1tag.get_text()#提取名为tag的bs4标签的内部的所有文字 参考链接： BeautifulSoup 获取标签中包含的文字-CSDN-niewzh（正是这个博客解决了我的问题） BeautifulSoup 中的.text 方法和 get_text()方法的区别-CSDN 解决方案： 12345678910#获取正文内容html=session.post(url,headers=headers).textsoup=BeautifulSoup(html,'lxml')article=soup.find('div',class_='bulletin-content')news_content=''for p in article.find_all('p'): if p.span!=None:#如果p含有一层span text=str(p.get_text()).strip()#获取内容并去除多余空格 news_content+=text+'\\n' 接着我就把爬下来的东西存到数据库里面去了。弄完之后得去赶作业了，这一天的时间用完了。 day5 进度1.找到无法登录且跳转到未知页面的原因是头部信息加了多余的值，解决之后成功登录到信息门户，实现模拟登陆 2.利用之前爬取单个页面到文件的方法，用 beautifulsoup 解析并保存内容到文件 3.存入 MySQL 数据库中 4.还差爬取多页目录的功能，预计明天完成。整理代码后可提交 190308 周五更多的目录页开了一个新文件准备整理一下代码，并完成最后一个功能——爬取完目录页第一页之后爬取后面更多的页。 查看源代码的时候，找“第二页”这个按钮对应的链接，发现了规律： 1234567891011121314151617181920212223242526272829303132333435363738&lt;div class=&quot;pagination-info clearFix&quot;&gt; &lt;span title=&quot;共2740条记录 分137页显示&quot;&gt; 2740/137 &lt;/span&gt; &lt;a href=&quot;detach.portal?pageIndex=1&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; title=&quot;点击跳转到第1页&quot; &gt;&amp;lt;&amp;lt;&lt;/a &gt; &lt;div title=&quot;当前页&quot;&gt;1&lt;/div&gt; &lt;a href=&quot;detach.portal?pageIndex=2&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; title=&quot;点击跳转到第2页&quot; &gt;2&lt;/a &gt; &lt;a href=&quot;detach.portal?pageIndex=3&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; title=&quot;点击跳转到第3页&quot; &gt;3&lt;/a &gt; &lt;a href=&quot;detach.portal?pageIndex=4&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; title=&quot;点击跳转到第4页&quot; &gt;4&lt;/a &gt; &lt;a href=&quot;detach.portal?pageIndex=5&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; title=&quot;点击跳转到第5页&quot; &gt;5&lt;/a &gt; &lt;a href=&quot;detach.portal?pageIndex=6&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; &gt;&amp;gt;&lt;/a &gt; &lt;a href=&quot;detach.portal?pageIndex=137&amp;amp;pageSize=&amp;amp;.pmn=view&amp;amp;.ia=false&amp;amp;action=bulletinsMoreView&amp;amp;search=true&amp;amp;groupid=all&amp;amp;.pen=pe65&quot; title=&quot;点击跳转到最后页&quot; &gt;&amp;gt;&amp;gt;&lt;/a &gt;&lt;/div&gt; 可以看出，指向其他目录页的相对链接，只是参数略有不同，参数中只有pageIndex发生了变化。至于给 url 加参数，我记得前几天看到过。 123456789101112131415161718#作为参数的字典para={ 'pageIndex':1,#这里需要修改，先爬第一页 'pageSize':'', '.pmn':'view', '.ia':'false', 'action':'bulletinsMoreView', 'search':'true', 'groupid':'all', '.pen':'pe65'}catalogue_url='http://xxx.xx.xx.cn/detach.portal'#未加参数的新闻目录页url session = login() # 获取已登录的session,这个自定义函数会在下面列出 for i in range(1,page_count+1):#page_count是要获取的页数 para['pageIndex']=i#设置新闻当前页的索引 # 从目录页获取新闻页面链接 html = session.post(catalogue_url,params=para).text 整理代码要用到的库 1234import requestsimport refrom bs4 import BeautifulSoupimport pymysql get_bulletin12345678910111213141516171819202122232425262728293031323334353637def get_bulletin(page_count): ''' 目录有多页，从第一页开始获取，往后获取page_count页的目录，并读取目录指向的所有公告 :param page_count: 要爬取的目录页面的数量 :return: 无 ''' para={ 'pageIndex':1, 'pageSize':'', '.pmn':'view', '.ia':'false', 'action':'bulletinsMoreView', 'search':'true', 'groupid':'all', '.pen':'pe65' } catalogue_url='http://xxx.xxx.xxx.cn/detach.portal'#未加参数的公告目录页url session = login() # 获取已登录的session for i in range(1,page_count+1): para['pageIndex']=i#设置公告当前页的索引 # 从目录页获取公告页面链接 html = session.post(catalogue_url,params=para).text soup = BeautifulSoup(html, 'lxml') rss_title = soup.find_all('a', class_='rss-title') #将得到的链接与标题组装成字典 bulletin_dict = {} for url in rss_title: bulletin_title = str(url.span.string).strip() bulletin_url = 'http://xxx.xx.xx.cn/' + url['href'] bulletin_dict.setdefault(bulletin_title, bulletin_url)#添加一条公告记录 #保存公告到数据库 for bulletin_title, bulletin_url in bulletin_dict.items(): #saveInTXT(bulletin_url, session, bulletin_title)#这个是保存到txt文件的函数，用于测试 saveInDB(news_url, session, news_title) login1234567891011121314151617181920212223242526272829303132333435363738def login(): &quot;&quot;&quot; 登录并返回已经登录的会话 :return: 已经登录的会话（session） &quot;&quot;&quot; #设置 login_url = 'http://xxx.xx.xx.cn/authserver/login?service=http%3A%2F%2F%2F' headers={ 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36' } #新建会话 session=requests.session() #获取登录校验码 html=session.post(login_url,headers=headers).text soup=BeautifulSoup(html,'lxml') lt=soup.find('input',{'name':'lt'})['value'] dllt=soup.find('input',{'name':'dllt'})['value'] execution = soup.find('input', {'name': 'execution'})['value'] _eventId = soup.find('input', {'name': '_eventId'})['value'] rmShown = soup.find('input', {'name': 'rmShown'})['value'] login_data={ 'username': input(&quot;请输入学号：&quot;), 'password': input(&quot;请输入密码：&quot;), 'btn':'', 'lt': lt, 'dllt': dllt, 'execution': execution, '_eventId': _eventId, 'rmShown': rmShown } #登录 response=session.post(login_url,headers=headers,data=login_data) if response.url=='http://xxx.xx.xx.cn/': print('登录成功！') return session saveInTXT12345678910111213141516171819202122232425262728293031323334353637def saveInTXT(url, session, title): ''' 获取单个公告页面的公告并保存到txt :param url: 要获取的页面的url :param session:已经登录的会话 :param title:公告标题 :return:无 ''' #将标题转换为可以作为文件名字的形式 reg = r'[\\/:*?&quot;&lt;&gt;|]' title = re.sub(reg, &quot;&quot;, title) path='bullet\\\\' + title+'.txt'#保存在py文件目录下的bulletin文件夹内，以txt格式保存 headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36' } ''' #测试代码，从文件读取手动获取的公告html页面，单机测试 with open('new.txt','r',encoding='utf8') as fin: html=fin.read() ''' html=session.post(url,headers=headers).text soup=BeautifulSoup(html,'lxml') #print(soup.prettify()) bulletin_content=soup.find('div', class_='bulletin-content') bulletin_content= '' for p in bulletin_content.find_all('p'): if p.span!=None:#如果p含有一层span text=str(p.get_text()).strip() bulletin_content+= text + '\\n' with open(path,'w',encoding='utf8') as fout: fout.write(bulletin_content) print('“{}”成功保存到{}'.format(title,path)) saveInDB1234567891011121314151617181920212223242526272829def saveInDB(url, session, title): ''' 获取单个公告页面的公告并保存到txt :param url: 要获取的页面的url :param session:已经登录的会话 :param title:公告标题 :return:无 ''' headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36' } html=session.post(url,headers=headers).text soup=BeautifulSoup(html,'lxml') bulletin_content=soup.find('div', class_='bulletin-content') bulletin_content= '' for p in bulletin_content.find_all('p'): if p.span!=None:#如果p含有一层span text=str(p.get_text()).strip() bulletin_content+= text + '\\n' #保存到数据库 db = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd='root', db='news', charset='utf8') cursor = db.cursor() cursor.execute(&quot;insert into chdnews(`title`,`content`) values('{0}','{1}')&quot;.format(title, bulletin_content)) db.commit() print('已经成功保存公告到数据库：“{}”'.format(title)) 调用12#调用get_bulletin(10)#爬取10页公告 暂时没有将其通用化，直接将网址写死在函数里面了。 day6 进度 通过调整服务门户的 url 中的参数来获取通知公告的每一个目录页的 url，从而爬取所有公告 将学习中写的测试代码重新构造整理，添加函数注释，提交任务 190309 周六day7 进度写了本篇博客进行总结","link":"/posts/python_spider_note2login_and_database/"}],"tags":[{"name":"cpp","slug":"cpp","link":"/tags/cpp/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"android","slug":"android","link":"/tags/android/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"word","slug":"word","link":"/tags/word/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"tkinter","slug":"tkinter","link":"/tags/tkinter/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"正则表达式","slug":"正则表达式","link":"/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"算法学习","slug":"算法学习","link":"/tags/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","link":"/tags/scrapy/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"excel","slug":"excel","link":"/tags/excel/"},{"name":"ajax","slug":"ajax","link":"/tags/ajax/"},{"name":"selenium","slug":"selenium","link":"/tags/selenium/"},{"name":"mfc","slug":"mfc","link":"/tags/mfc/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"xml","slug":"xml","link":"/tags/xml/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"awt","slug":"awt","link":"/tags/awt/"},{"name":"internet","slug":"internet","link":"/tags/internet/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"}],"categories":[{"name":"日志随笔","slug":"日志随笔","link":"/categories/%E6%97%A5%E5%BF%97%E9%9A%8F%E7%AC%94/"},{"name":"解决方案","slug":"解决方案","link":"/categories/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"name":"博客站务","slug":"博客站务","link":"/categories/%E5%8D%9A%E5%AE%A2%E7%AB%99%E5%8A%A1/"},{"name":"项目总结","slug":"项目总结","link":"/categories/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"},{"name":"学习笔记","slug":"学习笔记","link":"/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]}